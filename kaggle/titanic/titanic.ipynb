{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, id_train = df_train[['Pclass', 'Fare', 'Age']], df_train[['Survived']], df_train[['PassengerId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>3</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>3</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>3</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Fare  Age\n",
       "5         3   8.4583  NaN\n",
       "17        2  13.0000  NaN\n",
       "19        3   7.2250  NaN\n",
       "26        3   7.2250  NaN\n",
       "28        3   7.8792  NaN\n",
       "..      ...      ...  ...\n",
       "859       3   7.2292  NaN\n",
       "863       3  69.5500  NaN\n",
       "868       3   9.5000  NaN\n",
       "878       3   7.8958  NaN\n",
       "888       3  23.4500  NaN\n",
       "\n",
       "[177 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[x_train['Age'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning, cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'n_estimators': 100000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "def train_cv(input_x, input_y, input_id, params, n_splits=5):\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123).split(input_x, input_y))\n",
    "    \n",
    "    for nfold in np.arange(n_splits):\n",
    "        # dataset\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = input_x.loc[idx_tr, :], input_y.loc[idx_tr, :]\n",
    "        x_va, y_va = input_x.loc[idx_va, :], input_y.loc[idx_va, :]\n",
    "        print(f'x_tr:{x_tr.shape}, y_tr:{y_tr.shape}')\n",
    "        print(f'x_va:{x_va.shape}, y_va:{y_va.shape}')\n",
    "        print(\"input_y['Survived']_mean:{:.3f}, y_tr['Survived']_mean:{:.3f}, y_va['Survived']_mean{:.3f}\".format(\n",
    "            input_y['Survived'].mean(), y_tr['Survived'].mean(), y_va['Survived'].mean()\n",
    "        ))\n",
    "        \n",
    "        # learning\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(x_tr, y_tr, \n",
    "                  eval_set=[(x_tr, y_tr), (x_va, y_va)], \n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=10)]\n",
    "                 )\n",
    "        \n",
    "        # evaluation\n",
    "        y_tr_pred = model.predict(x_tr)\n",
    "        y_va_pred = model.predict(x_va)\n",
    "        metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "        metric_va = accuracy_score(y_va, y_va_pred)\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        print(f'[Accuracy]tr:{metric_tr}, [Accuracy]va:{metric_va}')\n",
    "        \n",
    "        # DataFrame(feature importance)\n",
    "        _imp = pd.DataFrame({\n",
    "            'col': input_x.columns,\n",
    "            'imp': model.feature_importances_,\n",
    "            'nfold': nfold\n",
    "        })\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=True)\n",
    "        \n",
    "        # result\n",
    "        print('-'*20, 'result', '-'*20)\n",
    "        metrics = np.array(metrics)\n",
    "        print(metrics)\n",
    "        print('[cv]  tr: {:.2f}+-{:.2f}, va: {:.2f}+-{:.2f}'.format(metrics[:, 1].mean(), metrics[:, 1].std(),\n",
    "                                                                    metrics[:, 2].mean(), metrics[:, 2].std(),\n",
    "                                                                   ))\n",
    "        imp = imp.groupby('col')['imp'].agg(['mean', 'std'])\n",
    "        imp.columns = ['imp', 'imp_std']\n",
    "        imp = imp.reset_index(drop=False)\n",
    "        print('Done')\n",
    "        \n",
    "        return imp, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "x_tr:(712, 2), y_tr:(712, 1)\n",
      "x_va:(179, 2), y_va:(179, 1)\n",
      "input_y['Survived']_mean:0.384, y_tr['Survived']_mean:0.383, y_va['Survived']_mean0.385\n",
      "[1]\ttraining's auc: 0.762985\tvalid_1's auc: 0.729381\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.763607\tvalid_1's auc: 0.730237\n",
      "[3]\ttraining's auc: 0.763607\tvalid_1's auc: 0.730237\n",
      "[4]\ttraining's auc: 0.777045\tvalid_1's auc: 0.732411\n",
      "[5]\ttraining's auc: 0.775702\tvalid_1's auc: 0.735046\n",
      "[6]\ttraining's auc: 0.777383\tvalid_1's auc: 0.72747\n",
      "[7]\ttraining's auc: 0.774955\tvalid_1's auc: 0.738274\n",
      "[8]\ttraining's auc: 0.776974\tvalid_1's auc: 0.739394\n",
      "[9]\ttraining's auc: 0.780612\tvalid_1's auc: 0.729644\n",
      "[10]\ttraining's auc: 0.788155\tvalid_1's auc: 0.736957\n",
      "[11]\ttraining's auc: 0.792636\tvalid_1's auc: 0.739723\n",
      "[12]\ttraining's auc: 0.793779\tvalid_1's auc: 0.740382\n",
      "[13]\ttraining's auc: 0.793958\tvalid_1's auc: 0.735903\n",
      "[14]\ttraining's auc: 0.794342\tvalid_1's auc: 0.737088\n",
      "[15]\ttraining's auc: 0.795168\tvalid_1's auc: 0.738603\n",
      "[16]\ttraining's auc: 0.800733\tvalid_1's auc: 0.735705\n",
      "[17]\ttraining's auc: 0.801868\tvalid_1's auc: 0.732345\n",
      "[18]\ttraining's auc: 0.803391\tvalid_1's auc: 0.731094\n",
      "[19]\ttraining's auc: 0.805331\tvalid_1's auc: 0.733663\n",
      "[20]\ttraining's auc: 0.805606\tvalid_1's auc: 0.731686\n",
      "[21]\ttraining's auc: 0.806311\tvalid_1's auc: 0.734321\n",
      "[22]\ttraining's auc: 0.807521\tvalid_1's auc: 0.735903\n",
      "[23]\ttraining's auc: 0.809507\tvalid_1's auc: 0.734453\n",
      "[24]\ttraining's auc: 0.809603\tvalid_1's auc: 0.732872\n",
      "[25]\ttraining's auc: 0.810876\tvalid_1's auc: 0.735244\n",
      "[26]\ttraining's auc: 0.811626\tvalid_1's auc: 0.732609\n",
      "[27]\ttraining's auc: 0.813362\tvalid_1's auc: 0.732213\n",
      "[28]\ttraining's auc: 0.813667\tvalid_1's auc: 0.734717\n",
      "[29]\ttraining's auc: 0.814221\tvalid_1's auc: 0.730171\n",
      "[30]\ttraining's auc: 0.814213\tvalid_1's auc: 0.734256\n",
      "[31]\ttraining's auc: 0.814764\tvalid_1's auc: 0.731094\n",
      "[32]\ttraining's auc: 0.815456\tvalid_1's auc: 0.726877\n",
      "[33]\ttraining's auc: 0.815807\tvalid_1's auc: 0.726877\n",
      "[34]\ttraining's auc: 0.816491\tvalid_1's auc: 0.727404\n",
      "[35]\ttraining's auc: 0.817467\tvalid_1's auc: 0.73307\n",
      "[36]\ttraining's auc: 0.818268\tvalid_1's auc: 0.732806\n",
      "[37]\ttraining's auc: 0.819282\tvalid_1's auc: 0.72747\n",
      "[38]\ttraining's auc: 0.819908\tvalid_1's auc: 0.729183\n",
      "[39]\ttraining's auc: 0.820909\tvalid_1's auc: 0.727075\n",
      "[40]\ttraining's auc: 0.82194\tvalid_1's auc: 0.731028\n",
      "[41]\ttraining's auc: 0.82244\tvalid_1's auc: 0.729447\n",
      "[42]\ttraining's auc: 0.823383\tvalid_1's auc: 0.729051\n",
      "[43]\ttraining's auc: 0.824126\tvalid_1's auc: 0.726812\n",
      "[44]\ttraining's auc: 0.824685\tvalid_1's auc: 0.731423\n",
      "[45]\ttraining's auc: 0.825286\tvalid_1's auc: 0.731159\n",
      "[46]\ttraining's auc: 0.825611\tvalid_1's auc: 0.731555\n",
      "[47]\ttraining's auc: 0.825928\tvalid_1's auc: 0.731555\n",
      "[48]\ttraining's auc: 0.826037\tvalid_1's auc: 0.731555\n",
      "[49]\ttraining's auc: 0.826604\tvalid_1's auc: 0.731423\n",
      "[50]\ttraining's auc: 0.826838\tvalid_1's auc: 0.730632\n",
      "[51]\ttraining's auc: 0.828481\tvalid_1's auc: 0.734717\n",
      "[52]\ttraining's auc: 0.829658\tvalid_1's auc: 0.734058\n",
      "[53]\ttraining's auc: 0.829349\tvalid_1's auc: 0.73643\n",
      "[54]\ttraining's auc: 0.830325\tvalid_1's auc: 0.735771\n",
      "[55]\ttraining's auc: 0.830909\tvalid_1's auc: 0.731818\n",
      "[56]\ttraining's auc: 0.831911\tvalid_1's auc: 0.72971\n",
      "[57]\ttraining's auc: 0.831911\tvalid_1's auc: 0.729315\n",
      "[58]\ttraining's auc: 0.832228\tvalid_1's auc: 0.732609\n",
      "[59]\ttraining's auc: 0.831936\tvalid_1's auc: 0.732477\n",
      "[60]\ttraining's auc: 0.832653\tvalid_1's auc: 0.732082\n",
      "[61]\ttraining's auc: 0.832929\tvalid_1's auc: 0.729776\n",
      "[62]\ttraining's auc: 0.833229\tvalid_1's auc: 0.730303\n",
      "[63]\ttraining's auc: 0.833638\tvalid_1's auc: 0.72859\n",
      "[64]\ttraining's auc: 0.833972\tvalid_1's auc: 0.728722\n",
      "[65]\ttraining's auc: 0.834723\tvalid_1's auc: 0.727536\n",
      "[66]\ttraining's auc: 0.834823\tvalid_1's auc: 0.729117\n",
      "[67]\ttraining's auc: 0.835048\tvalid_1's auc: 0.728854\n",
      "[68]\ttraining's auc: 0.835549\tvalid_1's auc: 0.725626\n",
      "[69]\ttraining's auc: 0.836216\tvalid_1's auc: 0.729842\n",
      "[70]\ttraining's auc: 0.835966\tvalid_1's auc: 0.724045\n",
      "[71]\ttraining's auc: 0.836241\tvalid_1's auc: 0.722069\n",
      "[72]\ttraining's auc: 0.837318\tvalid_1's auc: 0.725889\n",
      "[73]\ttraining's auc: 0.837685\tvalid_1's auc: 0.726943\n",
      "[74]\ttraining's auc: 0.838411\tvalid_1's auc: 0.726812\n",
      "[75]\ttraining's auc: 0.838628\tvalid_1's auc: 0.726943\n",
      "[76]\ttraining's auc: 0.838761\tvalid_1's auc: 0.723254\n",
      "[77]\ttraining's auc: 0.839195\tvalid_1's auc: 0.719433\n",
      "[78]\ttraining's auc: 0.839479\tvalid_1's auc: 0.720487\n",
      "[79]\ttraining's auc: 0.839896\tvalid_1's auc: 0.721146\n",
      "[80]\ttraining's auc: 0.839696\tvalid_1's auc: 0.71693"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[81]\ttraining's auc: 0.839846\tvalid_1's auc: 0.719433\n",
      "[82]\ttraining's auc: 0.840547\tvalid_1's auc: 0.715217\n",
      "[83]\ttraining's auc: 0.840801\tvalid_1's auc: 0.718841\n",
      "[84]\ttraining's auc: 0.841102\tvalid_1's auc: 0.71581\n",
      "[85]\ttraining's auc: 0.841611\tvalid_1's auc: 0.713966\n",
      "[86]\ttraining's auc: 0.841677\tvalid_1's auc: 0.716601\n",
      "[87]\ttraining's auc: 0.842662\tvalid_1's auc: 0.716469\n",
      "[88]\ttraining's auc: 0.842261\tvalid_1's auc: 0.71726\n",
      "[89]\ttraining's auc: 0.842303\tvalid_1's auc: 0.717128\n",
      "[90]\ttraining's auc: 0.843037\tvalid_1's auc: 0.716206\n",
      "[91]\ttraining's auc: 0.843596\tvalid_1's auc: 0.716601\n",
      "[92]\ttraining's auc: 0.843179\tvalid_1's auc: 0.718182\n",
      "[93]\ttraining's auc: 0.84406\tvalid_1's auc: 0.720553\n",
      "[94]\ttraining's auc: 0.84421\tvalid_1's auc: 0.72029\n",
      "[95]\ttraining's auc: 0.844535\tvalid_1's auc: 0.721212\n",
      "[96]\ttraining's auc: 0.844702\tvalid_1's auc: 0.720553\n",
      "[97]\ttraining's auc: 0.844552\tvalid_1's auc: 0.720685\n",
      "[98]\ttraining's auc: 0.844952\tvalid_1's auc: 0.719368\n",
      "[99]\ttraining's auc: 0.844902\tvalid_1's auc: 0.718314\n",
      "[100]\ttraining's auc: 0.844961\tvalid_1's auc: 0.716469\n",
      "[101]\ttraining's auc: 0.845219\tvalid_1's auc: 0.716864\n",
      "[102]\ttraining's auc: 0.845766\tvalid_1's auc: 0.716469\n",
      "[103]\ttraining's auc: 0.845716\tvalid_1's auc: 0.717918\n",
      "[104]\ttraining's auc: 0.845841\tvalid_1's auc: 0.714756\n",
      "[105]\ttraining's auc: 0.846575\tvalid_1's auc: 0.715942\n",
      "[106]\ttraining's auc: 0.846433\tvalid_1's auc: 0.713439\n",
      "[107]\ttraining's auc: 0.846358\tvalid_1's auc: 0.715942\n",
      "[108]\ttraining's auc: 0.846809\tvalid_1's auc: 0.715547\n",
      "[109]\ttraining's auc: 0.846767\tvalid_1's auc: 0.716733\n",
      "[110]\ttraining's auc: 0.847218\tvalid_1's auc: 0.71726\n",
      "[111]\ttraining's auc: 0.846942\tvalid_1's auc: 0.717787\n",
      "[112]\ttraining's auc: 0.847168\tvalid_1's auc: 0.716206\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.793779\tvalid_1's auc: 0.740382\n",
      "[Accuracy]tr:0.7205056179775281, [Accuracy]va:0.6759776536312849\n",
      "-------------------- result --------------------\n",
      "[[0.         0.72050562 0.67597765]]\n",
      "[cv]  tr: 0.72+-0.00, va: 0.68+-0.00\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "imp, metrics = train_cv(x_train, y_train, id_train, params, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>474.747741</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>371.877959</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col         imp  imp_std\n",
       "0    Fare  474.747741      NaN\n",
       "1  Pclass  371.877959      NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.8244382 , 0.70391061]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
