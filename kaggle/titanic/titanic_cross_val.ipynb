{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベースライン作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, id_train = df[['Pclass', 'Fare']], df[['Survived']], df[['PassengerId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベースライン検証用データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベースライン検証用データ(x_va, y_va)の作成\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train,\n",
    "                                           test_size=0.2,\n",
    "                                           shuffle=True,\n",
    "                                           stratify=y_train,\n",
    "                                           random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスバリデーション(5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tr.loc[] 　ERROR:'Passing list-likes to .loc or [] with any missing labels is no longer supported\n",
    "# -> 存在しないキーに対して.locで参照しようとしているためエラーが発生。x_trはベースライン検証データを分割した際に欠損ができている。\n",
    "# indexを更新したら解決するか\n",
    "x_tr = x_tr.reset_index(drop=True)\n",
    "y_tr = y_tr.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(569, 2) (569, 1)\n",
      "(143, 2) (143, 1)\n",
      "y_tr:0.383, y_tr1:0.383, y_va1:0.385\n",
      "[1]\ttraining's auc: 0.779372\tvalid_1's auc: 0.682645\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.782626\tvalid_1's auc: 0.704649\n",
      "[3]\ttraining's auc: 0.781176\tvalid_1's auc: 0.682541\n",
      "[4]\ttraining's auc: 0.784391\tvalid_1's auc: 0.703822\n",
      "[5]\ttraining's auc: 0.784874\tvalid_1's auc: 0.701136\n",
      "[6]\ttraining's auc: 0.784704\tvalid_1's auc: 0.690806\n",
      "[7]\ttraining's auc: 0.785992\tvalid_1's auc: 0.688946\n",
      "[8]\ttraining's auc: 0.790487\tvalid_1's auc: 0.696798\n",
      "[9]\ttraining's auc: 0.791859\tvalid_1's auc: 0.69938\n",
      "[10]\ttraining's auc: 0.790651\tvalid_1's auc: 0.695868\n",
      "[11]\ttraining's auc: 0.791742\tvalid_1's auc: 0.70062\n",
      "[12]\ttraining's auc: 0.794539\tvalid_1's auc: 0.687913\n",
      "[13]\ttraining's auc: 0.795297\tvalid_1's auc: 0.700826\n",
      "[14]\ttraining's auc: 0.796179\tvalid_1's auc: 0.696281\n",
      "[15]\ttraining's auc: 0.797923\tvalid_1's auc: 0.70155\n",
      "[16]\ttraining's auc: 0.798224\tvalid_1's auc: 0.697624\n",
      "[17]\ttraining's auc: 0.801334\tvalid_1's auc: 0.69969\n",
      "[18]\ttraining's auc: 0.801668\tvalid_1's auc: 0.702789\n",
      "[19]\ttraining's auc: 0.801798\tvalid_1's auc: 0.705269\n",
      "[20]\ttraining's auc: 0.802399\tvalid_1's auc: 0.710847\n",
      "[21]\ttraining's auc: 0.803223\tvalid_1's auc: 0.712087\n",
      "[22]\ttraining's auc: 0.805595\tvalid_1's auc: 0.708471\n",
      "[23]\ttraining's auc: 0.805987\tvalid_1's auc: 0.708471\n",
      "[24]\ttraining's auc: 0.808561\tvalid_1's auc: 0.712397\n",
      "[25]\ttraining's auc: 0.809901\tvalid_1's auc: 0.71157\n",
      "[26]\ttraining's auc: 0.811169\tvalid_1's auc: 0.711364\n",
      "[27]\ttraining's auc: 0.812685\tvalid_1's auc: 0.71405\n",
      "[28]\ttraining's auc: 0.813103\tvalid_1's auc: 0.71281\n",
      "[29]\ttraining's auc: 0.812214\tvalid_1's auc: 0.71157\n",
      "[30]\ttraining's auc: 0.813861\tvalid_1's auc: 0.712397\n",
      "[31]\ttraining's auc: 0.813247\tvalid_1's auc: 0.712397\n",
      "[32]\ttraining's auc: 0.814952\tvalid_1's auc: 0.714773\n",
      "[33]\ttraining's auc: 0.816187\tvalid_1's auc: 0.71312\n",
      "[34]\ttraining's auc: 0.816082\tvalid_1's auc: 0.71436\n",
      "[35]\ttraining's auc: 0.817128\tvalid_1's auc: 0.716529\n",
      "[36]\ttraining's auc: 0.817951\tvalid_1's auc: 0.717149\n",
      "[37]\ttraining's auc: 0.819454\tvalid_1's auc: 0.721488\n",
      "[38]\ttraining's auc: 0.820644\tvalid_1's auc: 0.720661\n",
      "[39]\ttraining's auc: 0.820735\tvalid_1's auc: 0.721901\n",
      "[40]\ttraining's auc: 0.821493\tvalid_1's auc: 0.726653\n",
      "[41]\ttraining's auc: 0.823022\tvalid_1's auc: 0.72624\n",
      "[42]\ttraining's auc: 0.824028\tvalid_1's auc: 0.729959\n",
      "[43]\ttraining's auc: 0.823806\tvalid_1's auc: 0.731198\n",
      "[44]\ttraining's auc: 0.824982\tvalid_1's auc: 0.731818\n",
      "[45]\ttraining's auc: 0.82527\tvalid_1's auc: 0.733471\n",
      "[46]\ttraining's auc: 0.826472\tvalid_1's auc: 0.733058\n",
      "[47]\ttraining's auc: 0.826145\tvalid_1's auc: 0.731405\n",
      "[48]\ttraining's auc: 0.82676\tvalid_1's auc: 0.731198\n",
      "[49]\ttraining's auc: 0.828223\tvalid_1's auc: 0.733678\n",
      "[50]\ttraining's auc: 0.827975\tvalid_1's auc: 0.730579\n",
      "[51]\ttraining's auc: 0.829047\tvalid_1's auc: 0.733884\n",
      "[52]\ttraining's auc: 0.828655\tvalid_1's auc: 0.729545\n",
      "[53]\ttraining's auc: 0.829556\tvalid_1's auc: 0.733884\n",
      "[54]\ttraining's auc: 0.829831\tvalid_1's auc: 0.732645\n",
      "[55]\ttraining's auc: 0.830994\tvalid_1's auc: 0.732645\n",
      "[56]\ttraining's auc: 0.830844\tvalid_1's auc: 0.731405\n",
      "[57]\ttraining's auc: 0.832033\tvalid_1's auc: 0.735331\n",
      "[58]\ttraining's auc: 0.832634\tvalid_1's auc: 0.730992\n",
      "[59]\ttraining's auc: 0.832856\tvalid_1's auc: 0.732438\n",
      "[60]\ttraining's auc: 0.833418\tvalid_1's auc: 0.735124\n",
      "[61]\ttraining's auc: 0.833105\tvalid_1's auc: 0.733884\n",
      "[62]\ttraining's auc: 0.834908\tvalid_1's auc: 0.734298\n",
      "[63]\ttraining's auc: 0.834621\tvalid_1's auc: 0.735331\n",
      "[64]\ttraining's auc: 0.834947\tvalid_1's auc: 0.734091\n",
      "[65]\ttraining's auc: 0.835967\tvalid_1's auc: 0.735331\n",
      "[66]\ttraining's auc: 0.836058\tvalid_1's auc: 0.734504\n",
      "[67]\ttraining's auc: 0.83743\tvalid_1's auc: 0.734091\n",
      "[68]\ttraining's auc: 0.837195\tvalid_1's auc: 0.734504\n",
      "[69]\ttraining's auc: 0.838019\tvalid_1's auc: 0.736157\n",
      "[70]\ttraining's auc: 0.83794\tvalid_1's auc: 0.734504\n",
      "[71]\ttraining's auc: 0.83875\tvalid_1's auc: 0.736157\n",
      "[72]\ttraining's auc: 0.839352\tvalid_1's auc: 0.735537\n",
      "[73]\ttraining's auc: 0.839639\tvalid_1's auc: 0.735744\n",
      "[74]\ttraining's auc: 0.840214\tvalid_1's auc: 0.733884\n",
      "[75]\ttraining's auc: 0.840292\tvalid_1's auc: 0.732851\n",
      "[76]\ttraining's auc: 0.840449\tvalid_1's auc: 0.734504\n",
      "[77]\ttraining's auc: 0.841129\tvalid_1's auc: 0.735331\n",
      "[78]\ttraining's auc: 0.841299\tvalid_1's auc: 0.734711\n",
      "[79]\ttraining's auc: 0.841521\tvalid_1's auc: 0.732231\n",
      "[80]\ttraining's auc: 0.841985\tvalid_1's auc: 0.732438\n",
      "[81]\ttraining's auc: 0.84256\tvalid_1's auc: 0.732645\n",
      "[82]\ttraining's auc: 0.843187\tvalid_1's auc: 0.733678\n",
      "[83]\ttraining's auc: 0.844128\tvalid_1's auc: 0.732851\n",
      "[84]\ttraining's auc: 0.843658\tvalid_1's auc: 0.733678\n",
      "[85]\ttraining's auc: 0.84469\tvalid_1's auc: 0.733471\n",
      "[86]\ttraining's auc: 0.844559\tvalid_1's auc: 0.735331\n",
      "[87]\ttraining's auc: 0.845566\tvalid_1's auc: 0.734091\n",
      "[88]\ttraining's auc: 0.845226\tvalid_1's auc: 0.731818\n",
      "[89]\ttraining's auc: 0.845736\tvalid_1's auc: 0.733678\n",
      "[90]\ttraining's auc: 0.846089\tvalid_1's auc: 0.733058\n",
      "[91]\ttraining's auc: 0.846664\tvalid_1's auc: 0.731818\n",
      "[92]\ttraining's auc: 0.846402\tvalid_1's auc: 0.732645\n",
      "[93]\ttraining's auc: 0.846846\tvalid_1's auc: 0.733058\n",
      "[94]\ttraining's auc: 0.846664\tvalid_1's auc: 0.732438\n",
      "[95]\ttraining's auc: 0.847225\tvalid_1's auc: 0.731405\n",
      "[96]\ttraining's auc: 0.847291\tvalid_1's auc: 0.730165\n",
      "[97]\ttraining's auc: 0.847591\tvalid_1's auc: 0.731818\n",
      "[98]\ttraining's auc: 0.847918\tvalid_1's auc: 0.730579\n",
      "[99]\ttraining's auc: 0.847983\tvalid_1's auc: 0.730992\n",
      "[100]\ttraining's auc: 0.847265\tvalid_1's auc: 0.73595\n",
      "[101]\ttraining's auc: 0.847944\tvalid_1's auc: 0.733678\n",
      "[102]\ttraining's auc: 0.847879\tvalid_1's auc: 0.735124\n",
      "[103]\ttraining's auc: 0.848519\tvalid_1's auc: 0.736777\n",
      "[104]\ttraining's auc: 0.848977\tvalid_1's auc: 0.732231\n",
      "[105]\ttraining's auc: 0.848924\tvalid_1's auc: 0.732851\n",
      "[106]\ttraining's auc: 0.848938\tvalid_1's auc: 0.733884\n",
      "[107]\ttraining's auc: 0.849865\tvalid_1's auc: 0.732645\n",
      "[108]\ttraining's auc: 0.84982\tvalid_1's auc: 0.734504\n",
      "[109]\ttraining's auc: 0.850133\tvalid_1's auc: 0.734711\n",
      "[110]\ttraining's auc: 0.850159\tvalid_1's auc: 0.733884\n",
      "[111]\ttraining's auc: 0.850826\tvalid_1's auc: 0.732645\n",
      "[112]\ttraining's auc: 0.850721\tvalid_1's auc: 0.734504\n",
      "[113]\ttraining's auc: 0.850643\tvalid_1's auc: 0.733781\n",
      "[114]\ttraining's auc: 0.850656\tvalid_1's auc: 0.732128\n",
      "[115]\ttraining's auc: 0.850904\tvalid_1's auc: 0.733781\n",
      "[116]\ttraining's auc: 0.851532\tvalid_1's auc: 0.730269\n",
      "[117]\ttraining's auc: 0.851466\tvalid_1's auc: 0.732541\n",
      "[118]\ttraining's auc: 0.851741\tvalid_1's auc: 0.732128\n",
      "[119]\ttraining's auc: 0.851845\tvalid_1's auc: 0.733368\n",
      "[120]\ttraining's auc: 0.852211\tvalid_1's auc: 0.731715\n",
      "[121]\ttraining's auc: 0.852512\tvalid_1's auc: 0.733781\n",
      "[122]\ttraining's auc: 0.852107\tvalid_1's auc: 0.732541\n",
      "[123]\ttraining's auc: 0.852159\tvalid_1's auc: 0.733781\n",
      "[124]\ttraining's auc: 0.852342\tvalid_1's auc: 0.733368\n",
      "[125]\ttraining's auc: 0.852486\tvalid_1's auc: 0.733574\n",
      "[126]\ttraining's auc: 0.852616\tvalid_1's auc: 0.734401\n",
      "[127]\ttraining's auc: 0.852669\tvalid_1's auc: 0.734814\n",
      "[128]\ttraining's auc: 0.85293\tvalid_1's auc: 0.734194\n",
      "[129]\ttraining's auc: 0.852799\tvalid_1's auc: 0.732748\n",
      "[130]\ttraining's auc: 0.852917\tvalid_1's auc: 0.733368\n",
      "[131]\ttraining's auc: 0.852995\tvalid_1's auc: 0.733574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[132]\ttraining's auc: 0.853636\tvalid_1's auc: 0.734607\n",
      "[133]\ttraining's auc: 0.85374\tvalid_1's auc: 0.734401\n",
      "[134]\ttraining's auc: 0.854002\tvalid_1's auc: 0.733781\n",
      "[135]\ttraining's auc: 0.85408\tvalid_1's auc: 0.734194\n",
      "[136]\ttraining's auc: 0.854302\tvalid_1's auc: 0.734401\n",
      "[137]\ttraining's auc: 0.854459\tvalid_1's auc: 0.734814\n",
      "[138]\ttraining's auc: 0.854433\tvalid_1's auc: 0.733988\n",
      "[139]\ttraining's auc: 0.854734\tvalid_1's auc: 0.734814\n",
      "[140]\ttraining's auc: 0.854786\tvalid_1's auc: 0.734401\n",
      "[141]\ttraining's auc: 0.85489\tvalid_1's auc: 0.734814\n",
      "[142]\ttraining's auc: 0.85472\tvalid_1's auc: 0.73564\n",
      "[143]\ttraining's auc: 0.854825\tvalid_1's auc: 0.734194\n",
      "[144]\ttraining's auc: 0.855113\tvalid_1's auc: 0.73626\n",
      "[145]\ttraining's auc: 0.855008\tvalid_1's auc: 0.735434\n",
      "[146]\ttraining's auc: 0.855165\tvalid_1's auc: 0.733368\n",
      "[147]\ttraining's auc: 0.855361\tvalid_1's auc: 0.734401\n",
      "[148]\ttraining's auc: 0.855269\tvalid_1's auc: 0.734401\n",
      "[149]\ttraining's auc: 0.855557\tvalid_1's auc: 0.73564\n",
      "[150]\ttraining's auc: 0.855962\tvalid_1's auc: 0.736054\n",
      "[151]\ttraining's auc: 0.855792\tvalid_1's auc: 0.73688\n",
      "[152]\ttraining's auc: 0.855557\tvalid_1's auc: 0.735847\n",
      "[153]\ttraining's auc: 0.855897\tvalid_1's auc: 0.736674\n",
      "[154]\ttraining's auc: 0.855884\tvalid_1's auc: 0.736054\n",
      "[155]\ttraining's auc: 0.856276\tvalid_1's auc: 0.736467\n",
      "[156]\ttraining's auc: 0.856106\tvalid_1's auc: 0.735227\n",
      "[157]\ttraining's auc: 0.856485\tvalid_1's auc: 0.735021\n",
      "[158]\ttraining's auc: 0.856341\tvalid_1's auc: 0.733988\n",
      "[159]\ttraining's auc: 0.856576\tvalid_1's auc: 0.735227\n",
      "[160]\ttraining's auc: 0.856367\tvalid_1's auc: 0.733988\n",
      "[161]\ttraining's auc: 0.856798\tvalid_1's auc: 0.733988\n",
      "[162]\ttraining's auc: 0.856733\tvalid_1's auc: 0.734607\n",
      "[163]\ttraining's auc: 0.857047\tvalid_1's auc: 0.738326\n",
      "[164]\ttraining's auc: 0.857086\tvalid_1's auc: 0.737293\n",
      "[165]\ttraining's auc: 0.857269\tvalid_1's auc: 0.737707\n",
      "[166]\ttraining's auc: 0.8577\tvalid_1's auc: 0.738946\n",
      "[167]\ttraining's auc: 0.856955\tvalid_1's auc: 0.735434\n",
      "[168]\ttraining's auc: 0.857831\tvalid_1's auc: 0.73626\n",
      "[169]\ttraining's auc: 0.858223\tvalid_1's auc: 0.740599\n",
      "[170]\ttraining's auc: 0.858367\tvalid_1's auc: 0.740186\n",
      "[171]\ttraining's auc: 0.858314\tvalid_1's auc: 0.739773\n",
      "[172]\ttraining's auc: 0.858589\tvalid_1's auc: 0.740186\n",
      "[173]\ttraining's auc: 0.858589\tvalid_1's auc: 0.740806\n",
      "[174]\ttraining's auc: 0.858863\tvalid_1's auc: 0.741839\n",
      "[175]\ttraining's auc: 0.858759\tvalid_1's auc: 0.740393\n",
      "[176]\ttraining's auc: 0.859099\tvalid_1's auc: 0.741219\n",
      "[177]\ttraining's auc: 0.858942\tvalid_1's auc: 0.739773\n",
      "[178]\ttraining's auc: 0.858942\tvalid_1's auc: 0.741219\n",
      "[179]\ttraining's auc: 0.859177\tvalid_1's auc: 0.739773\n",
      "[180]\ttraining's auc: 0.859138\tvalid_1's auc: 0.739773\n",
      "[181]\ttraining's auc: 0.859125\tvalid_1's auc: 0.740393\n",
      "[182]\ttraining's auc: 0.859386\tvalid_1's auc: 0.740186\n",
      "[183]\ttraining's auc: 0.859451\tvalid_1's auc: 0.742665\n",
      "[184]\ttraining's auc: 0.859399\tvalid_1's auc: 0.742665\n",
      "[185]\ttraining's auc: 0.859451\tvalid_1's auc: 0.742252\n",
      "[186]\ttraining's auc: 0.859739\tvalid_1's auc: 0.742459\n",
      "[187]\ttraining's auc: 0.859987\tvalid_1's auc: 0.742459\n",
      "[188]\ttraining's auc: 0.859778\tvalid_1's auc: 0.742045\n",
      "[189]\ttraining's auc: 0.859896\tvalid_1's auc: 0.743285\n",
      "[190]\ttraining's auc: 0.859948\tvalid_1's auc: 0.743698\n",
      "[191]\ttraining's auc: 0.860144\tvalid_1's auc: 0.742872\n",
      "[192]\ttraining's auc: 0.860249\tvalid_1's auc: 0.742459\n",
      "[193]\ttraining's auc: 0.860111\tvalid_1's auc: 0.741736\n",
      "[194]\ttraining's auc: 0.86036\tvalid_1's auc: 0.742355\n",
      "[195]\ttraining's auc: 0.860216\tvalid_1's auc: 0.741942\n",
      "[196]\ttraining's auc: 0.86032\tvalid_1's auc: 0.743182\n",
      "[197]\ttraining's auc: 0.860268\tvalid_1's auc: 0.742149\n",
      "[198]\ttraining's auc: 0.860281\tvalid_1's auc: 0.743595\n",
      "[199]\ttraining's auc: 0.860438\tvalid_1's auc: 0.742562\n",
      "[200]\ttraining's auc: 0.860948\tvalid_1's auc: 0.744008\n",
      "[201]\ttraining's auc: 0.860634\tvalid_1's auc: 0.743182\n",
      "[202]\ttraining's auc: 0.860935\tvalid_1's auc: 0.745248\n",
      "[203]\ttraining's auc: 0.86066\tvalid_1's auc: 0.744215\n",
      "[204]\ttraining's auc: 0.861105\tvalid_1's auc: 0.745248\n",
      "[205]\ttraining's auc: 0.861196\tvalid_1's auc: 0.745248\n",
      "[206]\ttraining's auc: 0.861288\tvalid_1's auc: 0.745248\n",
      "[207]\ttraining's auc: 0.861353\tvalid_1's auc: 0.745041\n",
      "[208]\ttraining's auc: 0.861379\tvalid_1's auc: 0.745248\n",
      "[209]\ttraining's auc: 0.861418\tvalid_1's auc: 0.745248\n",
      "[210]\ttraining's auc: 0.861418\tvalid_1's auc: 0.743595\n",
      "[211]\ttraining's auc: 0.861484\tvalid_1's auc: 0.743802\n",
      "[212]\ttraining's auc: 0.861523\tvalid_1's auc: 0.743595\n",
      "[213]\ttraining's auc: 0.861601\tvalid_1's auc: 0.743802\n",
      "[214]\ttraining's auc: 0.861784\tvalid_1's auc: 0.742769\n",
      "[215]\ttraining's auc: 0.861784\tvalid_1's auc: 0.743182\n",
      "[216]\ttraining's auc: 0.861889\tvalid_1's auc: 0.744008\n",
      "[217]\ttraining's auc: 0.861941\tvalid_1's auc: 0.745868\n",
      "[218]\ttraining's auc: 0.862111\tvalid_1's auc: 0.743802\n",
      "[219]\ttraining's auc: 0.862137\tvalid_1's auc: 0.744008\n",
      "[220]\ttraining's auc: 0.862059\tvalid_1's auc: 0.742769\n",
      "[221]\ttraining's auc: 0.862163\tvalid_1's auc: 0.743182\n",
      "[222]\ttraining's auc: 0.862137\tvalid_1's auc: 0.743595\n",
      "[223]\ttraining's auc: 0.862032\tvalid_1's auc: 0.744215\n",
      "[224]\ttraining's auc: 0.862019\tvalid_1's auc: 0.745248\n",
      "[225]\ttraining's auc: 0.862268\tvalid_1's auc: 0.743595\n",
      "[226]\ttraining's auc: 0.862163\tvalid_1's auc: 0.742355\n",
      "[227]\ttraining's auc: 0.862346\tvalid_1's auc: 0.742149\n",
      "[228]\ttraining's auc: 0.86249\tvalid_1's auc: 0.743182\n",
      "[229]\ttraining's auc: 0.862581\tvalid_1's auc: 0.742562\n",
      "[230]\ttraining's auc: 0.862634\tvalid_1's auc: 0.742769\n",
      "[231]\ttraining's auc: 0.86266\tvalid_1's auc: 0.742562\n",
      "[232]\ttraining's auc: 0.862712\tvalid_1's auc: 0.743182\n",
      "[233]\ttraining's auc: 0.862817\tvalid_1's auc: 0.741736\n",
      "[234]\ttraining's auc: 0.862804\tvalid_1's auc: 0.742769\n",
      "[235]\ttraining's auc: 0.862895\tvalid_1's auc: 0.742562\n",
      "[236]\ttraining's auc: 0.863065\tvalid_1's auc: 0.742562\n",
      "[237]\ttraining's auc: 0.863091\tvalid_1's auc: 0.742975\n",
      "[238]\ttraining's auc: 0.863104\tvalid_1's auc: 0.743802\n",
      "[239]\ttraining's auc: 0.863117\tvalid_1's auc: 0.742769\n",
      "[240]\ttraining's auc: 0.863052\tvalid_1's auc: 0.742975\n",
      "[241]\ttraining's auc: 0.863222\tvalid_1's auc: 0.742975\n",
      "[242]\ttraining's auc: 0.863274\tvalid_1's auc: 0.741529\n",
      "[243]\ttraining's auc: 0.863287\tvalid_1's auc: 0.742562\n",
      "[244]\ttraining's auc: 0.8633\tvalid_1's auc: 0.742149\n",
      "[245]\ttraining's auc: 0.863352\tvalid_1's auc: 0.741942\n",
      "[246]\ttraining's auc: 0.863588\tvalid_1's auc: 0.743182\n",
      "[247]\ttraining's auc: 0.863457\tvalid_1's auc: 0.743182\n",
      "[248]\ttraining's auc: 0.863509\tvalid_1's auc: 0.742975\n",
      "[249]\ttraining's auc: 0.863509\tvalid_1's auc: 0.741942\n",
      "[250]\ttraining's auc: 0.863522\tvalid_1's auc: 0.742149\n",
      "[251]\ttraining's auc: 0.86398\tvalid_1's auc: 0.741942\n",
      "[252]\ttraining's auc: 0.863849\tvalid_1's auc: 0.741322\n",
      "[253]\ttraining's auc: 0.863927\tvalid_1's auc: 0.741116\n",
      "[254]\ttraining's auc: 0.863967\tvalid_1's auc: 0.741116\n",
      "[255]\ttraining's auc: 0.864019\tvalid_1's auc: 0.741322\n",
      "[256]\ttraining's auc: 0.86411\tvalid_1's auc: 0.740909\n",
      "[257]\ttraining's auc: 0.86411\tvalid_1's auc: 0.740909\n",
      "[258]\ttraining's auc: 0.864058\tvalid_1's auc: 0.741116\n",
      "[259]\ttraining's auc: 0.864084\tvalid_1's auc: 0.741116\n",
      "[260]\ttraining's auc: 0.864542\tvalid_1's auc: 0.740496\n",
      "[261]\ttraining's auc: 0.864516\tvalid_1's auc: 0.740909\n",
      "[262]\ttraining's auc: 0.864424\tvalid_1's auc: 0.740289\n",
      "[263]\ttraining's auc: 0.864398\tvalid_1's auc: 0.740909\n",
      "[264]\ttraining's auc: 0.864594\tvalid_1's auc: 0.741116\n",
      "[265]\ttraining's auc: 0.864516\tvalid_1's auc: 0.741322\n",
      "[266]\ttraining's auc: 0.864672\tvalid_1's auc: 0.740496\n",
      "[267]\ttraining's auc: 0.864699\tvalid_1's auc: 0.741322\n",
      "[268]\ttraining's auc: 0.864764\tvalid_1's auc: 0.739876\n",
      "[269]\ttraining's auc: 0.864712\tvalid_1's auc: 0.740496\n",
      "[270]\ttraining's auc: 0.864842\tvalid_1's auc: 0.740083\n",
      "[271]\ttraining's auc: 0.864725\tvalid_1's auc: 0.740702\n",
      "[272]\ttraining's auc: 0.865025\tvalid_1's auc: 0.739876\n",
      "[273]\ttraining's auc: 0.864895\tvalid_1's auc: 0.740289\n",
      "[274]\ttraining's auc: 0.865077\tvalid_1's auc: 0.741116\n",
      "[275]\ttraining's auc: 0.865006\tvalid_1's auc: 0.740599\n",
      "[276]\ttraining's auc: 0.864927\tvalid_1's auc: 0.740393\n",
      "[277]\ttraining's auc: 0.865097\tvalid_1's auc: 0.740186\n",
      "[278]\ttraining's auc: 0.864953\tvalid_1's auc: 0.740186\n",
      "[279]\ttraining's auc: 0.864849\tvalid_1's auc: 0.739979\n",
      "[280]\ttraining's auc: 0.865123\tvalid_1's auc: 0.740393\n",
      "[281]\ttraining's auc: 0.865084\tvalid_1's auc: 0.740393\n",
      "[282]\ttraining's auc: 0.865084\tvalid_1's auc: 0.740599\n",
      "[283]\ttraining's auc: 0.865097\tvalid_1's auc: 0.740393\n",
      "[284]\ttraining's auc: 0.865123\tvalid_1's auc: 0.740599\n",
      "[285]\ttraining's auc: 0.865332\tvalid_1's auc: 0.740393\n",
      "[286]\ttraining's auc: 0.865215\tvalid_1's auc: 0.739566\n",
      "[287]\ttraining's auc: 0.865293\tvalid_1's auc: 0.738946\n",
      "[288]\ttraining's auc: 0.865372\tvalid_1's auc: 0.739979\n",
      "[289]\ttraining's auc: 0.86528\tvalid_1's auc: 0.73936\n",
      "[290]\ttraining's auc: 0.865228\tvalid_1's auc: 0.73936\n",
      "[291]\ttraining's auc: 0.865306\tvalid_1's auc: 0.73936\n",
      "[292]\ttraining's auc: 0.865345\tvalid_1's auc: 0.73874\n",
      "[293]\ttraining's auc: 0.865293\tvalid_1's auc: 0.73874\n",
      "[294]\ttraining's auc: 0.865476\tvalid_1's auc: 0.73936\n",
      "[295]\ttraining's auc: 0.865777\tvalid_1's auc: 0.739979\n",
      "[296]\ttraining's auc: 0.865842\tvalid_1's auc: 0.740393\n",
      "[297]\ttraining's auc: 0.865881\tvalid_1's auc: 0.739979\n",
      "[298]\ttraining's auc: 0.865973\tvalid_1's auc: 0.740393\n",
      "[299]\ttraining's auc: 0.865934\tvalid_1's auc: 0.73936\n",
      "[300]\ttraining's auc: 0.865973\tvalid_1's auc: 0.739979\n",
      "[301]\ttraining's auc: 0.866025\tvalid_1's auc: 0.740393\n",
      "[302]\ttraining's auc: 0.866247\tvalid_1's auc: 0.740599\n",
      "[303]\ttraining's auc: 0.866195\tvalid_1's auc: 0.739773\n",
      "[304]\ttraining's auc: 0.866299\tvalid_1's auc: 0.740599\n",
      "[305]\ttraining's auc: 0.866352\tvalid_1's auc: 0.740599\n",
      "[306]\ttraining's auc: 0.866326\tvalid_1's auc: 0.740599\n",
      "[307]\ttraining's auc: 0.866326\tvalid_1's auc: 0.739979\n",
      "[308]\ttraining's auc: 0.866417\tvalid_1's auc: 0.740599\n",
      "[309]\ttraining's auc: 0.866326\tvalid_1's auc: 0.739979\n",
      "[310]\ttraining's auc: 0.866378\tvalid_1's auc: 0.740599\n",
      "[311]\ttraining's auc: 0.866509\tvalid_1's auc: 0.740599\n",
      "[312]\ttraining's auc: 0.866495\tvalid_1's auc: 0.739979\n",
      "[313]\ttraining's auc: 0.866535\tvalid_1's auc: 0.739979\n",
      "[314]\ttraining's auc: 0.866522\tvalid_1's auc: 0.739979\n",
      "[315]\ttraining's auc: 0.866535\tvalid_1's auc: 0.739773\n",
      "[316]\ttraining's auc: 0.866561\tvalid_1's auc: 0.739979\n",
      "[317]\ttraining's auc: 0.866548\tvalid_1's auc: 0.741012\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's auc: 0.861941\tvalid_1's auc: 0.745868\n",
      "[検証用データ]acc:0.6923\n",
      "[ベースライン検証用データ]acc:0.6983\n",
      "-------------------- 1 --------------------\n",
      "(569, 2) (569, 1)\n",
      "(143, 2) (143, 1)\n",
      "y_tr:0.383, y_tr1:0.383, y_va1:0.385\n",
      "[1]\ttraining's auc: 0.755482\tvalid_1's auc: 0.741529\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.755482\tvalid_1's auc: 0.741529\n",
      "[3]\ttraining's auc: 0.756959\tvalid_1's auc: 0.747624\n",
      "[4]\ttraining's auc: 0.75858\tvalid_1's auc: 0.745868\n",
      "[5]\ttraining's auc: 0.763317\tvalid_1's auc: 0.746901\n",
      "[6]\ttraining's auc: 0.764663\tvalid_1's auc: 0.750826\n",
      "[7]\ttraining's auc: 0.766584\tvalid_1's auc: 0.744421\n",
      "[8]\ttraining's auc: 0.764637\tvalid_1's auc: 0.746074\n",
      "[9]\ttraining's auc: 0.765768\tvalid_1's auc: 0.746384\n",
      "[10]\ttraining's auc: 0.766695\tvalid_1's auc: 0.746384\n",
      "[11]\ttraining's auc: 0.774099\tvalid_1's auc: 0.74876\n",
      "[12]\ttraining's auc: 0.777654\tvalid_1's auc: 0.758781\n",
      "[13]\ttraining's auc: 0.780555\tvalid_1's auc: 0.760331\n",
      "[14]\ttraining's auc: 0.781646\tvalid_1's auc: 0.759711\n",
      "[15]\ttraining's auc: 0.785332\tvalid_1's auc: 0.758058\n",
      "[16]\ttraining's auc: 0.788089\tvalid_1's auc: 0.760021\n",
      "[17]\ttraining's auc: 0.78984\tvalid_1's auc: 0.756508\n",
      "[18]\ttraining's auc: 0.790664\tvalid_1's auc: 0.758368\n",
      "[19]\ttraining's auc: 0.792872\tvalid_1's auc: 0.755372\n",
      "[20]\ttraining's auc: 0.792951\tvalid_1's auc: 0.756612\n",
      "[21]\ttraining's auc: 0.792389\tvalid_1's auc: 0.754959\n",
      "[22]\ttraining's auc: 0.793225\tvalid_1's auc: 0.755992\n",
      "[23]\ttraining's auc: 0.794179\tvalid_1's auc: 0.753719\n",
      "[24]\ttraining's auc: 0.794976\tvalid_1's auc: 0.752376\n",
      "[25]\ttraining's auc: 0.796447\tvalid_1's auc: 0.75093\n",
      "[26]\ttraining's auc: 0.796545\tvalid_1's auc: 0.749277\n",
      "[27]\ttraining's auc: 0.796924\tvalid_1's auc: 0.751136\n",
      "[28]\ttraining's auc: 0.797407\tvalid_1's auc: 0.74969\n",
      "[29]\ttraining's auc: 0.799361\tvalid_1's auc: 0.752273\n",
      "[30]\ttraining's auc: 0.800616\tvalid_1's auc: 0.74876\n",
      "[31]\ttraining's auc: 0.80074\tvalid_1's auc: 0.751963\n",
      "[32]\ttraining's auc: 0.801308\tvalid_1's auc: 0.752789\n",
      "[33]\ttraining's auc: 0.803092\tvalid_1's auc: 0.74845\n",
      "[34]\ttraining's auc: 0.803987\tvalid_1's auc: 0.749483\n",
      "[35]\ttraining's auc: 0.804419\tvalid_1's auc: 0.74969\n",
      "[36]\ttraining's auc: 0.805425\tvalid_1's auc: 0.75031\n",
      "[37]\ttraining's auc: 0.806954\tvalid_1's auc: 0.749277\n",
      "[38]\ttraining's auc: 0.807085\tvalid_1's auc: 0.75155\n",
      "[39]\ttraining's auc: 0.808248\tvalid_1's auc: 0.744731\n",
      "[40]\ttraining's auc: 0.807594\tvalid_1's auc: 0.747831\n",
      "[41]\ttraining's auc: 0.809163\tvalid_1's auc: 0.746384\n",
      "[42]\ttraining's auc: 0.80962\tvalid_1's auc: 0.749483\n",
      "[43]\ttraining's auc: 0.809894\tvalid_1's auc: 0.749897\n",
      "[44]\ttraining's auc: 0.810509\tvalid_1's auc: 0.74845\n",
      "[45]\ttraining's auc: 0.811175\tvalid_1's auc: 0.747624\n",
      "[46]\ttraining's auc: 0.811515\tvalid_1's auc: 0.74845\n",
      "[47]\ttraining's auc: 0.811855\tvalid_1's auc: 0.74845\n",
      "[48]\ttraining's auc: 0.811567\tvalid_1's auc: 0.747831\n",
      "[49]\ttraining's auc: 0.81209\tvalid_1's auc: 0.747417\n",
      "[50]\ttraining's auc: 0.812704\tvalid_1's auc: 0.748037\n",
      "[51]\ttraining's auc: 0.813292\tvalid_1's auc: 0.750723\n",
      "[52]\ttraining's auc: 0.813933\tvalid_1's auc: 0.747624\n",
      "[53]\ttraining's auc: 0.814482\tvalid_1's auc: 0.745764\n",
      "[54]\ttraining's auc: 0.81524\tvalid_1's auc: 0.744938\n",
      "[55]\ttraining's auc: 0.815135\tvalid_1's auc: 0.745764\n",
      "[56]\ttraining's auc: 0.815697\tvalid_1's auc: 0.744318\n",
      "[57]\ttraining's auc: 0.814978\tvalid_1's auc: 0.743079\n",
      "[58]\ttraining's auc: 0.815226\tvalid_1's auc: 0.743905\n",
      "[59]\ttraining's auc: 0.815553\tvalid_1's auc: 0.748657\n",
      "[60]\ttraining's auc: 0.815782\tvalid_1's auc: 0.747934\n",
      "[61]\ttraining's auc: 0.816082\tvalid_1's auc: 0.745248\n",
      "[62]\ttraining's auc: 0.817102\tvalid_1's auc: 0.746901\n",
      "[63]\ttraining's auc: 0.816971\tvalid_1's auc: 0.746901\n",
      "[64]\ttraining's auc: 0.817396\tvalid_1's auc: 0.747314\n",
      "[65]\ttraining's auc: 0.816788\tvalid_1's auc: 0.746901\n",
      "[66]\ttraining's auc: 0.818265\tvalid_1's auc: 0.745455\n",
      "[67]\ttraining's auc: 0.817703\tvalid_1's auc: 0.745248\n",
      "[68]\ttraining's auc: 0.818108\tvalid_1's auc: 0.745455\n",
      "[69]\ttraining's auc: 0.817899\tvalid_1's auc: 0.746488\n",
      "[70]\ttraining's auc: 0.818461\tvalid_1's auc: 0.746901\n",
      "[71]\ttraining's auc: 0.818814\tvalid_1's auc: 0.746694\n",
      "[72]\ttraining's auc: 0.819493\tvalid_1's auc: 0.743802\n",
      "[73]\ttraining's auc: 0.819454\tvalid_1's auc: 0.743182\n",
      "[74]\ttraining's auc: 0.820251\tvalid_1's auc: 0.739669\n",
      "[75]\ttraining's auc: 0.820578\tvalid_1's auc: 0.740909\n",
      "[76]\ttraining's auc: 0.820578\tvalid_1's auc: 0.742562\n",
      "[77]\ttraining's auc: 0.820559\tvalid_1's auc: 0.738326\n",
      "[78]\ttraining's auc: 0.820846\tvalid_1's auc: 0.739566\n",
      "[79]\ttraining's auc: 0.82116\tvalid_1's auc: 0.73936\n",
      "[80]\ttraining's auc: 0.821709\tvalid_1's auc: 0.741012\n",
      "[81]\ttraining's auc: 0.822597\tvalid_1's auc: 0.741839\n",
      "[82]\ttraining's auc: 0.823225\tvalid_1's auc: 0.739153\n",
      "[83]\ttraining's auc: 0.823943\tvalid_1's auc: 0.738533\n",
      "[84]\ttraining's auc: 0.824087\tvalid_1's auc: 0.740186\n",
      "[85]\ttraining's auc: 0.823865\tvalid_1's auc: 0.740393\n",
      "[86]\ttraining's auc: 0.824244\tvalid_1's auc: 0.737707\n",
      "[87]\ttraining's auc: 0.824714\tvalid_1's auc: 0.740393\n",
      "[88]\ttraining's auc: 0.825041\tvalid_1's auc: 0.736674\n",
      "[89]\ttraining's auc: 0.825799\tvalid_1's auc: 0.737087\n",
      "[90]\ttraining's auc: 0.825289\tvalid_1's auc: 0.736467\n",
      "[91]\ttraining's auc: 0.826021\tvalid_1's auc: 0.735021\n",
      "[92]\ttraining's auc: 0.826008\tvalid_1's auc: 0.736467\n",
      "[93]\ttraining's auc: 0.826923\tvalid_1's auc: 0.738946\n",
      "[94]\ttraining's auc: 0.827158\tvalid_1's auc: 0.735434\n",
      "[95]\ttraining's auc: 0.826871\tvalid_1's auc: 0.733368\n",
      "[96]\ttraining's auc: 0.827694\tvalid_1's auc: 0.73564\n",
      "[97]\ttraining's auc: 0.827485\tvalid_1's auc: 0.735227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[98]\ttraining's auc: 0.827681\tvalid_1's auc: 0.73688\n",
      "[99]\ttraining's auc: 0.828282\tvalid_1's auc: 0.733988\n",
      "[100]\ttraining's auc: 0.827929\tvalid_1's auc: 0.732955\n",
      "[101]\ttraining's auc: 0.82857\tvalid_1's auc: 0.735227\n",
      "[102]\ttraining's auc: 0.82904\tvalid_1's auc: 0.735434\n",
      "[103]\ttraining's auc: 0.82938\tvalid_1's auc: 0.734607\n",
      "[104]\ttraining's auc: 0.829798\tvalid_1's auc: 0.73688\n",
      "[105]\ttraining's auc: 0.829654\tvalid_1's auc: 0.737707\n",
      "[106]\ttraining's auc: 0.829968\tvalid_1's auc: 0.737293\n",
      "[107]\ttraining's auc: 0.829916\tvalid_1's auc: 0.735434\n",
      "[108]\ttraining's auc: 0.830726\tvalid_1's auc: 0.738326\n",
      "[109]\ttraining's auc: 0.831079\tvalid_1's auc: 0.738326\n",
      "[110]\ttraining's auc: 0.831471\tvalid_1's auc: 0.739773\n",
      "[111]\ttraining's auc: 0.831732\tvalid_1's auc: 0.73936\n",
      "[112]\ttraining's auc: 0.832164\tvalid_1's auc: 0.738326\n",
      "[113]\ttraining's auc: 0.832138\tvalid_1's auc: 0.739566\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.780555\tvalid_1's auc: 0.760331\n",
      "[検証用データ]acc:0.7063\n",
      "[ベースライン検証用データ]acc:0.7095\n",
      "-------------------- 2 --------------------\n",
      "(570, 2) (570, 1)\n",
      "(142, 2) (142, 1)\n",
      "y_tr:0.383, y_tr1:0.384, y_va1:0.380\n",
      "[1]\ttraining's auc: 0.762043\tvalid_1's auc: 0.699916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.764443\tvalid_1's auc: 0.697811\n",
      "[3]\ttraining's auc: 0.763377\tvalid_1's auc: 0.703283\n",
      "[4]\ttraining's auc: 0.764606\tvalid_1's auc: 0.697285\n",
      "[5]\ttraining's auc: 0.768203\tvalid_1's auc: 0.697391\n",
      "[6]\ttraining's auc: 0.768535\tvalid_1's auc: 0.701073\n",
      "[7]\ttraining's auc: 0.772548\tvalid_1's auc: 0.700021\n",
      "[8]\ttraining's auc: 0.776516\tvalid_1's auc: 0.70686\n",
      "[9]\ttraining's auc: 0.779664\tvalid_1's auc: 0.718013\n",
      "[10]\ttraining's auc: 0.783151\tvalid_1's auc: 0.713805\n",
      "[11]\ttraining's auc: 0.785557\tvalid_1's auc: 0.727694\n",
      "[12]\ttraining's auc: 0.790592\tvalid_1's auc: 0.732008\n",
      "[13]\ttraining's auc: 0.792725\tvalid_1's auc: 0.722538\n",
      "[14]\ttraining's auc: 0.796101\tvalid_1's auc: 0.727062\n",
      "[15]\ttraining's auc: 0.796739\tvalid_1's auc: 0.727483\n",
      "[16]\ttraining's auc: 0.798781\tvalid_1's auc: 0.736742\n",
      "[17]\ttraining's auc: 0.797383\tvalid_1's auc: 0.725694\n",
      "[18]\ttraining's auc: 0.798775\tvalid_1's auc: 0.723169\n",
      "[19]\ttraining's auc: 0.800271\tvalid_1's auc: 0.722854\n",
      "[20]\ttraining's auc: 0.802137\tvalid_1's auc: 0.7258\n",
      "[21]\ttraining's auc: 0.802866\tvalid_1's auc: 0.726641\n",
      "[22]\ttraining's auc: 0.802267\tvalid_1's auc: 0.723485\n",
      "[23]\ttraining's auc: 0.804102\tvalid_1's auc: 0.724116\n",
      "[24]\ttraining's auc: 0.806912\tvalid_1's auc: 0.729903\n",
      "[25]\ttraining's auc: 0.8066\tvalid_1's auc: 0.728851\n",
      "[26]\ttraining's auc: 0.806925\tvalid_1's auc: 0.727588\n",
      "[27]\ttraining's auc: 0.807601\tvalid_1's auc: 0.729061\n",
      "[28]\ttraining's auc: 0.808278\tvalid_1's auc: 0.732849\n",
      "[29]\ttraining's auc: 0.810561\tvalid_1's auc: 0.736532\n",
      "[30]\ttraining's auc: 0.810145\tvalid_1's auc: 0.735059\n",
      "[31]\ttraining's auc: 0.812473\tvalid_1's auc: 0.738215\n",
      "[32]\ttraining's auc: 0.812902\tvalid_1's auc: 0.737374\n",
      "[33]\ttraining's auc: 0.812369\tvalid_1's auc: 0.734848\n",
      "[34]\ttraining's auc: 0.81328\tvalid_1's auc: 0.736111\n",
      "[35]\ttraining's auc: 0.813969\tvalid_1's auc: 0.737584\n",
      "[36]\ttraining's auc: 0.814555\tvalid_1's auc: 0.737584\n",
      "[37]\ttraining's auc: 0.816181\tvalid_1's auc: 0.739268\n",
      "[38]\ttraining's auc: 0.81661\tvalid_1's auc: 0.740636\n",
      "[39]\ttraining's auc: 0.817534\tvalid_1's auc: 0.741688\n",
      "[40]\ttraining's auc: 0.819472\tvalid_1's auc: 0.742109\n",
      "[41]\ttraining's auc: 0.81929\tvalid_1's auc: 0.743371\n",
      "[42]\ttraining's auc: 0.821449\tvalid_1's auc: 0.74274\n",
      "[43]\ttraining's auc: 0.822087\tvalid_1's auc: 0.741898\n",
      "[44]\ttraining's auc: 0.820812\tvalid_1's auc: 0.741267\n",
      "[45]\ttraining's auc: 0.822113\tvalid_1's auc: 0.742529\n",
      "[46]\ttraining's auc: 0.822516\tvalid_1's auc: 0.743687\n",
      "[47]\ttraining's auc: 0.822295\tvalid_1's auc: 0.742635\n",
      "[48]\ttraining's auc: 0.823414\tvalid_1's auc: 0.742214\n",
      "[49]\ttraining's auc: 0.825404\tvalid_1's auc: 0.741372\n",
      "[50]\ttraining's auc: 0.824767\tvalid_1's auc: 0.74053\n",
      "[51]\ttraining's auc: 0.824741\tvalid_1's auc: 0.738426\n",
      "[52]\ttraining's auc: 0.8253\tvalid_1's auc: 0.741372\n",
      "[53]\ttraining's auc: 0.826276\tvalid_1's auc: 0.739899\n",
      "[54]\ttraining's auc: 0.827024\tvalid_1's auc: 0.741162\n",
      "[55]\ttraining's auc: 0.828598\tvalid_1's auc: 0.740951\n",
      "[56]\ttraining's auc: 0.828832\tvalid_1's auc: 0.743897\n",
      "[57]\ttraining's auc: 0.828351\tvalid_1's auc: 0.743056\n",
      "[58]\ttraining's auc: 0.829353\tvalid_1's auc: 0.741793\n",
      "[59]\ttraining's auc: 0.829522\tvalid_1's auc: 0.743266\n",
      "[60]\ttraining's auc: 0.830432\tvalid_1's auc: 0.742845\n",
      "[61]\ttraining's auc: 0.831629\tvalid_1's auc: 0.746843\n",
      "[62]\ttraining's auc: 0.831486\tvalid_1's auc: 0.744108\n",
      "[63]\ttraining's auc: 0.831857\tvalid_1's auc: 0.743897\n",
      "[64]\ttraining's auc: 0.831779\tvalid_1's auc: 0.74537\n",
      "[65]\ttraining's auc: 0.832078\tvalid_1's auc: 0.74537\n",
      "[66]\ttraining's auc: 0.832325\tvalid_1's auc: 0.744003\n",
      "[67]\ttraining's auc: 0.832403\tvalid_1's auc: 0.745686\n",
      "[68]\ttraining's auc: 0.833249\tvalid_1's auc: 0.746738\n",
      "[69]\ttraining's auc: 0.833418\tvalid_1's auc: 0.745265\n",
      "[70]\ttraining's auc: 0.833197\tvalid_1's auc: 0.745055\n",
      "[71]\ttraining's auc: 0.834914\tvalid_1's auc: 0.745686\n",
      "[72]\ttraining's auc: 0.835148\tvalid_1's auc: 0.745265\n",
      "[73]\ttraining's auc: 0.834927\tvalid_1's auc: 0.746317\n",
      "[74]\ttraining's auc: 0.83533\tvalid_1's auc: 0.746738\n",
      "[75]\ttraining's auc: 0.835434\tvalid_1's auc: 0.748001\n",
      "[76]\ttraining's auc: 0.83589\tvalid_1's auc: 0.74737\n",
      "[77]\ttraining's auc: 0.836358\tvalid_1's auc: 0.74758\n",
      "[78]\ttraining's auc: 0.836137\tvalid_1's auc: 0.746949\n",
      "[79]\ttraining's auc: 0.836124\tvalid_1's auc: 0.74758\n",
      "[80]\ttraining's auc: 0.837132\tvalid_1's auc: 0.747159\n",
      "[81]\ttraining's auc: 0.837015\tvalid_1's auc: 0.746949\n",
      "[82]\ttraining's auc: 0.837691\tvalid_1's auc: 0.746949\n",
      "[83]\ttraining's auc: 0.83734\tvalid_1's auc: 0.74737\n",
      "[84]\ttraining's auc: 0.837795\tvalid_1's auc: 0.746738\n",
      "[85]\ttraining's auc: 0.83803\tvalid_1's auc: 0.746528\n",
      "[86]\ttraining's auc: 0.837939\tvalid_1's auc: 0.746317\n",
      "[87]\ttraining's auc: 0.838017\tvalid_1's auc: 0.746528\n",
      "[88]\ttraining's auc: 0.838511\tvalid_1's auc: 0.746528\n",
      "[89]\ttraining's auc: 0.840762\tvalid_1's auc: 0.746738\n",
      "[90]\ttraining's auc: 0.84097\tvalid_1's auc: 0.746949\n",
      "[91]\ttraining's auc: 0.84067\tvalid_1's auc: 0.746528\n",
      "[92]\ttraining's auc: 0.84123\tvalid_1's auc: 0.747159\n",
      "[93]\ttraining's auc: 0.841854\tvalid_1's auc: 0.746738\n",
      "[94]\ttraining's auc: 0.842596\tvalid_1's auc: 0.746949\n",
      "[95]\ttraining's auc: 0.842622\tvalid_1's auc: 0.746738\n",
      "[96]\ttraining's auc: 0.843181\tvalid_1's auc: 0.746528\n",
      "[97]\ttraining's auc: 0.842648\tvalid_1's auc: 0.746317\n",
      "[98]\ttraining's auc: 0.842323\tvalid_1's auc: 0.745896\n",
      "[99]\ttraining's auc: 0.84309\tvalid_1's auc: 0.745896\n",
      "[100]\ttraining's auc: 0.843155\tvalid_1's auc: 0.745896\n",
      "[101]\ttraining's auc: 0.84365\tvalid_1's auc: 0.745265\n",
      "[102]\ttraining's auc: 0.845003\tvalid_1's auc: 0.74737\n",
      "[103]\ttraining's auc: 0.845627\tvalid_1's auc: 0.74737\n",
      "[104]\ttraining's auc: 0.845686\tvalid_1's auc: 0.747475\n",
      "[105]\ttraining's auc: 0.845289\tvalid_1's auc: 0.747685\n",
      "[106]\ttraining's auc: 0.84564\tvalid_1's auc: 0.748316\n",
      "[107]\ttraining's auc: 0.845822\tvalid_1's auc: 0.747685\n",
      "[108]\ttraining's auc: 0.846329\tvalid_1's auc: 0.748948\n",
      "[109]\ttraining's auc: 0.847123\tvalid_1's auc: 0.746843\n",
      "[110]\ttraining's auc: 0.847058\tvalid_1's auc: 0.747685\n",
      "[111]\ttraining's auc: 0.847019\tvalid_1's auc: 0.747896\n",
      "[112]\ttraining's auc: 0.847136\tvalid_1's auc: 0.747685\n",
      "[113]\ttraining's auc: 0.84711\tvalid_1's auc: 0.746843\n",
      "[114]\ttraining's auc: 0.847123\tvalid_1's auc: 0.747896\n",
      "[115]\ttraining's auc: 0.846889\tvalid_1's auc: 0.747896\n",
      "[116]\ttraining's auc: 0.847266\tvalid_1's auc: 0.747896\n",
      "[117]\ttraining's auc: 0.847396\tvalid_1's auc: 0.748106\n",
      "[118]\ttraining's auc: 0.847344\tvalid_1's auc: 0.747685\n",
      "[119]\ttraining's auc: 0.84737\tvalid_1's auc: 0.747685\n",
      "[120]\ttraining's auc: 0.847331\tvalid_1's auc: 0.747896\n",
      "[121]\ttraining's auc: 0.847995\tvalid_1's auc: 0.749369\n",
      "[122]\ttraining's auc: 0.848034\tvalid_1's auc: 0.749579\n",
      "[123]\ttraining's auc: 0.848515\tvalid_1's auc: 0.749369\n",
      "[124]\ttraining's auc: 0.848567\tvalid_1's auc: 0.751894\n",
      "[125]\ttraining's auc: 0.848587\tvalid_1's auc: 0.74979\n",
      "[126]\ttraining's auc: 0.84873\tvalid_1's auc: 0.749579\n",
      "[127]\ttraining's auc: 0.848587\tvalid_1's auc: 0.750631\n",
      "[128]\ttraining's auc: 0.848834\tvalid_1's auc: 0.751894\n",
      "[129]\ttraining's auc: 0.849484\tvalid_1's auc: 0.753157\n",
      "[130]\ttraining's auc: 0.84925\tvalid_1's auc: 0.753157\n",
      "[131]\ttraining's auc: 0.849484\tvalid_1's auc: 0.74979\n",
      "[132]\ttraining's auc: 0.849458\tvalid_1's auc: 0.75\n",
      "[133]\ttraining's auc: 0.849575\tvalid_1's auc: 0.751473\n",
      "[134]\ttraining's auc: 0.849757\tvalid_1's auc: 0.75021\n",
      "[135]\ttraining's auc: 0.849809\tvalid_1's auc: 0.750631\n",
      "[136]\ttraining's auc: 0.849966\tvalid_1's auc: 0.74979\n",
      "[137]\ttraining's auc: 0.85007\tvalid_1's auc: 0.750842\n",
      "[138]\ttraining's auc: 0.850226\tvalid_1's auc: 0.75\n",
      "[139]\ttraining's auc: 0.850083\tvalid_1's auc: 0.751473\n",
      "[140]\ttraining's auc: 0.850577\tvalid_1's auc: 0.751473\n",
      "[141]\ttraining's auc: 0.850759\tvalid_1's auc: 0.751684\n",
      "[142]\ttraining's auc: 0.85072\tvalid_1's auc: 0.754209\n",
      "[143]\ttraining's auc: 0.851305\tvalid_1's auc: 0.753998\n",
      "[144]\ttraining's auc: 0.851644\tvalid_1's auc: 0.755471\n",
      "[145]\ttraining's auc: 0.851592\tvalid_1's auc: 0.755051\n",
      "[146]\ttraining's auc: 0.851943\tvalid_1's auc: 0.755051\n",
      "[147]\ttraining's auc: 0.852086\tvalid_1's auc: 0.755051\n",
      "[148]\ttraining's auc: 0.851917\tvalid_1's auc: 0.755051\n",
      "[149]\ttraining's auc: 0.85232\tvalid_1's auc: 0.756313\n",
      "[150]\ttraining's auc: 0.852021\tvalid_1's auc: 0.755682\n",
      "[151]\ttraining's auc: 0.852476\tvalid_1's auc: 0.755892\n",
      "[152]\ttraining's auc: 0.852867\tvalid_1's auc: 0.756313\n",
      "[153]\ttraining's auc: 0.852749\tvalid_1's auc: 0.755471\n",
      "[154]\ttraining's auc: 0.853153\tvalid_1's auc: 0.755892\n",
      "[155]\ttraining's auc: 0.85314\tvalid_1's auc: 0.756734\n",
      "[156]\ttraining's auc: 0.853166\tvalid_1's auc: 0.756944\n",
      "[157]\ttraining's auc: 0.853023\tvalid_1's auc: 0.756313\n",
      "[158]\ttraining's auc: 0.853205\tvalid_1's auc: 0.757155\n",
      "[159]\ttraining's auc: 0.853413\tvalid_1's auc: 0.756734\n",
      "[160]\ttraining's auc: 0.853387\tvalid_1's auc: 0.756524\n",
      "[161]\ttraining's auc: 0.853569\tvalid_1's auc: 0.756734\n",
      "[162]\ttraining's auc: 0.853491\tvalid_1's auc: 0.756734\n",
      "[163]\ttraining's auc: 0.853608\tvalid_1's auc: 0.756103\n",
      "[164]\ttraining's auc: 0.853413\tvalid_1's auc: 0.756313\n",
      "[165]\ttraining's auc: 0.854102\tvalid_1's auc: 0.758628\n",
      "[166]\ttraining's auc: 0.853959\tvalid_1's auc: 0.756524\n",
      "[167]\ttraining's auc: 0.854213\tvalid_1's auc: 0.756103\n",
      "[168]\ttraining's auc: 0.854369\tvalid_1's auc: 0.757786\n",
      "[169]\ttraining's auc: 0.854096\tvalid_1's auc: 0.757576\n",
      "[170]\ttraining's auc: 0.854499\tvalid_1's auc: 0.758207\n",
      "[171]\ttraining's auc: 0.854493\tvalid_1's auc: 0.758312\n",
      "[172]\ttraining's auc: 0.854948\tvalid_1's auc: 0.757471\n",
      "[173]\ttraining's auc: 0.854688\tvalid_1's auc: 0.758102\n",
      "[174]\ttraining's auc: 0.854779\tvalid_1's auc: 0.758102\n",
      "[175]\ttraining's auc: 0.854636\tvalid_1's auc: 0.757891\n",
      "[176]\ttraining's auc: 0.854987\tvalid_1's auc: 0.75705\n",
      "[177]\ttraining's auc: 0.854935\tvalid_1's auc: 0.757891\n",
      "[178]\ttraining's auc: 0.855221\tvalid_1's auc: 0.757681\n",
      "[179]\ttraining's auc: 0.855442\tvalid_1's auc: 0.75726\n",
      "[180]\ttraining's auc: 0.855598\tvalid_1's auc: 0.757471\n",
      "[181]\ttraining's auc: 0.855572\tvalid_1's auc: 0.757471\n",
      "[182]\ttraining's auc: 0.855703\tvalid_1's auc: 0.75726\n",
      "[183]\ttraining's auc: 0.855748\tvalid_1's auc: 0.755787\n",
      "[184]\ttraining's auc: 0.855787\tvalid_1's auc: 0.757471\n",
      "[185]\ttraining's auc: 0.855787\tvalid_1's auc: 0.757681\n",
      "[186]\ttraining's auc: 0.856034\tvalid_1's auc: 0.75726\n",
      "[187]\ttraining's auc: 0.856158\tvalid_1's auc: 0.758102\n",
      "[188]\ttraining's auc: 0.85608\tvalid_1's auc: 0.754945\n",
      "[189]\ttraining's auc: 0.856106\tvalid_1's auc: 0.75705\n",
      "[190]\ttraining's auc: 0.85634\tvalid_1's auc: 0.754735\n",
      "[191]\ttraining's auc: 0.856249\tvalid_1's auc: 0.754735\n",
      "[192]\ttraining's auc: 0.856314\tvalid_1's auc: 0.755156\n",
      "[193]\ttraining's auc: 0.856392\tvalid_1's auc: 0.754945\n",
      "[194]\ttraining's auc: 0.856327\tvalid_1's auc: 0.754735\n",
      "[195]\ttraining's auc: 0.856457\tvalid_1's auc: 0.756418\n",
      "[196]\ttraining's auc: 0.856496\tvalid_1's auc: 0.755156\n",
      "[197]\ttraining's auc: 0.856795\tvalid_1's auc: 0.754945\n",
      "[198]\ttraining's auc: 0.856678\tvalid_1's auc: 0.754945\n",
      "[199]\ttraining's auc: 0.856873\tvalid_1's auc: 0.755156\n",
      "[200]\ttraining's auc: 0.857199\tvalid_1's auc: 0.755787\n",
      "[201]\ttraining's auc: 0.857309\tvalid_1's auc: 0.756629\n",
      "[202]\ttraining's auc: 0.857348\tvalid_1's auc: 0.756208\n",
      "[203]\ttraining's auc: 0.857322\tvalid_1's auc: 0.755366\n",
      "[204]\ttraining's auc: 0.857426\tvalid_1's auc: 0.755156\n",
      "[205]\ttraining's auc: 0.857465\tvalid_1's auc: 0.756208\n",
      "[206]\ttraining's auc: 0.857504\tvalid_1's auc: 0.755787\n",
      "[207]\ttraining's auc: 0.857491\tvalid_1's auc: 0.755997\n",
      "[208]\ttraining's auc: 0.857517\tvalid_1's auc: 0.755787\n",
      "[209]\ttraining's auc: 0.857699\tvalid_1's auc: 0.757891\n",
      "[210]\ttraining's auc: 0.858129\tvalid_1's auc: 0.758312\n",
      "[211]\ttraining's auc: 0.858012\tvalid_1's auc: 0.756208\n",
      "[212]\ttraining's auc: 0.85822\tvalid_1's auc: 0.75705\n",
      "[213]\ttraining's auc: 0.85809\tvalid_1's auc: 0.756208\n",
      "[214]\ttraining's auc: 0.858233\tvalid_1's auc: 0.759154\n",
      "[215]\ttraining's auc: 0.858571\tvalid_1's auc: 0.759785\n",
      "[216]\ttraining's auc: 0.858584\tvalid_1's auc: 0.758944\n",
      "[217]\ttraining's auc: 0.858571\tvalid_1's auc: 0.759154\n",
      "[218]\ttraining's auc: 0.858714\tvalid_1's auc: 0.758944\n",
      "[219]\ttraining's auc: 0.858675\tvalid_1's auc: 0.758944\n",
      "[220]\ttraining's auc: 0.858675\tvalid_1's auc: 0.759154\n",
      "[221]\ttraining's auc: 0.85874\tvalid_1's auc: 0.758944\n",
      "[222]\ttraining's auc: 0.858701\tvalid_1's auc: 0.758944\n",
      "[223]\ttraining's auc: 0.858701\tvalid_1's auc: 0.759364\n",
      "[224]\ttraining's auc: 0.858701\tvalid_1's auc: 0.758944\n",
      "[225]\ttraining's auc: 0.858844\tvalid_1's auc: 0.758944\n",
      "[226]\ttraining's auc: 0.859091\tvalid_1's auc: 0.758733\n",
      "[227]\ttraining's auc: 0.859091\tvalid_1's auc: 0.758733\n",
      "[228]\ttraining's auc: 0.859183\tvalid_1's auc: 0.758733\n",
      "[229]\ttraining's auc: 0.85943\tvalid_1's auc: 0.760417\n",
      "[230]\ttraining's auc: 0.859573\tvalid_1's auc: 0.759575\n",
      "[231]\ttraining's auc: 0.859313\tvalid_1's auc: 0.760417\n",
      "[232]\ttraining's auc: 0.859443\tvalid_1's auc: 0.761048\n",
      "[233]\ttraining's auc: 0.859482\tvalid_1's auc: 0.761048\n",
      "[234]\ttraining's auc: 0.859521\tvalid_1's auc: 0.760838\n",
      "[235]\ttraining's auc: 0.859547\tvalid_1's auc: 0.760417\n",
      "[236]\ttraining's auc: 0.859859\tvalid_1's auc: 0.761469\n",
      "[237]\ttraining's auc: 0.859833\tvalid_1's auc: 0.760627\n",
      "[238]\ttraining's auc: 0.859612\tvalid_1's auc: 0.760627\n",
      "[239]\ttraining's auc: 0.85956\tvalid_1's auc: 0.760627\n",
      "[240]\ttraining's auc: 0.859703\tvalid_1's auc: 0.760417\n",
      "[241]\ttraining's auc: 0.859716\tvalid_1's auc: 0.760627\n",
      "[242]\ttraining's auc: 0.859755\tvalid_1's auc: 0.760206\n",
      "[243]\ttraining's auc: 0.860028\tvalid_1's auc: 0.759996\n",
      "[244]\ttraining's auc: 0.860002\tvalid_1's auc: 0.760206\n",
      "[245]\ttraining's auc: 0.859729\tvalid_1's auc: 0.759575\n",
      "[246]\ttraining's auc: 0.859963\tvalid_1's auc: 0.759996\n",
      "[247]\ttraining's auc: 0.860041\tvalid_1's auc: 0.759996\n",
      "[248]\ttraining's auc: 0.860054\tvalid_1's auc: 0.760417\n",
      "[249]\ttraining's auc: 0.860054\tvalid_1's auc: 0.759364\n",
      "[250]\ttraining's auc: 0.860041\tvalid_1's auc: 0.759364\n",
      "[251]\ttraining's auc: 0.860184\tvalid_1's auc: 0.759364\n",
      "[252]\ttraining's auc: 0.860275\tvalid_1's auc: 0.759996\n",
      "[253]\ttraining's auc: 0.860522\tvalid_1's auc: 0.759364\n",
      "[254]\ttraining's auc: 0.860379\tvalid_1's auc: 0.759154\n",
      "[255]\ttraining's auc: 0.860379\tvalid_1's auc: 0.759575\n",
      "[256]\ttraining's auc: 0.860444\tvalid_1's auc: 0.759575\n",
      "[257]\ttraining's auc: 0.860548\tvalid_1's auc: 0.759785\n",
      "[258]\ttraining's auc: 0.860627\tvalid_1's auc: 0.759364\n",
      "[259]\ttraining's auc: 0.860614\tvalid_1's auc: 0.759785\n",
      "[260]\ttraining's auc: 0.86064\tvalid_1's auc: 0.759575\n",
      "[261]\ttraining's auc: 0.860679\tvalid_1's auc: 0.759575\n",
      "[262]\ttraining's auc: 0.860666\tvalid_1's auc: 0.759575\n",
      "[263]\ttraining's auc: 0.860718\tvalid_1's auc: 0.759996\n",
      "[264]\ttraining's auc: 0.860561\tvalid_1's auc: 0.759785\n",
      "[265]\ttraining's auc: 0.860705\tvalid_1's auc: 0.759364\n",
      "[266]\ttraining's auc: 0.860783\tvalid_1's auc: 0.759575\n",
      "[267]\ttraining's auc: 0.860783\tvalid_1's auc: 0.762521\n",
      "[268]\ttraining's auc: 0.860796\tvalid_1's auc: 0.763573\n",
      "[269]\ttraining's auc: 0.861121\tvalid_1's auc: 0.763573\n",
      "[270]\ttraining's auc: 0.861212\tvalid_1's auc: 0.763152\n",
      "[271]\ttraining's auc: 0.861264\tvalid_1's auc: 0.763152\n",
      "[272]\ttraining's auc: 0.861108\tvalid_1's auc: 0.763152\n",
      "[273]\ttraining's auc: 0.861186\tvalid_1's auc: 0.763152\n",
      "[274]\ttraining's auc: 0.861186\tvalid_1's auc: 0.763152\n",
      "[275]\ttraining's auc: 0.861225\tvalid_1's auc: 0.763152\n",
      "[276]\ttraining's auc: 0.861225\tvalid_1's auc: 0.763152\n",
      "[277]\ttraining's auc: 0.861199\tvalid_1's auc: 0.763363\n",
      "[278]\ttraining's auc: 0.861212\tvalid_1's auc: 0.763152\n",
      "[279]\ttraining's auc: 0.861277\tvalid_1's auc: 0.763152\n",
      "[280]\ttraining's auc: 0.861238\tvalid_1's auc: 0.763152\n",
      "[281]\ttraining's auc: 0.861485\tvalid_1's auc: 0.763573\n",
      "[282]\ttraining's auc: 0.861264\tvalid_1's auc: 0.762521\n",
      "[283]\ttraining's auc: 0.861433\tvalid_1's auc: 0.763573\n",
      "[284]\ttraining's auc: 0.861342\tvalid_1's auc: 0.762521\n",
      "[285]\ttraining's auc: 0.861498\tvalid_1's auc: 0.763784\n",
      "[286]\ttraining's auc: 0.861511\tvalid_1's auc: 0.763363\n",
      "[287]\ttraining's auc: 0.861433\tvalid_1's auc: 0.763784\n",
      "[288]\ttraining's auc: 0.861498\tvalid_1's auc: 0.763784\n",
      "[289]\ttraining's auc: 0.861576\tvalid_1's auc: 0.763363\n",
      "[290]\ttraining's auc: 0.861433\tvalid_1's auc: 0.765046\n",
      "[291]\ttraining's auc: 0.861472\tvalid_1's auc: 0.763994\n",
      "[292]\ttraining's auc: 0.861485\tvalid_1's auc: 0.764205\n",
      "[293]\ttraining's auc: 0.861459\tvalid_1's auc: 0.763573\n",
      "[294]\ttraining's auc: 0.861511\tvalid_1's auc: 0.764625\n",
      "[295]\ttraining's auc: 0.861849\tvalid_1's auc: 0.766519\n",
      "[296]\ttraining's auc: 0.86181\tvalid_1's auc: 0.76694\n",
      "[297]\ttraining's auc: 0.861862\tvalid_1's auc: 0.76673\n",
      "[298]\ttraining's auc: 0.861992\tvalid_1's auc: 0.76694\n",
      "[299]\ttraining's auc: 0.862005\tvalid_1's auc: 0.766309\n",
      "[300]\ttraining's auc: 0.862032\tvalid_1's auc: 0.767361\n",
      "[301]\ttraining's auc: 0.861966\tvalid_1's auc: 0.767992\n",
      "[302]\ttraining's auc: 0.862045\tvalid_1's auc: 0.767992\n",
      "[303]\ttraining's auc: 0.862084\tvalid_1's auc: 0.767572\n",
      "[304]\ttraining's auc: 0.862227\tvalid_1's auc: 0.767992\n",
      "[305]\ttraining's auc: 0.862292\tvalid_1's auc: 0.767992\n",
      "[306]\ttraining's auc: 0.862188\tvalid_1's auc: 0.767782\n",
      "[307]\ttraining's auc: 0.862435\tvalid_1's auc: 0.767992\n",
      "[308]\ttraining's auc: 0.862552\tvalid_1's auc: 0.767782\n",
      "[309]\ttraining's auc: 0.862383\tvalid_1's auc: 0.767361\n",
      "[310]\ttraining's auc: 0.862513\tvalid_1's auc: 0.767782\n",
      "[311]\ttraining's auc: 0.862526\tvalid_1's auc: 0.767572\n",
      "[312]\ttraining's auc: 0.8625\tvalid_1's auc: 0.767572\n",
      "[313]\ttraining's auc: 0.862461\tvalid_1's auc: 0.767782\n",
      "[314]\ttraining's auc: 0.862279\tvalid_1's auc: 0.767992\n",
      "[315]\ttraining's auc: 0.862734\tvalid_1's auc: 0.767782\n",
      "[316]\ttraining's auc: 0.862682\tvalid_1's auc: 0.768413\n",
      "[317]\ttraining's auc: 0.862539\tvalid_1's auc: 0.767572\n",
      "[318]\ttraining's auc: 0.862552\tvalid_1's auc: 0.767572\n",
      "[319]\ttraining's auc: 0.862487\tvalid_1's auc: 0.767572\n",
      "[320]\ttraining's auc: 0.862695\tvalid_1's auc: 0.768203\n",
      "[321]\ttraining's auc: 0.862799\tvalid_1's auc: 0.767782\n",
      "[322]\ttraining's auc: 0.862981\tvalid_1's auc: 0.767151\n",
      "[323]\ttraining's auc: 0.863033\tvalid_1's auc: 0.76673\n",
      "[324]\ttraining's auc: 0.862994\tvalid_1's auc: 0.767151\n",
      "[325]\ttraining's auc: 0.862955\tvalid_1's auc: 0.767782\n",
      "[326]\ttraining's auc: 0.863189\tvalid_1's auc: 0.767572\n",
      "[327]\ttraining's auc: 0.863085\tvalid_1's auc: 0.767572\n",
      "[328]\ttraining's auc: 0.863319\tvalid_1's auc: 0.767572\n",
      "[329]\ttraining's auc: 0.863397\tvalid_1's auc: 0.767361\n",
      "[330]\ttraining's auc: 0.863463\tvalid_1's auc: 0.767572\n",
      "[331]\ttraining's auc: 0.863319\tvalid_1's auc: 0.767572\n",
      "[332]\ttraining's auc: 0.863306\tvalid_1's auc: 0.767151\n",
      "[333]\ttraining's auc: 0.863645\tvalid_1's auc: 0.767572\n",
      "[334]\ttraining's auc: 0.863632\tvalid_1's auc: 0.76694\n",
      "[335]\ttraining's auc: 0.863723\tvalid_1's auc: 0.767045\n",
      "[336]\ttraining's auc: 0.863619\tvalid_1's auc: 0.766835\n",
      "[337]\ttraining's auc: 0.863749\tvalid_1's auc: 0.766835\n",
      "[338]\ttraining's auc: 0.863931\tvalid_1's auc: 0.767045\n",
      "[339]\ttraining's auc: 0.863892\tvalid_1's auc: 0.767045\n",
      "[340]\ttraining's auc: 0.86384\tvalid_1's auc: 0.767045\n",
      "[341]\ttraining's auc: 0.863853\tvalid_1's auc: 0.767466\n",
      "[342]\ttraining's auc: 0.863983\tvalid_1's auc: 0.764099\n",
      "[343]\ttraining's auc: 0.864126\tvalid_1's auc: 0.766835\n",
      "[344]\ttraining's auc: 0.864074\tvalid_1's auc: 0.767045\n",
      "[345]\ttraining's auc: 0.864425\tvalid_1's auc: 0.768308\n",
      "[346]\ttraining's auc: 0.864152\tvalid_1's auc: 0.767045\n",
      "[347]\ttraining's auc: 0.864451\tvalid_1's auc: 0.767677\n",
      "[348]\ttraining's auc: 0.86423\tvalid_1's auc: 0.766625\n",
      "[349]\ttraining's auc: 0.864594\tvalid_1's auc: 0.767677\n",
      "[350]\ttraining's auc: 0.86462\tvalid_1's auc: 0.767677\n",
      "[351]\ttraining's auc: 0.86462\tvalid_1's auc: 0.768098\n",
      "[352]\ttraining's auc: 0.865206\tvalid_1's auc: 0.767887\n",
      "[353]\ttraining's auc: 0.865102\tvalid_1's auc: 0.765572\n",
      "[354]\ttraining's auc: 0.865154\tvalid_1's auc: 0.766204\n",
      "[355]\ttraining's auc: 0.865388\tvalid_1's auc: 0.765993\n",
      "[356]\ttraining's auc: 0.865232\tvalid_1's auc: 0.766204\n",
      "[357]\ttraining's auc: 0.865297\tvalid_1's auc: 0.768308\n",
      "[358]\ttraining's auc: 0.86531\tvalid_1's auc: 0.766414\n",
      "[359]\ttraining's auc: 0.865323\tvalid_1's auc: 0.765993\n",
      "[360]\ttraining's auc: 0.865375\tvalid_1's auc: 0.768519\n",
      "[361]\ttraining's auc: 0.865453\tvalid_1's auc: 0.768939\n",
      "[362]\ttraining's auc: 0.865479\tvalid_1's auc: 0.768939\n",
      "[363]\ttraining's auc: 0.86557\tvalid_1's auc: 0.765362\n",
      "[364]\ttraining's auc: 0.865557\tvalid_1's auc: 0.765993\n",
      "[365]\ttraining's auc: 0.865531\tvalid_1's auc: 0.765362\n",
      "[366]\ttraining's auc: 0.865583\tvalid_1's auc: 0.765362\n",
      "[367]\ttraining's auc: 0.86557\tvalid_1's auc: 0.765362\n",
      "[368]\ttraining's auc: 0.865596\tvalid_1's auc: 0.767677\n",
      "[369]\ttraining's auc: 0.865635\tvalid_1's auc: 0.765152\n",
      "[370]\ttraining's auc: 0.865843\tvalid_1's auc: 0.765572\n",
      "[371]\ttraining's auc: 0.865973\tvalid_1's auc: 0.765783\n",
      "[372]\ttraining's auc: 0.866012\tvalid_1's auc: 0.765783\n",
      "[373]\ttraining's auc: 0.866077\tvalid_1's auc: 0.765362\n",
      "[374]\ttraining's auc: 0.865973\tvalid_1's auc: 0.765783\n",
      "[375]\ttraining's auc: 0.866077\tvalid_1's auc: 0.765783\n",
      "[376]\ttraining's auc: 0.866129\tvalid_1's auc: 0.765783\n",
      "[377]\ttraining's auc: 0.866142\tvalid_1's auc: 0.765783\n",
      "[378]\ttraining's auc: 0.866142\tvalid_1's auc: 0.765572\n",
      "[379]\ttraining's auc: 0.866155\tvalid_1's auc: 0.768519\n",
      "[380]\ttraining's auc: 0.866103\tvalid_1's auc: 0.765993\n",
      "[381]\ttraining's auc: 0.866103\tvalid_1's auc: 0.765572\n",
      "[382]\ttraining's auc: 0.866259\tvalid_1's auc: 0.768308\n",
      "[383]\ttraining's auc: 0.866168\tvalid_1's auc: 0.768098\n",
      "[384]\ttraining's auc: 0.866285\tvalid_1's auc: 0.768308\n",
      "[385]\ttraining's auc: 0.866168\tvalid_1's auc: 0.765572\n",
      "[386]\ttraining's auc: 0.866194\tvalid_1's auc: 0.765993\n",
      "[387]\ttraining's auc: 0.86622\tvalid_1's auc: 0.765783\n",
      "[388]\ttraining's auc: 0.866338\tvalid_1's auc: 0.76936\n",
      "[389]\ttraining's auc: 0.866494\tvalid_1's auc: 0.768308\n",
      "[390]\ttraining's auc: 0.866442\tvalid_1's auc: 0.768519\n",
      "[391]\ttraining's auc: 0.866403\tvalid_1's auc: 0.766835\n",
      "[392]\ttraining's auc: 0.866494\tvalid_1's auc: 0.768098\n",
      "[393]\ttraining's auc: 0.866442\tvalid_1's auc: 0.768729\n",
      "[394]\ttraining's auc: 0.866481\tvalid_1's auc: 0.765572\n",
      "[395]\ttraining's auc: 0.866429\tvalid_1's auc: 0.766414\n",
      "[396]\ttraining's auc: 0.866468\tvalid_1's auc: 0.767677\n",
      "[397]\ttraining's auc: 0.866481\tvalid_1's auc: 0.765993\n",
      "[398]\ttraining's auc: 0.866546\tvalid_1's auc: 0.767677\n",
      "[399]\ttraining's auc: 0.866611\tvalid_1's auc: 0.768098\n",
      "[400]\ttraining's auc: 0.866546\tvalid_1's auc: 0.765783\n",
      "[401]\ttraining's auc: 0.866572\tvalid_1's auc: 0.765783\n",
      "[402]\ttraining's auc: 0.866754\tvalid_1's auc: 0.76452\n",
      "[403]\ttraining's auc: 0.866793\tvalid_1's auc: 0.76452\n",
      "[404]\ttraining's auc: 0.866832\tvalid_1's auc: 0.765362\n",
      "[405]\ttraining's auc: 0.86678\tvalid_1's auc: 0.765572\n",
      "[406]\ttraining's auc: 0.86665\tvalid_1's auc: 0.766835\n",
      "[407]\ttraining's auc: 0.867092\tvalid_1's auc: 0.768098\n",
      "[408]\ttraining's auc: 0.867209\tvalid_1's auc: 0.768729\n",
      "[409]\ttraining's auc: 0.867222\tvalid_1's auc: 0.770202\n",
      "[410]\ttraining's auc: 0.867183\tvalid_1's auc: 0.767466\n",
      "[411]\ttraining's auc: 0.867118\tvalid_1's auc: 0.769992\n",
      "[412]\ttraining's auc: 0.867248\tvalid_1's auc: 0.771886\n",
      "[413]\ttraining's auc: 0.867209\tvalid_1's auc: 0.772096\n",
      "[414]\ttraining's auc: 0.867196\tvalid_1's auc: 0.76936\n",
      "[415]\ttraining's auc: 0.867287\tvalid_1's auc: 0.771886\n",
      "[416]\ttraining's auc: 0.867326\tvalid_1's auc: 0.771044\n",
      "[417]\ttraining's auc: 0.867222\tvalid_1's auc: 0.76936\n",
      "[418]\ttraining's auc: 0.867131\tvalid_1's auc: 0.770623\n",
      "[419]\ttraining's auc: 0.867196\tvalid_1's auc: 0.768939\n",
      "[420]\ttraining's auc: 0.867261\tvalid_1's auc: 0.768308\n",
      "[421]\ttraining's auc: 0.8673\tvalid_1's auc: 0.768939\n",
      "[422]\ttraining's auc: 0.867443\tvalid_1's auc: 0.771465\n",
      "[423]\ttraining's auc: 0.867391\tvalid_1's auc: 0.771886\n",
      "[424]\ttraining's auc: 0.867417\tvalid_1's auc: 0.771675\n",
      "[425]\ttraining's auc: 0.867547\tvalid_1's auc: 0.771254\n",
      "[426]\ttraining's auc: 0.867482\tvalid_1's auc: 0.771675\n",
      "[427]\ttraining's auc: 0.867677\tvalid_1's auc: 0.770412\n",
      "[428]\ttraining's auc: 0.867534\tvalid_1's auc: 0.771254\n",
      "[429]\ttraining's auc: 0.867482\tvalid_1's auc: 0.771044\n",
      "[430]\ttraining's auc: 0.867625\tvalid_1's auc: 0.771254\n",
      "[431]\ttraining's auc: 0.86756\tvalid_1's auc: 0.771465\n",
      "[432]\ttraining's auc: 0.867703\tvalid_1's auc: 0.772306\n",
      "[433]\ttraining's auc: 0.867703\tvalid_1's auc: 0.770833\n",
      "[434]\ttraining's auc: 0.867808\tvalid_1's auc: 0.771886\n",
      "[435]\ttraining's auc: 0.868003\tvalid_1's auc: 0.772096\n",
      "[436]\ttraining's auc: 0.86799\tvalid_1's auc: 0.772517\n",
      "[437]\ttraining's auc: 0.868042\tvalid_1's auc: 0.772517\n",
      "[438]\ttraining's auc: 0.867977\tvalid_1's auc: 0.772517\n",
      "[439]\ttraining's auc: 0.868224\tvalid_1's auc: 0.771675\n",
      "[440]\ttraining's auc: 0.86812\tvalid_1's auc: 0.770623\n",
      "[441]\ttraining's auc: 0.86812\tvalid_1's auc: 0.771675\n",
      "[442]\ttraining's auc: 0.86812\tvalid_1's auc: 0.772306\n",
      "[443]\ttraining's auc: 0.86812\tvalid_1's auc: 0.772306\n",
      "[444]\ttraining's auc: 0.86812\tvalid_1's auc: 0.772096\n",
      "[445]\ttraining's auc: 0.868107\tvalid_1's auc: 0.772096\n",
      "[446]\ttraining's auc: 0.868133\tvalid_1's auc: 0.771254\n",
      "[447]\ttraining's auc: 0.868133\tvalid_1's auc: 0.771254\n",
      "[448]\ttraining's auc: 0.86812\tvalid_1's auc: 0.770833\n",
      "[449]\ttraining's auc: 0.868211\tvalid_1's auc: 0.771886\n",
      "[450]\ttraining's auc: 0.868211\tvalid_1's auc: 0.771886\n",
      "[451]\ttraining's auc: 0.868302\tvalid_1's auc: 0.771886\n",
      "[452]\ttraining's auc: 0.868263\tvalid_1's auc: 0.772517\n",
      "[453]\ttraining's auc: 0.868406\tvalid_1's auc: 0.771886\n",
      "[454]\ttraining's auc: 0.868302\tvalid_1's auc: 0.772096\n",
      "[455]\ttraining's auc: 0.868315\tvalid_1's auc: 0.771675\n",
      "[456]\ttraining's auc: 0.868367\tvalid_1's auc: 0.771675\n",
      "[457]\ttraining's auc: 0.868406\tvalid_1's auc: 0.772096\n",
      "[458]\ttraining's auc: 0.868341\tvalid_1's auc: 0.771675\n",
      "[459]\ttraining's auc: 0.868354\tvalid_1's auc: 0.771886\n",
      "[460]\ttraining's auc: 0.86838\tvalid_1's auc: 0.772517\n",
      "[461]\ttraining's auc: 0.868445\tvalid_1's auc: 0.771886\n",
      "[462]\ttraining's auc: 0.86838\tvalid_1's auc: 0.771886\n",
      "[463]\ttraining's auc: 0.868432\tvalid_1's auc: 0.772306\n",
      "[464]\ttraining's auc: 0.868484\tvalid_1's auc: 0.771886\n",
      "[465]\ttraining's auc: 0.868458\tvalid_1's auc: 0.772517\n",
      "[466]\ttraining's auc: 0.868471\tvalid_1's auc: 0.772306\n",
      "[467]\ttraining's auc: 0.868523\tvalid_1's auc: 0.772727\n",
      "[468]\ttraining's auc: 0.868549\tvalid_1's auc: 0.772938\n",
      "[469]\ttraining's auc: 0.868614\tvalid_1's auc: 0.773148\n",
      "[470]\ttraining's auc: 0.868549\tvalid_1's auc: 0.772938\n",
      "[471]\ttraining's auc: 0.868575\tvalid_1's auc: 0.773148\n",
      "[472]\ttraining's auc: 0.868757\tvalid_1's auc: 0.771886\n",
      "[473]\ttraining's auc: 0.868718\tvalid_1's auc: 0.769781\n",
      "[474]\ttraining's auc: 0.868705\tvalid_1's auc: 0.76936\n",
      "[475]\ttraining's auc: 0.868744\tvalid_1's auc: 0.769781\n",
      "[476]\ttraining's auc: 0.868718\tvalid_1's auc: 0.771465\n",
      "[477]\ttraining's auc: 0.868718\tvalid_1's auc: 0.771886\n",
      "[478]\ttraining's auc: 0.868796\tvalid_1's auc: 0.772306\n",
      "[479]\ttraining's auc: 0.868705\tvalid_1's auc: 0.773359\n",
      "[480]\ttraining's auc: 0.868718\tvalid_1's auc: 0.773148\n",
      "[481]\ttraining's auc: 0.868705\tvalid_1's auc: 0.770833\n",
      "[482]\ttraining's auc: 0.868666\tvalid_1's auc: 0.773148\n",
      "[483]\ttraining's auc: 0.868783\tvalid_1's auc: 0.772306\n",
      "[484]\ttraining's auc: 0.868692\tvalid_1's auc: 0.773148\n",
      "[485]\ttraining's auc: 0.868692\tvalid_1's auc: 0.773148\n",
      "[486]\ttraining's auc: 0.868705\tvalid_1's auc: 0.773148\n",
      "[487]\ttraining's auc: 0.868679\tvalid_1's auc: 0.772727\n",
      "[488]\ttraining's auc: 0.868679\tvalid_1's auc: 0.772727\n",
      "[489]\ttraining's auc: 0.868666\tvalid_1's auc: 0.770412\n",
      "[490]\ttraining's auc: 0.868692\tvalid_1's auc: 0.770412\n",
      "[491]\ttraining's auc: 0.868692\tvalid_1's auc: 0.770412\n",
      "[492]\ttraining's auc: 0.86877\tvalid_1's auc: 0.771886\n",
      "[493]\ttraining's auc: 0.868809\tvalid_1's auc: 0.772306\n",
      "[494]\ttraining's auc: 0.868822\tvalid_1's auc: 0.769992\n",
      "[495]\ttraining's auc: 0.868731\tvalid_1's auc: 0.770833\n",
      "[496]\ttraining's auc: 0.868705\tvalid_1's auc: 0.770833\n",
      "[497]\ttraining's auc: 0.868822\tvalid_1's auc: 0.772306\n",
      "[498]\ttraining's auc: 0.868796\tvalid_1's auc: 0.773359\n",
      "[499]\ttraining's auc: 0.868718\tvalid_1's auc: 0.773359\n",
      "[500]\ttraining's auc: 0.868757\tvalid_1's auc: 0.772727\n",
      "[501]\ttraining's auc: 0.868796\tvalid_1's auc: 0.772306\n",
      "[502]\ttraining's auc: 0.868731\tvalid_1's auc: 0.771675\n",
      "[503]\ttraining's auc: 0.868731\tvalid_1's auc: 0.76936\n",
      "[504]\ttraining's auc: 0.868653\tvalid_1's auc: 0.771675\n",
      "[505]\ttraining's auc: 0.868705\tvalid_1's auc: 0.772096\n",
      "[506]\ttraining's auc: 0.868653\tvalid_1's auc: 0.771675\n",
      "[507]\ttraining's auc: 0.868731\tvalid_1's auc: 0.772306\n",
      "[508]\ttraining's auc: 0.868692\tvalid_1's auc: 0.772096\n",
      "[509]\ttraining's auc: 0.86877\tvalid_1's auc: 0.772938\n",
      "[510]\ttraining's auc: 0.868692\tvalid_1's auc: 0.76936\n",
      "[511]\ttraining's auc: 0.868744\tvalid_1's auc: 0.769571\n",
      "[512]\ttraining's auc: 0.868692\tvalid_1's auc: 0.771886\n",
      "[513]\ttraining's auc: 0.868796\tvalid_1's auc: 0.769992\n",
      "[514]\ttraining's auc: 0.868692\tvalid_1's auc: 0.769781\n",
      "[515]\ttraining's auc: 0.868796\tvalid_1's auc: 0.769992\n",
      "[516]\ttraining's auc: 0.868692\tvalid_1's auc: 0.769781\n",
      "[517]\ttraining's auc: 0.868796\tvalid_1's auc: 0.769992\n",
      "[518]\ttraining's auc: 0.868731\tvalid_1's auc: 0.769992\n",
      "[519]\ttraining's auc: 0.868809\tvalid_1's auc: 0.769571\n",
      "[520]\ttraining's auc: 0.868822\tvalid_1's auc: 0.769571\n",
      "[521]\ttraining's auc: 0.868783\tvalid_1's auc: 0.76936\n",
      "[522]\ttraining's auc: 0.86877\tvalid_1's auc: 0.76936\n",
      "[523]\ttraining's auc: 0.868835\tvalid_1's auc: 0.768939\n",
      "[524]\ttraining's auc: 0.868796\tvalid_1's auc: 0.76915\n",
      "[525]\ttraining's auc: 0.868809\tvalid_1's auc: 0.768939\n",
      "[526]\ttraining's auc: 0.868887\tvalid_1's auc: 0.769571\n",
      "[527]\ttraining's auc: 0.868848\tvalid_1's auc: 0.769992\n",
      "[528]\ttraining's auc: 0.868939\tvalid_1's auc: 0.769781\n",
      "[529]\ttraining's auc: 0.868939\tvalid_1's auc: 0.770202\n",
      "[530]\ttraining's auc: 0.868939\tvalid_1's auc: 0.769571\n",
      "[531]\ttraining's auc: 0.868913\tvalid_1's auc: 0.770202\n",
      "[532]\ttraining's auc: 0.869004\tvalid_1's auc: 0.769571\n",
      "[533]\ttraining's auc: 0.869004\tvalid_1's auc: 0.770202\n",
      "[534]\ttraining's auc: 0.86903\tvalid_1's auc: 0.769571\n",
      "[535]\ttraining's auc: 0.86903\tvalid_1's auc: 0.770202\n",
      "[536]\ttraining's auc: 0.869082\tvalid_1's auc: 0.769571\n",
      "[537]\ttraining's auc: 0.86903\tvalid_1's auc: 0.76936\n",
      "[538]\ttraining's auc: 0.869108\tvalid_1's auc: 0.769571\n",
      "[539]\ttraining's auc: 0.869174\tvalid_1's auc: 0.769571\n",
      "[540]\ttraining's auc: 0.869265\tvalid_1's auc: 0.770202\n",
      "[541]\ttraining's auc: 0.869252\tvalid_1's auc: 0.770202\n",
      "[542]\ttraining's auc: 0.869239\tvalid_1's auc: 0.768939\n",
      "[543]\ttraining's auc: 0.869421\tvalid_1's auc: 0.76915\n",
      "[544]\ttraining's auc: 0.86946\tvalid_1's auc: 0.768939\n",
      "[545]\ttraining's auc: 0.869421\tvalid_1's auc: 0.768939\n",
      "[546]\ttraining's auc: 0.869408\tvalid_1's auc: 0.768729\n",
      "[547]\ttraining's auc: 0.869382\tvalid_1's auc: 0.768939\n",
      "[548]\ttraining's auc: 0.869421\tvalid_1's auc: 0.768939\n",
      "[549]\ttraining's auc: 0.869499\tvalid_1's auc: 0.76915\n",
      "[550]\ttraining's auc: 0.869486\tvalid_1's auc: 0.768939\n",
      "[551]\ttraining's auc: 0.869668\tvalid_1's auc: 0.768939\n",
      "[552]\ttraining's auc: 0.869681\tvalid_1's auc: 0.768939\n",
      "[553]\ttraining's auc: 0.869577\tvalid_1's auc: 0.768939\n",
      "[554]\ttraining's auc: 0.869577\tvalid_1's auc: 0.768939\n",
      "[555]\ttraining's auc: 0.869681\tvalid_1's auc: 0.76915\n",
      "[556]\ttraining's auc: 0.869694\tvalid_1's auc: 0.768519\n",
      "[557]\ttraining's auc: 0.869837\tvalid_1's auc: 0.768939\n",
      "[558]\ttraining's auc: 0.869837\tvalid_1's auc: 0.76936\n",
      "[559]\ttraining's auc: 0.869798\tvalid_1's auc: 0.76936\n",
      "[560]\ttraining's auc: 0.869837\tvalid_1's auc: 0.769571\n",
      "[561]\ttraining's auc: 0.86972\tvalid_1's auc: 0.76936\n",
      "[562]\ttraining's auc: 0.869889\tvalid_1's auc: 0.769571\n",
      "[563]\ttraining's auc: 0.869876\tvalid_1's auc: 0.769571\n",
      "[564]\ttraining's auc: 0.869785\tvalid_1's auc: 0.76915\n",
      "[565]\ttraining's auc: 0.869876\tvalid_1's auc: 0.768729\n",
      "[566]\ttraining's auc: 0.869837\tvalid_1's auc: 0.76936\n",
      "[567]\ttraining's auc: 0.869863\tvalid_1's auc: 0.768729\n",
      "[568]\ttraining's auc: 0.869941\tvalid_1's auc: 0.768939\n",
      "[569]\ttraining's auc: 0.869798\tvalid_1's auc: 0.76936\n",
      "[570]\ttraining's auc: 0.869746\tvalid_1's auc: 0.768519\n",
      "[571]\ttraining's auc: 0.86985\tvalid_1's auc: 0.769571\n",
      "[572]\ttraining's auc: 0.869811\tvalid_1's auc: 0.769992\n",
      "[573]\ttraining's auc: 0.869824\tvalid_1's auc: 0.770412\n",
      "[574]\ttraining's auc: 0.869928\tvalid_1's auc: 0.768729\n",
      "[575]\ttraining's auc: 0.870006\tvalid_1's auc: 0.770412\n",
      "[576]\ttraining's auc: 0.869993\tvalid_1's auc: 0.770202\n",
      "[577]\ttraining's auc: 0.870045\tvalid_1's auc: 0.770623\n",
      "[578]\ttraining's auc: 0.870019\tvalid_1's auc: 0.76936\n",
      "[579]\ttraining's auc: 0.870032\tvalid_1's auc: 0.770412\n",
      "Early stopping, best iteration is:\n",
      "[479]\ttraining's auc: 0.868705\tvalid_1's auc: 0.773359\n",
      "[検証用データ]acc:0.7324\n",
      "[ベースライン検証用データ]acc:0.7039\n",
      "-------------------- 3 --------------------\n",
      "(570, 2) (570, 1)\n",
      "(142, 2) (142, 1)\n",
      "y_tr:0.383, y_tr1:0.384, y_va1:0.380\n",
      "[1]\ttraining's auc: 0.77701\tvalid_1's auc: 0.64436\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.77701\tvalid_1's auc: 0.64436\n",
      "[3]\ttraining's auc: 0.777179\tvalid_1's auc: 0.64436\n",
      "[4]\ttraining's auc: 0.777179\tvalid_1's auc: 0.64436\n",
      "[5]\ttraining's auc: 0.781284\tvalid_1's auc: 0.652462\n",
      "[6]\ttraining's auc: 0.782578\tvalid_1's auc: 0.65846\n",
      "[7]\ttraining's auc: 0.78332\tvalid_1's auc: 0.659091\n",
      "[8]\ttraining's auc: 0.783424\tvalid_1's auc: 0.659091\n",
      "[9]\ttraining's auc: 0.786136\tvalid_1's auc: 0.660459\n",
      "[10]\ttraining's auc: 0.786754\tvalid_1's auc: 0.660248\n",
      "[11]\ttraining's auc: 0.787957\tvalid_1's auc: 0.664141\n",
      "[12]\ttraining's auc: 0.789961\tvalid_1's auc: 0.662142\n",
      "[13]\ttraining's auc: 0.792595\tvalid_1's auc: 0.666141\n",
      "[14]\ttraining's auc: 0.796661\tvalid_1's auc: 0.669718\n",
      "[15]\ttraining's auc: 0.799633\tvalid_1's auc: 0.677609\n",
      "[16]\ttraining's auc: 0.801123\tvalid_1's auc: 0.677399\n",
      "[17]\ttraining's auc: 0.801019\tvalid_1's auc: 0.679082\n",
      "[18]\ttraining's auc: 0.80269\tvalid_1's auc: 0.68045\n",
      "[19]\ttraining's auc: 0.802814\tvalid_1's auc: 0.679398\n",
      "[20]\ttraining's auc: 0.805624\tvalid_1's auc: 0.681292\n",
      "[21]\ttraining's auc: 0.808044\tvalid_1's auc: 0.68992\n",
      "[22]\ttraining's auc: 0.808915\tvalid_1's auc: 0.689078\n",
      "[23]\ttraining's auc: 0.809266\tvalid_1's auc: 0.688763\n",
      "[24]\ttraining's auc: 0.809735\tvalid_1's auc: 0.691919\n",
      "[25]\ttraining's auc: 0.811959\tvalid_1's auc: 0.693287\n",
      "[26]\ttraining's auc: 0.812688\tvalid_1's auc: 0.693708\n",
      "[27]\ttraining's auc: 0.813221\tvalid_1's auc: 0.693287\n",
      "[28]\ttraining's auc: 0.81369\tvalid_1's auc: 0.692235\n",
      "[29]\ttraining's auc: 0.814028\tvalid_1's auc: 0.692866\n",
      "[30]\ttraining's auc: 0.814665\tvalid_1's auc: 0.692866\n",
      "[31]\ttraining's auc: 0.816096\tvalid_1's auc: 0.696233\n",
      "[32]\ttraining's auc: 0.816558\tvalid_1's auc: 0.699179\n",
      "[33]\ttraining's auc: 0.816961\tvalid_1's auc: 0.698127\n",
      "[34]\ttraining's auc: 0.817599\tvalid_1's auc: 0.701284\n",
      "[35]\ttraining's auc: 0.818802\tvalid_1's auc: 0.700442\n",
      "[36]\ttraining's auc: 0.818451\tvalid_1's auc: 0.697917\n",
      "[37]\ttraining's auc: 0.819414\tvalid_1's auc: 0.700652\n",
      "[38]\ttraining's auc: 0.820845\tvalid_1's auc: 0.70181\n",
      "[39]\ttraining's auc: 0.822198\tvalid_1's auc: 0.704756\n",
      "[40]\ttraining's auc: 0.822445\tvalid_1's auc: 0.705387\n",
      "[41]\ttraining's auc: 0.823017\tvalid_1's auc: 0.703493\n",
      "[42]\ttraining's auc: 0.824461\tvalid_1's auc: 0.707071\n",
      "[43]\ttraining's auc: 0.825125\tvalid_1's auc: 0.705598\n",
      "[44]\ttraining's auc: 0.82545\tvalid_1's auc: 0.705808\n",
      "[45]\ttraining's auc: 0.825463\tvalid_1's auc: 0.705387\n",
      "[46]\ttraining's auc: 0.826165\tvalid_1's auc: 0.708965\n",
      "[47]\ttraining's auc: 0.826816\tvalid_1's auc: 0.707702\n",
      "[48]\ttraining's auc: 0.82785\tvalid_1's auc: 0.707702\n",
      "[49]\ttraining's auc: 0.828045\tvalid_1's auc: 0.705387\n",
      "[50]\ttraining's auc: 0.828598\tvalid_1's auc: 0.704966\n",
      "[51]\ttraining's auc: 0.829079\tvalid_1's auc: 0.70444\n",
      "[52]\ttraining's auc: 0.830862\tvalid_1's auc: 0.70907\n",
      "[53]\ttraining's auc: 0.830718\tvalid_1's auc: 0.707386\n",
      "[54]\ttraining's auc: 0.830666\tvalid_1's auc: 0.708859\n",
      "[55]\ttraining's auc: 0.831824\tvalid_1's auc: 0.712542\n",
      "[56]\ttraining's auc: 0.832306\tvalid_1's auc: 0.711911\n",
      "[57]\ttraining's auc: 0.832429\tvalid_1's auc: 0.707912\n",
      "[58]\ttraining's auc: 0.832689\tvalid_1's auc: 0.708333\n",
      "[59]\ttraining's auc: 0.832481\tvalid_1's auc: 0.709175\n",
      "[60]\ttraining's auc: 0.833327\tvalid_1's auc: 0.708965\n",
      "[61]\ttraining's auc: 0.833405\tvalid_1's auc: 0.710438\n",
      "[62]\ttraining's auc: 0.833958\tvalid_1's auc: 0.709175\n",
      "[63]\ttraining's auc: 0.834055\tvalid_1's auc: 0.711279\n",
      "[64]\ttraining's auc: 0.834823\tvalid_1's auc: 0.711069\n",
      "[65]\ttraining's auc: 0.835499\tvalid_1's auc: 0.709386\n",
      "[66]\ttraining's auc: 0.835786\tvalid_1's auc: 0.710964\n",
      "[67]\ttraining's auc: 0.836579\tvalid_1's auc: 0.710122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68]\ttraining's auc: 0.836521\tvalid_1's auc: 0.70907\n",
      "[69]\ttraining's auc: 0.836872\tvalid_1's auc: 0.708018\n",
      "[70]\ttraining's auc: 0.837132\tvalid_1's auc: 0.705492\n",
      "[71]\ttraining's auc: 0.837613\tvalid_1's auc: 0.707386\n",
      "[72]\ttraining's auc: 0.838225\tvalid_1's auc: 0.707597\n",
      "[73]\ttraining's auc: 0.839018\tvalid_1's auc: 0.711595\n",
      "[74]\ttraining's auc: 0.838862\tvalid_1's auc: 0.711595\n",
      "[75]\ttraining's auc: 0.839708\tvalid_1's auc: 0.712858\n",
      "[76]\ttraining's auc: 0.839344\tvalid_1's auc: 0.712016\n",
      "[77]\ttraining's auc: 0.839864\tvalid_1's auc: 0.711174\n",
      "[78]\ttraining's auc: 0.840163\tvalid_1's auc: 0.714962\n",
      "[79]\ttraining's auc: 0.84054\tvalid_1's auc: 0.713699\n",
      "[80]\ttraining's auc: 0.841308\tvalid_1's auc: 0.713068\n",
      "[81]\ttraining's auc: 0.841594\tvalid_1's auc: 0.716225\n",
      "[82]\ttraining's auc: 0.8411\tvalid_1's auc: 0.716856\n",
      "[83]\ttraining's auc: 0.841568\tvalid_1's auc: 0.714962\n",
      "[84]\ttraining's auc: 0.841503\tvalid_1's auc: 0.717066\n",
      "[85]\ttraining's auc: 0.841997\tvalid_1's auc: 0.716014\n",
      "[86]\ttraining's auc: 0.842804\tvalid_1's auc: 0.719171\n",
      "[87]\ttraining's auc: 0.842999\tvalid_1's auc: 0.720434\n",
      "[88]\ttraining's auc: 0.843116\tvalid_1's auc: 0.717066\n",
      "[89]\ttraining's auc: 0.843285\tvalid_1's auc: 0.717698\n",
      "[90]\ttraining's auc: 0.843923\tvalid_1's auc: 0.721696\n",
      "[91]\ttraining's auc: 0.843897\tvalid_1's auc: 0.722117\n",
      "[92]\ttraining's auc: 0.844131\tvalid_1's auc: 0.721907\n",
      "[93]\ttraining's auc: 0.844092\tvalid_1's auc: 0.721696\n",
      "[94]\ttraining's auc: 0.844326\tvalid_1's auc: 0.720013\n",
      "[95]\ttraining's auc: 0.844196\tvalid_1's auc: 0.718329\n",
      "[96]\ttraining's auc: 0.844651\tvalid_1's auc: 0.716646\n",
      "[97]\ttraining's auc: 0.845341\tvalid_1's auc: 0.717277\n",
      "[98]\ttraining's auc: 0.845302\tvalid_1's auc: 0.717908\n",
      "[99]\ttraining's auc: 0.845718\tvalid_1's auc: 0.720644\n",
      "[100]\ttraining's auc: 0.846108\tvalid_1's auc: 0.719381\n",
      "[101]\ttraining's auc: 0.845835\tvalid_1's auc: 0.721275\n",
      "[102]\ttraining's auc: 0.845913\tvalid_1's auc: 0.720854\n",
      "[103]\ttraining's auc: 0.846772\tvalid_1's auc: 0.720644\n",
      "[104]\ttraining's auc: 0.846505\tvalid_1's auc: 0.72096\n",
      "[105]\ttraining's auc: 0.846856\tvalid_1's auc: 0.722854\n",
      "[106]\ttraining's auc: 0.847182\tvalid_1's auc: 0.722643\n",
      "[107]\ttraining's auc: 0.847416\tvalid_1's auc: 0.722222\n",
      "[108]\ttraining's auc: 0.847104\tvalid_1's auc: 0.720328\n",
      "[109]\ttraining's auc: 0.847767\tvalid_1's auc: 0.723064\n",
      "[110]\ttraining's auc: 0.847975\tvalid_1's auc: 0.722012\n",
      "[111]\ttraining's auc: 0.848001\tvalid_1's auc: 0.723064\n",
      "[112]\ttraining's auc: 0.847741\tvalid_1's auc: 0.722222\n",
      "[113]\ttraining's auc: 0.848066\tvalid_1's auc: 0.722433\n",
      "[114]\ttraining's auc: 0.848092\tvalid_1's auc: 0.722012\n",
      "[115]\ttraining's auc: 0.848313\tvalid_1's auc: 0.721591\n",
      "[116]\ttraining's auc: 0.848482\tvalid_1's auc: 0.721801\n",
      "[117]\ttraining's auc: 0.848912\tvalid_1's auc: 0.722222\n",
      "[118]\ttraining's auc: 0.848756\tvalid_1's auc: 0.722222\n",
      "[119]\ttraining's auc: 0.848456\tvalid_1's auc: 0.72117\n",
      "[120]\ttraining's auc: 0.849302\tvalid_1's auc: 0.721591\n",
      "[121]\ttraining's auc: 0.848365\tvalid_1's auc: 0.720539\n",
      "[122]\ttraining's auc: 0.849198\tvalid_1's auc: 0.722854\n",
      "[123]\ttraining's auc: 0.849159\tvalid_1's auc: 0.724958\n",
      "[124]\ttraining's auc: 0.8499\tvalid_1's auc: 0.725379\n",
      "[125]\ttraining's auc: 0.849744\tvalid_1's auc: 0.7258\n",
      "[126]\ttraining's auc: 0.84951\tvalid_1's auc: 0.721801\n",
      "[127]\ttraining's auc: 0.849549\tvalid_1's auc: 0.721801\n",
      "[128]\ttraining's auc: 0.850148\tvalid_1's auc: 0.723274\n",
      "[129]\ttraining's auc: 0.849874\tvalid_1's auc: 0.722643\n",
      "[130]\ttraining's auc: 0.849913\tvalid_1's auc: 0.72096\n",
      "[131]\ttraining's auc: 0.850083\tvalid_1's auc: 0.720749\n",
      "[132]\ttraining's auc: 0.850662\tvalid_1's auc: 0.724958\n",
      "[133]\ttraining's auc: 0.850909\tvalid_1's auc: 0.724327\n",
      "[134]\ttraining's auc: 0.850466\tvalid_1's auc: 0.724958\n",
      "[135]\ttraining's auc: 0.850909\tvalid_1's auc: 0.72601\n",
      "[136]\ttraining's auc: 0.851156\tvalid_1's auc: 0.724958\n",
      "[137]\ttraining's auc: 0.851247\tvalid_1's auc: 0.724958\n",
      "[138]\ttraining's auc: 0.851507\tvalid_1's auc: 0.724958\n",
      "[139]\ttraining's auc: 0.85165\tvalid_1's auc: 0.724116\n",
      "[140]\ttraining's auc: 0.851559\tvalid_1's auc: 0.72601\n",
      "[141]\ttraining's auc: 0.851819\tvalid_1's auc: 0.726431\n",
      "[142]\ttraining's auc: 0.851325\tvalid_1's auc: 0.724958\n",
      "[143]\ttraining's auc: 0.851468\tvalid_1's auc: 0.725168\n",
      "[144]\ttraining's auc: 0.85191\tvalid_1's auc: 0.72601\n",
      "[145]\ttraining's auc: 0.851962\tvalid_1's auc: 0.726221\n",
      "[146]\ttraining's auc: 0.851975\tvalid_1's auc: 0.724958\n",
      "[147]\ttraining's auc: 0.852223\tvalid_1's auc: 0.726221\n",
      "[148]\ttraining's auc: 0.852548\tvalid_1's auc: 0.727483\n",
      "[149]\ttraining's auc: 0.852535\tvalid_1's auc: 0.727483\n",
      "[150]\ttraining's auc: 0.853159\tvalid_1's auc: 0.728325\n",
      "[151]\ttraining's auc: 0.852314\tvalid_1's auc: 0.726852\n",
      "[152]\ttraining's auc: 0.852756\tvalid_1's auc: 0.726641\n",
      "[153]\ttraining's auc: 0.853159\tvalid_1's auc: 0.726431\n",
      "[154]\ttraining's auc: 0.853133\tvalid_1's auc: 0.727062\n",
      "[155]\ttraining's auc: 0.853094\tvalid_1's auc: 0.727062\n",
      "[156]\ttraining's auc: 0.853289\tvalid_1's auc: 0.726431\n",
      "[157]\ttraining's auc: 0.854207\tvalid_1's auc: 0.727273\n",
      "[158]\ttraining's auc: 0.853751\tvalid_1's auc: 0.726221\n",
      "[159]\ttraining's auc: 0.854259\tvalid_1's auc: 0.72601\n",
      "[160]\ttraining's auc: 0.854636\tvalid_1's auc: 0.727062\n",
      "[161]\ttraining's auc: 0.854532\tvalid_1's auc: 0.726431\n",
      "[162]\ttraining's auc: 0.85448\tvalid_1's auc: 0.726221\n",
      "[163]\ttraining's auc: 0.854584\tvalid_1's auc: 0.728325\n",
      "[164]\ttraining's auc: 0.854844\tvalid_1's auc: 0.728535\n",
      "[165]\ttraining's auc: 0.854662\tvalid_1's auc: 0.728325\n",
      "[166]\ttraining's auc: 0.854675\tvalid_1's auc: 0.728535\n",
      "[167]\ttraining's auc: 0.855104\tvalid_1's auc: 0.726641\n",
      "[168]\ttraining's auc: 0.85526\tvalid_1's auc: 0.726641\n",
      "[169]\ttraining's auc: 0.85552\tvalid_1's auc: 0.727273\n",
      "[170]\ttraining's auc: 0.855677\tvalid_1's auc: 0.726431\n",
      "[171]\ttraining's auc: 0.855533\tvalid_1's auc: 0.728535\n",
      "[172]\ttraining's auc: 0.855638\tvalid_1's auc: 0.728325\n",
      "[173]\ttraining's auc: 0.855664\tvalid_1's auc: 0.72601\n",
      "[174]\ttraining's auc: 0.855742\tvalid_1's auc: 0.727273\n",
      "[175]\ttraining's auc: 0.856093\tvalid_1's auc: 0.728535\n",
      "[176]\ttraining's auc: 0.855729\tvalid_1's auc: 0.728746\n",
      "[177]\ttraining's auc: 0.855924\tvalid_1's auc: 0.728114\n",
      "[178]\ttraining's auc: 0.855989\tvalid_1's auc: 0.727273\n",
      "[179]\ttraining's auc: 0.855898\tvalid_1's auc: 0.727483\n",
      "[180]\ttraining's auc: 0.856015\tvalid_1's auc: 0.727694\n",
      "[181]\ttraining's auc: 0.855885\tvalid_1's auc: 0.728535\n",
      "[182]\ttraining's auc: 0.856223\tvalid_1's auc: 0.728325\n",
      "[183]\ttraining's auc: 0.856145\tvalid_1's auc: 0.73085\n",
      "[184]\ttraining's auc: 0.856288\tvalid_1's auc: 0.73085\n",
      "[185]\ttraining's auc: 0.856548\tvalid_1's auc: 0.73064\n",
      "[186]\ttraining's auc: 0.856561\tvalid_1's auc: 0.731061\n",
      "[187]\ttraining's auc: 0.856652\tvalid_1's auc: 0.731271\n",
      "[188]\ttraining's auc: 0.856782\tvalid_1's auc: 0.729798\n",
      "[189]\ttraining's auc: 0.857016\tvalid_1's auc: 0.729798\n",
      "[190]\ttraining's auc: 0.856912\tvalid_1's auc: 0.731692\n",
      "[191]\ttraining's auc: 0.857003\tvalid_1's auc: 0.731271\n",
      "[192]\ttraining's auc: 0.857264\tvalid_1's auc: 0.733165\n",
      "[193]\ttraining's auc: 0.85742\tvalid_1's auc: 0.732955\n",
      "[194]\ttraining's auc: 0.857719\tvalid_1's auc: 0.732113\n",
      "[195]\ttraining's auc: 0.858031\tvalid_1's auc: 0.732534\n",
      "[196]\ttraining's auc: 0.857667\tvalid_1's auc: 0.733586\n",
      "[197]\ttraining's auc: 0.858044\tvalid_1's auc: 0.733586\n",
      "[198]\ttraining's auc: 0.858265\tvalid_1's auc: 0.732744\n",
      "[199]\ttraining's auc: 0.858395\tvalid_1's auc: 0.732955\n",
      "[200]\ttraining's auc: 0.858369\tvalid_1's auc: 0.732955\n",
      "[201]\ttraining's auc: 0.858239\tvalid_1's auc: 0.732955\n",
      "[202]\ttraining's auc: 0.858526\tvalid_1's auc: 0.732113\n",
      "[203]\ttraining's auc: 0.858643\tvalid_1's auc: 0.731481\n",
      "[204]\ttraining's auc: 0.858766\tvalid_1's auc: 0.734428\n",
      "[205]\ttraining's auc: 0.858766\tvalid_1's auc: 0.735269\n",
      "[206]\ttraining's auc: 0.858779\tvalid_1's auc: 0.733796\n",
      "[207]\ttraining's auc: 0.858779\tvalid_1's auc: 0.734428\n",
      "[208]\ttraining's auc: 0.858727\tvalid_1's auc: 0.736322\n",
      "[209]\ttraining's auc: 0.858909\tvalid_1's auc: 0.733796\n",
      "[210]\ttraining's auc: 0.858805\tvalid_1's auc: 0.736322\n",
      "[211]\ttraining's auc: 0.859052\tvalid_1's auc: 0.73569\n",
      "[212]\ttraining's auc: 0.859026\tvalid_1's auc: 0.736111\n",
      "[213]\ttraining's auc: 0.85913\tvalid_1's auc: 0.734638\n",
      "[214]\ttraining's auc: 0.859313\tvalid_1's auc: 0.734217\n",
      "[215]\ttraining's auc: 0.859495\tvalid_1's auc: 0.734217\n",
      "[216]\ttraining's auc: 0.860041\tvalid_1's auc: 0.734428\n",
      "[217]\ttraining's auc: 0.859677\tvalid_1's auc: 0.734428\n",
      "[218]\ttraining's auc: 0.859534\tvalid_1's auc: 0.732323\n",
      "[219]\ttraining's auc: 0.86034\tvalid_1's auc: 0.731902\n",
      "[220]\ttraining's auc: 0.859905\tvalid_1's auc: 0.731692\n",
      "[221]\ttraining's auc: 0.860581\tvalid_1's auc: 0.731692\n",
      "[222]\ttraining's auc: 0.860165\tvalid_1's auc: 0.731271\n",
      "[223]\ttraining's auc: 0.860464\tvalid_1's auc: 0.731692\n",
      "[224]\ttraining's auc: 0.860789\tvalid_1's auc: 0.731481\n",
      "[225]\ttraining's auc: 0.860971\tvalid_1's auc: 0.731692\n",
      "[226]\ttraining's auc: 0.861166\tvalid_1's auc: 0.731061\n",
      "[227]\ttraining's auc: 0.860984\tvalid_1's auc: 0.730219\n",
      "[228]\ttraining's auc: 0.861114\tvalid_1's auc: 0.731481\n",
      "[229]\ttraining's auc: 0.861375\tvalid_1's auc: 0.730429\n",
      "[230]\ttraining's auc: 0.861192\tvalid_1's auc: 0.730429\n",
      "[231]\ttraining's auc: 0.861296\tvalid_1's auc: 0.730429\n",
      "[232]\ttraining's auc: 0.861492\tvalid_1's auc: 0.731692\n",
      "[233]\ttraining's auc: 0.861492\tvalid_1's auc: 0.731692\n",
      "[234]\ttraining's auc: 0.861583\tvalid_1's auc: 0.731271\n",
      "[235]\ttraining's auc: 0.861505\tvalid_1's auc: 0.731692\n",
      "[236]\ttraining's auc: 0.861349\tvalid_1's auc: 0.731061\n",
      "[237]\ttraining's auc: 0.861479\tvalid_1's auc: 0.732113\n",
      "[238]\ttraining's auc: 0.861531\tvalid_1's auc: 0.732323\n",
      "[239]\ttraining's auc: 0.861583\tvalid_1's auc: 0.729798\n",
      "[240]\ttraining's auc: 0.861466\tvalid_1's auc: 0.729588\n",
      "[241]\ttraining's auc: 0.861622\tvalid_1's auc: 0.729588\n",
      "[242]\ttraining's auc: 0.861661\tvalid_1's auc: 0.731271\n",
      "[243]\ttraining's auc: 0.86183\tvalid_1's auc: 0.73085\n",
      "[244]\ttraining's auc: 0.8617\tvalid_1's auc: 0.731061\n",
      "[245]\ttraining's auc: 0.862012\tvalid_1's auc: 0.730219\n",
      "[246]\ttraining's auc: 0.862142\tvalid_1's auc: 0.729798\n",
      "[247]\ttraining's auc: 0.862142\tvalid_1's auc: 0.730429\n",
      "[248]\ttraining's auc: 0.862259\tvalid_1's auc: 0.730008\n",
      "[249]\ttraining's auc: 0.862272\tvalid_1's auc: 0.730219\n",
      "[250]\ttraining's auc: 0.862129\tvalid_1's auc: 0.730429\n",
      "[251]\ttraining's auc: 0.862233\tvalid_1's auc: 0.73064\n",
      "[252]\ttraining's auc: 0.862116\tvalid_1's auc: 0.731061\n",
      "[253]\ttraining's auc: 0.862194\tvalid_1's auc: 0.731902\n",
      "[254]\ttraining's auc: 0.862259\tvalid_1's auc: 0.730008\n",
      "[255]\ttraining's auc: 0.862246\tvalid_1's auc: 0.73064\n",
      "[256]\ttraining's auc: 0.862324\tvalid_1's auc: 0.728114\n",
      "[257]\ttraining's auc: 0.86235\tvalid_1's auc: 0.728114\n",
      "[258]\ttraining's auc: 0.862194\tvalid_1's auc: 0.727904\n",
      "[259]\ttraining's auc: 0.862402\tvalid_1's auc: 0.727483\n",
      "[260]\ttraining's auc: 0.862506\tvalid_1's auc: 0.727483\n",
      "[261]\ttraining's auc: 0.862519\tvalid_1's auc: 0.727273\n",
      "[262]\ttraining's auc: 0.862506\tvalid_1's auc: 0.727483\n",
      "[263]\ttraining's auc: 0.862649\tvalid_1's auc: 0.727694\n",
      "[264]\ttraining's auc: 0.862584\tvalid_1's auc: 0.727483\n",
      "[265]\ttraining's auc: 0.86278\tvalid_1's auc: 0.727904\n",
      "[266]\ttraining's auc: 0.862767\tvalid_1's auc: 0.728114\n",
      "[267]\ttraining's auc: 0.863001\tvalid_1's auc: 0.728746\n",
      "[268]\ttraining's auc: 0.862949\tvalid_1's auc: 0.728325\n",
      "[269]\ttraining's auc: 0.863027\tvalid_1's auc: 0.726431\n",
      "[270]\ttraining's auc: 0.863105\tvalid_1's auc: 0.725168\n",
      "[271]\ttraining's auc: 0.863222\tvalid_1's auc: 0.726641\n",
      "[272]\ttraining's auc: 0.863313\tvalid_1's auc: 0.726852\n",
      "[273]\ttraining's auc: 0.863313\tvalid_1's auc: 0.726641\n",
      "[274]\ttraining's auc: 0.863196\tvalid_1's auc: 0.726431\n",
      "[275]\ttraining's auc: 0.863339\tvalid_1's auc: 0.725379\n",
      "[276]\ttraining's auc: 0.863287\tvalid_1's auc: 0.726641\n",
      "[277]\ttraining's auc: 0.863586\tvalid_1's auc: 0.726852\n",
      "[278]\ttraining's auc: 0.863508\tvalid_1's auc: 0.726852\n",
      "[279]\ttraining's auc: 0.863677\tvalid_1's auc: 0.725589\n",
      "[280]\ttraining's auc: 0.863554\tvalid_1's auc: 0.728114\n",
      "[281]\ttraining's auc: 0.863684\tvalid_1's auc: 0.726852\n",
      "[282]\ttraining's auc: 0.863645\tvalid_1's auc: 0.728535\n",
      "[283]\ttraining's auc: 0.863658\tvalid_1's auc: 0.727062\n",
      "[284]\ttraining's auc: 0.863775\tvalid_1's auc: 0.725168\n",
      "[285]\ttraining's auc: 0.863801\tvalid_1's auc: 0.725589\n",
      "[286]\ttraining's auc: 0.863827\tvalid_1's auc: 0.7258\n",
      "[287]\ttraining's auc: 0.863788\tvalid_1's auc: 0.725589\n",
      "[288]\ttraining's auc: 0.863918\tvalid_1's auc: 0.7258\n",
      "[289]\ttraining's auc: 0.863892\tvalid_1's auc: 0.72601\n",
      "[290]\ttraining's auc: 0.864074\tvalid_1's auc: 0.726221\n",
      "[291]\ttraining's auc: 0.864165\tvalid_1's auc: 0.726221\n",
      "[292]\ttraining's auc: 0.864191\tvalid_1's auc: 0.726221\n",
      "[293]\ttraining's auc: 0.864074\tvalid_1's auc: 0.7258\n",
      "[294]\ttraining's auc: 0.864139\tvalid_1's auc: 0.726221\n",
      "[295]\ttraining's auc: 0.864295\tvalid_1's auc: 0.724537\n",
      "[296]\ttraining's auc: 0.864503\tvalid_1's auc: 0.723485\n",
      "[297]\ttraining's auc: 0.864529\tvalid_1's auc: 0.723695\n",
      "[298]\ttraining's auc: 0.86449\tvalid_1's auc: 0.723274\n",
      "[299]\ttraining's auc: 0.864633\tvalid_1's auc: 0.723485\n",
      "[300]\ttraining's auc: 0.864646\tvalid_1's auc: 0.723485\n",
      "[301]\ttraining's auc: 0.864594\tvalid_1's auc: 0.723485\n",
      "[302]\ttraining's auc: 0.864646\tvalid_1's auc: 0.723485\n",
      "[303]\ttraining's auc: 0.864724\tvalid_1's auc: 0.723695\n",
      "[304]\ttraining's auc: 0.864724\tvalid_1's auc: 0.723695\n",
      "[305]\ttraining's auc: 0.864828\tvalid_1's auc: 0.722433\n",
      "[306]\ttraining's auc: 0.864881\tvalid_1's auc: 0.722643\n",
      "[307]\ttraining's auc: 0.86475\tvalid_1's auc: 0.723695\n",
      "[308]\ttraining's auc: 0.864868\tvalid_1's auc: 0.724537\n",
      "Early stopping, best iteration is:\n",
      "[208]\ttraining's auc: 0.858727\tvalid_1's auc: 0.736322\n",
      "[検証用データ]acc:0.7113\n",
      "[ベースライン検証用データ]acc:0.7207\n",
      "-------------------- 4 --------------------\n",
      "(570, 2) (570, 1)\n",
      "(142, 2) (142, 1)\n",
      "y_tr:0.383, y_tr1:0.382, y_va1:0.387\n",
      "[1]\ttraining's auc: 0.756978\tvalid_1's auc: 0.755904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.758979\tvalid_1's auc: 0.754545\n",
      "[3]\ttraining's auc: 0.759402\tvalid_1's auc: 0.747544\n",
      "[4]\ttraining's auc: 0.759396\tvalid_1's auc: 0.743783\n",
      "[5]\ttraining's auc: 0.761383\tvalid_1's auc: 0.745559\n",
      "[6]\ttraining's auc: 0.760406\tvalid_1's auc: 0.744932\n",
      "[7]\ttraining's auc: 0.76094\tvalid_1's auc: 0.745141\n",
      "[8]\ttraining's auc: 0.761989\tvalid_1's auc: 0.747649\n",
      "[9]\ttraining's auc: 0.771059\tvalid_1's auc: 0.750888\n",
      "[10]\ttraining's auc: 0.773587\tvalid_1's auc: 0.751306\n",
      "[11]\ttraining's auc: 0.777099\tvalid_1's auc: 0.751097\n",
      "[12]\ttraining's auc: 0.780983\tvalid_1's auc: 0.749112\n",
      "[13]\ttraining's auc: 0.783537\tvalid_1's auc: 0.752142\n",
      "[14]\ttraining's auc: 0.788672\tvalid_1's auc: 0.760711\n",
      "[15]\ttraining's auc: 0.791115\tvalid_1's auc: 0.761546\n",
      "[16]\ttraining's auc: 0.79131\tvalid_1's auc: 0.764472\n",
      "[17]\ttraining's auc: 0.793115\tvalid_1's auc: 0.765622\n",
      "[18]\ttraining's auc: 0.79537\tvalid_1's auc: 0.767503\n",
      "[19]\ttraining's auc: 0.794653\tvalid_1's auc: 0.770742\n",
      "[20]\ttraining's auc: 0.795161\tvalid_1's auc: 0.772205\n",
      "[21]\ttraining's auc: 0.795839\tvalid_1's auc: 0.773459\n",
      "[22]\ttraining's auc: 0.797742\tvalid_1's auc: 0.770324\n",
      "[23]\ttraining's auc: 0.798224\tvalid_1's auc: 0.770951\n",
      "[24]\ttraining's auc: 0.800576\tvalid_1's auc: 0.77534\n",
      "[25]\ttraining's auc: 0.800426\tvalid_1's auc: 0.771682\n",
      "[26]\ttraining's auc: 0.801371\tvalid_1's auc: 0.773668\n",
      "[27]\ttraining's auc: 0.803195\tvalid_1's auc: 0.773877\n",
      "[28]\ttraining's auc: 0.803365\tvalid_1's auc: 0.775758\n",
      "[29]\ttraining's auc: 0.805033\tvalid_1's auc: 0.770115\n",
      "[30]\ttraining's auc: 0.80429\tvalid_1's auc: 0.774713\n",
      "[31]\ttraining's auc: 0.806792\tvalid_1's auc: 0.77325\n",
      "[32]\ttraining's auc: 0.807111\tvalid_1's auc: 0.770742\n",
      "[33]\ttraining's auc: 0.807828\tvalid_1's auc: 0.769697\n",
      "[34]\ttraining's auc: 0.808415\tvalid_1's auc: 0.773354\n",
      "[35]\ttraining's auc: 0.80816\tvalid_1's auc: 0.770846\n",
      "[36]\ttraining's auc: 0.808955\tvalid_1's auc: 0.770846\n",
      "[37]\ttraining's auc: 0.809503\tvalid_1's auc: 0.775444\n",
      "[38]\ttraining's auc: 0.811314\tvalid_1's auc: 0.775653\n",
      "[39]\ttraining's auc: 0.810702\tvalid_1's auc: 0.771055\n",
      "[40]\ttraining's auc: 0.811119\tvalid_1's auc: 0.771891\n",
      "[41]\ttraining's auc: 0.811575\tvalid_1's auc: 0.771264\n",
      "[42]\ttraining's auc: 0.812063\tvalid_1's auc: 0.770219\n",
      "[43]\ttraining's auc: 0.814442\tvalid_1's auc: 0.768548\n",
      "[44]\ttraining's auc: 0.813399\tvalid_1's auc: 0.767503\n",
      "[45]\ttraining's auc: 0.814833\tvalid_1's auc: 0.771682\n",
      "[46]\ttraining's auc: 0.815536\tvalid_1's auc: 0.768966\n",
      "[47]\ttraining's auc: 0.81641\tvalid_1's auc: 0.767921\n",
      "[48]\ttraining's auc: 0.8168\tvalid_1's auc: 0.769383\n",
      "[49]\ttraining's auc: 0.817283\tvalid_1's auc: 0.767921\n",
      "[50]\ttraining's auc: 0.817413\tvalid_1's auc: 0.766458\n",
      "[51]\ttraining's auc: 0.818573\tvalid_1's auc: 0.768757\n",
      "[52]\ttraining's auc: 0.818742\tvalid_1's auc: 0.767712\n",
      "[53]\ttraining's auc: 0.819329\tvalid_1's auc: 0.769175\n",
      "[54]\ttraining's auc: 0.819237\tvalid_1's auc: 0.769801\n",
      "[55]\ttraining's auc: 0.819811\tvalid_1's auc: 0.77001\n",
      "[56]\ttraining's auc: 0.82013\tvalid_1's auc: 0.770428\n",
      "[57]\ttraining's auc: 0.820651\tvalid_1's auc: 0.770428\n",
      "[58]\ttraining's auc: 0.822124\tvalid_1's auc: 0.770637\n",
      "[59]\ttraining's auc: 0.821863\tvalid_1's auc: 0.771891\n",
      "[60]\ttraining's auc: 0.822463\tvalid_1's auc: 0.7721\n",
      "[61]\ttraining's auc: 0.823238\tvalid_1's auc: 0.77419\n",
      "[62]\ttraining's auc: 0.823264\tvalid_1's auc: 0.773563\n",
      "[63]\ttraining's auc: 0.823082\tvalid_1's auc: 0.772309\n",
      "[64]\ttraining's auc: 0.823381\tvalid_1's auc: 0.772936\n",
      "[65]\ttraining's auc: 0.823512\tvalid_1's auc: 0.773354\n",
      "[66]\ttraining's auc: 0.823655\tvalid_1's auc: 0.773354\n",
      "[67]\ttraining's auc: 0.825102\tvalid_1's auc: 0.7721\n",
      "[68]\ttraining's auc: 0.824867\tvalid_1's auc: 0.772727\n",
      "[69]\ttraining's auc: 0.826587\tvalid_1's auc: 0.771891\n",
      "[70]\ttraining's auc: 0.825493\tvalid_1's auc: 0.772727\n",
      "[71]\ttraining's auc: 0.827043\tvalid_1's auc: 0.771055\n",
      "[72]\ttraining's auc: 0.826692\tvalid_1's auc: 0.770846\n",
      "[73]\ttraining's auc: 0.827408\tvalid_1's auc: 0.771473\n",
      "[74]\ttraining's auc: 0.827773\tvalid_1's auc: 0.773563\n",
      "[75]\ttraining's auc: 0.827916\tvalid_1's auc: 0.772727\n",
      "[76]\ttraining's auc: 0.828203\tvalid_1's auc: 0.773145\n",
      "[77]\ttraining's auc: 0.828255\tvalid_1's auc: 0.773145\n",
      "[78]\ttraining's auc: 0.828249\tvalid_1's auc: 0.774399\n",
      "[79]\ttraining's auc: 0.828679\tvalid_1's auc: 0.774608\n",
      "[80]\ttraining's auc: 0.829396\tvalid_1's auc: 0.773981\n",
      "[81]\ttraining's auc: 0.829747\tvalid_1's auc: 0.773354\n",
      "[82]\ttraining's auc: 0.830595\tvalid_1's auc: 0.77419\n",
      "[83]\ttraining's auc: 0.830529\tvalid_1's auc: 0.773772\n",
      "[84]\ttraining's auc: 0.830503\tvalid_1's auc: 0.773145\n",
      "[85]\ttraining's auc: 0.830621\tvalid_1's auc: 0.772936\n",
      "[86]\ttraining's auc: 0.831402\tvalid_1's auc: 0.772309\n",
      "[87]\ttraining's auc: 0.831337\tvalid_1's auc: 0.775026\n",
      "[88]\ttraining's auc: 0.832132\tvalid_1's auc: 0.774608\n",
      "[89]\ttraining's auc: 0.833527\tvalid_1's auc: 0.774817\n",
      "[90]\ttraining's auc: 0.833344\tvalid_1's auc: 0.773145\n",
      "[91]\ttraining's auc: 0.833292\tvalid_1's auc: 0.774608\n",
      "[92]\ttraining's auc: 0.833448\tvalid_1's auc: 0.77419\n",
      "[93]\ttraining's auc: 0.833357\tvalid_1's auc: 0.774608\n",
      "[94]\ttraining's auc: 0.834178\tvalid_1's auc: 0.774399\n",
      "[95]\ttraining's auc: 0.834699\tvalid_1's auc: 0.772727\n",
      "[96]\ttraining's auc: 0.834465\tvalid_1's auc: 0.773563\n",
      "[97]\ttraining's auc: 0.834686\tvalid_1's auc: 0.774608\n",
      "[98]\ttraining's auc: 0.83556\tvalid_1's auc: 0.774399\n",
      "[99]\ttraining's auc: 0.835703\tvalid_1's auc: 0.774399\n",
      "[100]\ttraining's auc: 0.83509\tvalid_1's auc: 0.774608\n",
      "[101]\ttraining's auc: 0.83642\tvalid_1's auc: 0.775444\n",
      "[102]\ttraining's auc: 0.836641\tvalid_1's auc: 0.776907\n",
      "[103]\ttraining's auc: 0.836876\tvalid_1's auc: 0.777116\n",
      "[104]\ttraining's auc: 0.836602\tvalid_1's auc: 0.775444\n",
      "[105]\ttraining's auc: 0.836902\tvalid_1's auc: 0.775862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106]\ttraining's auc: 0.837371\tvalid_1's auc: 0.77628\n",
      "[107]\ttraining's auc: 0.837397\tvalid_1's auc: 0.774817\n",
      "[108]\ttraining's auc: 0.837306\tvalid_1's auc: 0.776071\n",
      "[109]\ttraining's auc: 0.837254\tvalid_1's auc: 0.774608\n",
      "[110]\ttraining's auc: 0.837553\tvalid_1's auc: 0.773772\n",
      "[111]\ttraining's auc: 0.837905\tvalid_1's auc: 0.774399\n",
      "[112]\ttraining's auc: 0.838062\tvalid_1's auc: 0.774817\n",
      "[113]\ttraining's auc: 0.838427\tvalid_1's auc: 0.775444\n",
      "[114]\ttraining's auc: 0.838309\tvalid_1's auc: 0.775026\n",
      "[115]\ttraining's auc: 0.839248\tvalid_1's auc: 0.775653\n",
      "[116]\ttraining's auc: 0.838909\tvalid_1's auc: 0.775026\n",
      "[117]\ttraining's auc: 0.839691\tvalid_1's auc: 0.776489\n",
      "[118]\ttraining's auc: 0.839612\tvalid_1's auc: 0.775862\n",
      "[119]\ttraining's auc: 0.839417\tvalid_1's auc: 0.773981\n",
      "[120]\ttraining's auc: 0.840264\tvalid_1's auc: 0.775235\n",
      "[121]\ttraining's auc: 0.84059\tvalid_1's auc: 0.774817\n",
      "[122]\ttraining's auc: 0.840603\tvalid_1's auc: 0.776071\n",
      "[123]\ttraining's auc: 0.840955\tvalid_1's auc: 0.77628\n",
      "[124]\ttraining's auc: 0.840668\tvalid_1's auc: 0.775862\n",
      "[125]\ttraining's auc: 0.841411\tvalid_1's auc: 0.77628\n",
      "[126]\ttraining's auc: 0.841437\tvalid_1's auc: 0.775653\n",
      "[127]\ttraining's auc: 0.841489\tvalid_1's auc: 0.777534\n",
      "[128]\ttraining's auc: 0.841776\tvalid_1's auc: 0.776071\n",
      "[129]\ttraining's auc: 0.841919\tvalid_1's auc: 0.776698\n",
      "[130]\ttraining's auc: 0.84201\tvalid_1's auc: 0.776698\n",
      "[131]\ttraining's auc: 0.842271\tvalid_1's auc: 0.776907\n",
      "[132]\ttraining's auc: 0.842206\tvalid_1's auc: 0.776489\n",
      "[133]\ttraining's auc: 0.842401\tvalid_1's auc: 0.776907\n",
      "[134]\ttraining's auc: 0.842349\tvalid_1's auc: 0.776698\n",
      "[135]\ttraining's auc: 0.842597\tvalid_1's auc: 0.775235\n",
      "[136]\ttraining's auc: 0.842805\tvalid_1's auc: 0.774608\n",
      "[137]\ttraining's auc: 0.84287\tvalid_1's auc: 0.775235\n",
      "[138]\ttraining's auc: 0.843326\tvalid_1's auc: 0.774399\n",
      "[139]\ttraining's auc: 0.843835\tvalid_1's auc: 0.775653\n",
      "[140]\ttraining's auc: 0.843509\tvalid_1's auc: 0.776071\n",
      "[141]\ttraining's auc: 0.843874\tvalid_1's auc: 0.77419\n",
      "[142]\ttraining's auc: 0.844056\tvalid_1's auc: 0.775862\n",
      "[143]\ttraining's auc: 0.844004\tvalid_1's auc: 0.775862\n",
      "[144]\ttraining's auc: 0.844382\tvalid_1's auc: 0.776071\n",
      "[145]\ttraining's auc: 0.844564\tvalid_1's auc: 0.777116\n",
      "[146]\ttraining's auc: 0.845021\tvalid_1's auc: 0.77628\n",
      "[147]\ttraining's auc: 0.844734\tvalid_1's auc: 0.775444\n",
      "[148]\ttraining's auc: 0.844903\tvalid_1's auc: 0.775862\n",
      "[149]\ttraining's auc: 0.84476\tvalid_1's auc: 0.775862\n",
      "[150]\ttraining's auc: 0.844877\tvalid_1's auc: 0.775653\n",
      "[151]\ttraining's auc: 0.844838\tvalid_1's auc: 0.777325\n",
      "[152]\ttraining's auc: 0.845086\tvalid_1's auc: 0.776698\n",
      "[153]\ttraining's auc: 0.845242\tvalid_1's auc: 0.777952\n",
      "[154]\ttraining's auc: 0.845503\tvalid_1's auc: 0.776907\n",
      "[155]\ttraining's auc: 0.84562\tvalid_1's auc: 0.777534\n",
      "[156]\ttraining's auc: 0.845555\tvalid_1's auc: 0.776907\n",
      "[157]\ttraining's auc: 0.84575\tvalid_1's auc: 0.776907\n",
      "[158]\ttraining's auc: 0.845842\tvalid_1's auc: 0.773772\n",
      "[159]\ttraining's auc: 0.84592\tvalid_1's auc: 0.773563\n",
      "[160]\ttraining's auc: 0.845959\tvalid_1's auc: 0.773354\n",
      "[161]\ttraining's auc: 0.846519\tvalid_1's auc: 0.773354\n",
      "[162]\ttraining's auc: 0.846167\tvalid_1's auc: 0.773563\n",
      "[163]\ttraining's auc: 0.846376\tvalid_1's auc: 0.771682\n",
      "[164]\ttraining's auc: 0.846154\tvalid_1's auc: 0.773354\n",
      "[165]\ttraining's auc: 0.846545\tvalid_1's auc: 0.773145\n",
      "[166]\ttraining's auc: 0.846793\tvalid_1's auc: 0.773145\n",
      "[167]\ttraining's auc: 0.847158\tvalid_1's auc: 0.773145\n",
      "[168]\ttraining's auc: 0.847405\tvalid_1's auc: 0.772309\n",
      "[169]\ttraining's auc: 0.847275\tvalid_1's auc: 0.773145\n",
      "[170]\ttraining's auc: 0.847497\tvalid_1's auc: 0.7721\n",
      "[171]\ttraining's auc: 0.847523\tvalid_1's auc: 0.772518\n",
      "[172]\ttraining's auc: 0.847431\tvalid_1's auc: 0.772727\n",
      "[173]\ttraining's auc: 0.847809\tvalid_1's auc: 0.772518\n",
      "[174]\ttraining's auc: 0.848435\tvalid_1's auc: 0.77419\n",
      "[175]\ttraining's auc: 0.848239\tvalid_1's auc: 0.774817\n",
      "[176]\ttraining's auc: 0.847992\tvalid_1's auc: 0.775026\n",
      "[177]\ttraining's auc: 0.848213\tvalid_1's auc: 0.775235\n",
      "[178]\ttraining's auc: 0.848461\tvalid_1's auc: 0.77419\n",
      "[179]\ttraining's auc: 0.848722\tvalid_1's auc: 0.776907\n",
      "[180]\ttraining's auc: 0.848774\tvalid_1's auc: 0.777116\n",
      "[181]\ttraining's auc: 0.848656\tvalid_1's auc: 0.777116\n",
      "[182]\ttraining's auc: 0.848904\tvalid_1's auc: 0.777534\n",
      "[183]\ttraining's auc: 0.848969\tvalid_1's auc: 0.777534\n",
      "[184]\ttraining's auc: 0.848917\tvalid_1's auc: 0.776698\n",
      "[185]\ttraining's auc: 0.849295\tvalid_1's auc: 0.775653\n",
      "[186]\ttraining's auc: 0.849373\tvalid_1's auc: 0.773145\n",
      "[187]\ttraining's auc: 0.850351\tvalid_1's auc: 0.776698\n",
      "[188]\ttraining's auc: 0.850344\tvalid_1's auc: 0.774608\n",
      "[189]\ttraining's auc: 0.850409\tvalid_1's auc: 0.773145\n",
      "[190]\ttraining's auc: 0.850422\tvalid_1's auc: 0.772936\n",
      "[191]\ttraining's auc: 0.850409\tvalid_1's auc: 0.772936\n",
      "[192]\ttraining's auc: 0.850526\tvalid_1's auc: 0.773981\n",
      "[193]\ttraining's auc: 0.850122\tvalid_1's auc: 0.772936\n",
      "[194]\ttraining's auc: 0.850787\tvalid_1's auc: 0.7721\n",
      "[195]\ttraining's auc: 0.850657\tvalid_1's auc: 0.772727\n",
      "[196]\ttraining's auc: 0.850957\tvalid_1's auc: 0.771473\n",
      "[197]\ttraining's auc: 0.851048\tvalid_1's auc: 0.771682\n",
      "[198]\ttraining's auc: 0.851048\tvalid_1's auc: 0.771473\n",
      "[199]\ttraining's auc: 0.851269\tvalid_1's auc: 0.771891\n",
      "[200]\ttraining's auc: 0.851165\tvalid_1's auc: 0.771473\n",
      "[201]\ttraining's auc: 0.851217\tvalid_1's auc: 0.772727\n",
      "[202]\ttraining's auc: 0.851413\tvalid_1's auc: 0.772727\n",
      "[203]\ttraining's auc: 0.851465\tvalid_1's auc: 0.772518\n",
      "[204]\ttraining's auc: 0.851269\tvalid_1's auc: 0.772518\n",
      "[205]\ttraining's auc: 0.851817\tvalid_1's auc: 0.774817\n",
      "[206]\ttraining's auc: 0.851712\tvalid_1's auc: 0.775235\n",
      "[207]\ttraining's auc: 0.851608\tvalid_1's auc: 0.775444\n",
      "[208]\ttraining's auc: 0.851804\tvalid_1's auc: 0.771473\n",
      "[209]\ttraining's auc: 0.852312\tvalid_1's auc: 0.774608\n",
      "[210]\ttraining's auc: 0.852155\tvalid_1's auc: 0.774817\n",
      "[211]\ttraining's auc: 0.852963\tvalid_1's auc: 0.774608\n",
      "[212]\ttraining's auc: 0.852729\tvalid_1's auc: 0.774399\n",
      "[213]\ttraining's auc: 0.852403\tvalid_1's auc: 0.775235\n",
      "[214]\ttraining's auc: 0.852155\tvalid_1's auc: 0.775026\n",
      "[215]\ttraining's auc: 0.852416\tvalid_1's auc: 0.7721\n",
      "[216]\ttraining's auc: 0.852664\tvalid_1's auc: 0.775235\n",
      "[217]\ttraining's auc: 0.852599\tvalid_1's auc: 0.774817\n",
      "[218]\ttraining's auc: 0.852651\tvalid_1's auc: 0.772727\n",
      "[219]\ttraining's auc: 0.852794\tvalid_1's auc: 0.77001\n",
      "[220]\ttraining's auc: 0.853159\tvalid_1's auc: 0.771682\n",
      "[221]\ttraining's auc: 0.853016\tvalid_1's auc: 0.771264\n",
      "[222]\ttraining's auc: 0.853211\tvalid_1's auc: 0.771264\n",
      "[223]\ttraining's auc: 0.853367\tvalid_1's auc: 0.771473\n",
      "[224]\ttraining's auc: 0.853433\tvalid_1's auc: 0.771682\n",
      "[225]\ttraining's auc: 0.853354\tvalid_1's auc: 0.770637\n",
      "[226]\ttraining's auc: 0.853498\tvalid_1's auc: 0.775026\n",
      "[227]\ttraining's auc: 0.853576\tvalid_1's auc: 0.775026\n",
      "[228]\ttraining's auc: 0.853472\tvalid_1's auc: 0.771473\n",
      "[229]\ttraining's auc: 0.853641\tvalid_1's auc: 0.771682\n",
      "[230]\ttraining's auc: 0.853928\tvalid_1's auc: 0.771891\n",
      "[231]\ttraining's auc: 0.853876\tvalid_1's auc: 0.771682\n",
      "[232]\ttraining's auc: 0.853837\tvalid_1's auc: 0.776489\n",
      "[233]\ttraining's auc: 0.854188\tvalid_1's auc: 0.771055\n",
      "[234]\ttraining's auc: 0.853667\tvalid_1's auc: 0.772936\n",
      "[235]\ttraining's auc: 0.854071\tvalid_1's auc: 0.769801\n",
      "[236]\ttraining's auc: 0.85411\tvalid_1's auc: 0.771055\n",
      "[237]\ttraining's auc: 0.854358\tvalid_1's auc: 0.767712\n",
      "[238]\ttraining's auc: 0.853889\tvalid_1's auc: 0.773981\n",
      "[239]\ttraining's auc: 0.854188\tvalid_1's auc: 0.76813\n",
      "[240]\ttraining's auc: 0.854058\tvalid_1's auc: 0.773563\n",
      "[241]\ttraining's auc: 0.854071\tvalid_1's auc: 0.768757\n",
      "[242]\ttraining's auc: 0.854618\tvalid_1's auc: 0.767921\n",
      "[243]\ttraining's auc: 0.854293\tvalid_1's auc: 0.76813\n",
      "[244]\ttraining's auc: 0.854345\tvalid_1's auc: 0.77001\n",
      "[245]\ttraining's auc: 0.854384\tvalid_1's auc: 0.767085\n",
      "[246]\ttraining's auc: 0.854332\tvalid_1's auc: 0.766458\n",
      "[247]\ttraining's auc: 0.85454\tvalid_1's auc: 0.766667\n",
      "[248]\ttraining's auc: 0.854762\tvalid_1's auc: 0.765622\n",
      "[249]\ttraining's auc: 0.855062\tvalid_1's auc: 0.767921\n",
      "[250]\ttraining's auc: 0.855114\tvalid_1's auc: 0.77001\n",
      "[251]\ttraining's auc: 0.855283\tvalid_1's auc: 0.769175\n",
      "[252]\ttraining's auc: 0.855075\tvalid_1's auc: 0.770428\n",
      "[253]\ttraining's auc: 0.855361\tvalid_1's auc: 0.771473\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's auc: 0.845242\tvalid_1's auc: 0.777952\n",
      "[検証用データ]acc:0.7113\n",
      "[ベースライン検証用データ]acc:0.7095\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'n_estimators': 100000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "imp = pd.DataFrame()\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "# x_tr, y_trのデータセットの分割の組み合わせをn_splits種類作成、それぞれのindexをリストで所持\n",
    "cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123).split(x_tr, y_tr))\n",
    "\n",
    "# クロスバリデーション\n",
    "for nfold in np.arange(n_splits):\n",
    "    print('-'*20, nfold, '-'*20)\n",
    "    # 学習データ(x_tr1,y_tr1)と検証データ(x_va1,y_va1)の分割\n",
    "    idx_tr, idx_va = cv[nfold][0], cv[nfold][1] # 各組合わせcv[tr],cv[va]のidxを格納\n",
    "    x_tr1, y_tr1 = x_tr.loc[idx_tr], y_tr.loc[idx_tr] # trindex -> 学習用データフレイム作成\n",
    "    x_va1, y_va1 = x_tr.loc[idx_va], y_tr.loc[idx_va] # vaindex -> 検証用データフレイム作成\n",
    "    print(x_tr1.shape, y_tr1.shape) # 学習データ\n",
    "    print(x_va1.shape, y_va1.shape) # 検証データ\n",
    "    print('y_tr:{:.3f}, y_tr1:{:.3f}, y_va1:{:.3f}'.format(y_tr['Survived'].mean(),\n",
    "                                               y_tr1['Survived'].mean(),\n",
    "                                               y_va1['Survived'].mean(),\n",
    "                                               ))\n",
    "    \n",
    "    # モデル学習\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(x_tr1, y_tr1,\n",
    "              eval_set = [(x_tr1, y_tr1), (x_va1, y_va1)],\n",
    "              callbacks=[lgb.early_stopping(stopping_rounds=100,\n",
    "                                            verbose=10)\n",
    "                         ])\n",
    "    \n",
    "    # 精度評価\n",
    "    y_va1_pred = model.predict(x_va1) \n",
    "    y_va_pred = model.predict(x_va)    \n",
    "    metric_va1 = accuracy_score(y_va1, y_va1_pred) # 検証用データ\n",
    "    metric_va = accuracy_score(y_va, y_va_pred) # ベースライン検証用データ\n",
    "    print(f'[検証用データ]acc:{metric_va1:.4f}')\n",
    "    print(f'[ベースライン検証用データ]acc:{metric_va:.4f}')\n",
    "    \n",
    "    metrics.append([nfold, metric_va1, metric_va])\n",
    "    _imp = pd.DataFrame({'col': x_tr.columns,\n",
    "                         'imp':model.feature_importances_,\n",
    "                         'nfold': nfold})\n",
    "    imp = pd.concat([imp, _imp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- result --------------------\n",
      "[[0.         0.69230769 0.69832402]\n",
      " [1.         0.70629371 0.70949721]\n",
      " [2.         0.73239437 0.70391061]\n",
      " [3.         0.71126761 0.72067039]\n",
      " [4.         0.71126761 0.70949721]]\n",
      "[cv]検証用データ: 0.711+-0.013, ベースライン検証用データ: 0.708+-0.007\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('-'*20, 'result', '-'*20)\n",
    "metrics = np.array(metrics)\n",
    "print(metrics)\n",
    "\n",
    "print('[cv]検証用データ: {:.3f}+-{:.3f}, ベースライン検証用データ: {:.3f}+-{:.3f}'.format(\n",
    "    metrics[:, 1].mean(), metrics[:, 1].std(),\n",
    "    metrics[:, 2].mean(), metrics[:, 2].std(),\n",
    "))\n",
    "\n",
    "imp = imp.groupby('col')['imp'].agg(['mean', 'std'])\n",
    "imp.columns = ['imp', 'imp_std']\n",
    "imp = imp.reset_index(drop=False)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数の重要度算出\n",
    "imp.sort_values('imp', ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証用データ\n",
      "[[75 12]\n",
      " [30 25]]\n",
      "[[0.52816901 0.08450704]\n",
      " [0.21126761 0.17605634]]\n",
      "ベースライン検証用データ\n",
      "[[87 23]\n",
      " [29 40]]\n",
      "[[0.48603352 0.12849162]\n",
      " [0.16201117 0.22346369]]\n"
     ]
    }
   ],
   "source": [
    "# 誤差分布\n",
    "print('検証用データ')\n",
    "print(confusion_matrix(y_va1, y_va1_pred))\n",
    "print(confusion_matrix(y_va1, y_va1_pred,  normalize='all')) # 全データを分母とした割合\n",
    "print('ベースライン検証用データ')\n",
    "print(confusion_matrix(y_va, y_va_pred))\n",
    "print(confusion_matrix(y_va, y_va_pred,  normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f37959a3a10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測値の分布比較\n",
    "y_va1_pred_prod = model.predict_proba(x_va1)[:, 1]\n",
    "y_va_pred_prod = model.predict_proba(x_va)[:, 1]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "fig.add_subplot(2, 1, 1)\n",
    "plt.title('検証データ')\n",
    "plt.hist(y_va1_pred_prod[np.array(y_va1).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va1_pred_prod[np.array(y_va1).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(2, 1, 2)\n",
    "plt.title('ベースライン検証データ')\n",
    "plt.hist(y_va_pred_prod[np.array(y_va).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va_pred_prod[np.array(y_va).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "x_test = df_test[['Pclass', 'Fare']]\n",
    "id_test = df_test[['PassengerId']]\n",
    "y_test_pred = model.predict(x_test)\n",
    "df_submit = pd.DataFrame({\n",
    "    'PassengerId': id_test['PassengerId'],\n",
    "    'Survived': y_test_pred\n",
    "})\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('c_submission_baseline.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
