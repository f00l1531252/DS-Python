{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベースライン作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, id_train = df[['Pclass', 'Fare']], df[['Survived']], df[['PassengerId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベースライン検証用データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベースライン検証用データ(x_va, y_va)の作成\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train,\n",
    "                                           test_size=0.2,\n",
    "                                           shuffle=True,\n",
    "                                           stratify=y_train,\n",
    "                                           random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスバリデーション(5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tr.loc[] 　ERROR:'Passing list-likes to .loc or [] with any missing labels is no longer supported\n",
    "# -> 存在しないキーに対して.locで参照しようとしているためエラーが発生。x_trはベースライン検証データを分割した際に欠損ができている。\n",
    "# indexを更新したら解決するか\n",
    "x_tr = x_tr.reset_index(drop=True)\n",
    "y_tr = y_tr.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(569, 2) (569, 1)\n",
      "(143, 2) (143, 1)\n",
      "y_tr:0.383, y_tr1:0.383, y_va1:0.385\n",
      "[1]\ttraining's binary_logloss: 0.644244\tvalid_1's binary_logloss: 0.654045\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.626498\tvalid_1's binary_logloss: 0.64288\n",
      "[3]\ttraining's binary_logloss: 0.612086\tvalid_1's binary_logloss: 0.636296\n",
      "[4]\ttraining's binary_logloss: 0.599696\tvalid_1's binary_logloss: 0.628585\n",
      "[5]\ttraining's binary_logloss: 0.589674\tvalid_1's binary_logloss: 0.624997\n",
      "[6]\ttraining's binary_logloss: 0.581299\tvalid_1's binary_logloss: 0.622469\n",
      "[7]\ttraining's binary_logloss: 0.573875\tvalid_1's binary_logloss: 0.618863\n",
      "[8]\ttraining's binary_logloss: 0.567687\tvalid_1's binary_logloss: 0.617064\n",
      "[9]\ttraining's binary_logloss: 0.562518\tvalid_1's binary_logloss: 0.615393\n",
      "[10]\ttraining's binary_logloss: 0.557819\tvalid_1's binary_logloss: 0.613938\n",
      "[11]\ttraining's binary_logloss: 0.551979\tvalid_1's binary_logloss: 0.612237\n",
      "[12]\ttraining's binary_logloss: 0.548599\tvalid_1's binary_logloss: 0.61159\n",
      "[13]\ttraining's binary_logloss: 0.545214\tvalid_1's binary_logloss: 0.610315\n",
      "[14]\ttraining's binary_logloss: 0.541196\tvalid_1's binary_logloss: 0.608647\n",
      "[15]\ttraining's binary_logloss: 0.537897\tvalid_1's binary_logloss: 0.608569\n",
      "[16]\ttraining's binary_logloss: 0.535288\tvalid_1's binary_logloss: 0.608325\n",
      "[17]\ttraining's binary_logloss: 0.532371\tvalid_1's binary_logloss: 0.606942\n",
      "[18]\ttraining's binary_logloss: 0.529945\tvalid_1's binary_logloss: 0.607205\n",
      "[19]\ttraining's binary_logloss: 0.527432\tvalid_1's binary_logloss: 0.606008\n",
      "[20]\ttraining's binary_logloss: 0.526126\tvalid_1's binary_logloss: 0.606467\n",
      "[21]\ttraining's binary_logloss: 0.524015\tvalid_1's binary_logloss: 0.603952\n",
      "[22]\ttraining's binary_logloss: 0.52278\tvalid_1's binary_logloss: 0.603167\n",
      "[23]\ttraining's binary_logloss: 0.521027\tvalid_1's binary_logloss: 0.602642\n",
      "[24]\ttraining's binary_logloss: 0.519544\tvalid_1's binary_logloss: 0.601542\n",
      "[25]\ttraining's binary_logloss: 0.517674\tvalid_1's binary_logloss: 0.600993\n",
      "[26]\ttraining's binary_logloss: 0.516223\tvalid_1's binary_logloss: 0.60035\n",
      "[27]\ttraining's binary_logloss: 0.514534\tvalid_1's binary_logloss: 0.600356\n",
      "[28]\ttraining's binary_logloss: 0.513401\tvalid_1's binary_logloss: 0.600431\n",
      "[29]\ttraining's binary_logloss: 0.51242\tvalid_1's binary_logloss: 0.600331\n",
      "[30]\ttraining's binary_logloss: 0.510674\tvalid_1's binary_logloss: 0.601003\n",
      "[31]\ttraining's binary_logloss: 0.509532\tvalid_1's binary_logloss: 0.59969\n",
      "[32]\ttraining's binary_logloss: 0.508698\tvalid_1's binary_logloss: 0.599854\n",
      "[33]\ttraining's binary_logloss: 0.507599\tvalid_1's binary_logloss: 0.600254\n",
      "[34]\ttraining's binary_logloss: 0.506739\tvalid_1's binary_logloss: 0.601326\n",
      "[35]\ttraining's binary_logloss: 0.504932\tvalid_1's binary_logloss: 0.602482\n",
      "[36]\ttraining's binary_logloss: 0.503845\tvalid_1's binary_logloss: 0.603145\n",
      "[37]\ttraining's binary_logloss: 0.502431\tvalid_1's binary_logloss: 0.604278\n",
      "[38]\ttraining's binary_logloss: 0.501507\tvalid_1's binary_logloss: 0.604578\n",
      "[39]\ttraining's binary_logloss: 0.500516\tvalid_1's binary_logloss: 0.603887\n",
      "[40]\ttraining's binary_logloss: 0.499485\tvalid_1's binary_logloss: 0.6029\n",
      "[41]\ttraining's binary_logloss: 0.498769\tvalid_1's binary_logloss: 0.6023\n",
      "[42]\ttraining's binary_logloss: 0.497434\tvalid_1's binary_logloss: 0.601088\n",
      "[43]\ttraining's binary_logloss: 0.496667\tvalid_1's binary_logloss: 0.600278\n",
      "[44]\ttraining's binary_logloss: 0.495794\tvalid_1's binary_logloss: 0.599801\n",
      "[45]\ttraining's binary_logloss: 0.494838\tvalid_1's binary_logloss: 0.599254\n",
      "[46]\ttraining's binary_logloss: 0.493972\tvalid_1's binary_logloss: 0.600012\n",
      "[47]\ttraining's binary_logloss: 0.493341\tvalid_1's binary_logloss: 0.599456\n",
      "[48]\ttraining's binary_logloss: 0.492512\tvalid_1's binary_logloss: 0.599766\n",
      "[49]\ttraining's binary_logloss: 0.491665\tvalid_1's binary_logloss: 0.599583\n",
      "[50]\ttraining's binary_logloss: 0.490859\tvalid_1's binary_logloss: 0.599011\n",
      "[51]\ttraining's binary_logloss: 0.490199\tvalid_1's binary_logloss: 0.599228\n",
      "[52]\ttraining's binary_logloss: 0.489416\tvalid_1's binary_logloss: 0.598352\n",
      "[53]\ttraining's binary_logloss: 0.488673\tvalid_1's binary_logloss: 0.598329\n",
      "[54]\ttraining's binary_logloss: 0.487942\tvalid_1's binary_logloss: 0.599596\n",
      "[55]\ttraining's binary_logloss: 0.487342\tvalid_1's binary_logloss: 0.599477\n",
      "[56]\ttraining's binary_logloss: 0.486758\tvalid_1's binary_logloss: 0.598425\n",
      "[57]\ttraining's binary_logloss: 0.486002\tvalid_1's binary_logloss: 0.598229\n",
      "[58]\ttraining's binary_logloss: 0.48518\tvalid_1's binary_logloss: 0.598419\n",
      "[59]\ttraining's binary_logloss: 0.484652\tvalid_1's binary_logloss: 0.59883\n",
      "[60]\ttraining's binary_logloss: 0.484122\tvalid_1's binary_logloss: 0.598658\n",
      "[61]\ttraining's binary_logloss: 0.483404\tvalid_1's binary_logloss: 0.599669\n",
      "[62]\ttraining's binary_logloss: 0.482849\tvalid_1's binary_logloss: 0.599739\n",
      "[63]\ttraining's binary_logloss: 0.482334\tvalid_1's binary_logloss: 0.598087\n",
      "[64]\ttraining's binary_logloss: 0.481845\tvalid_1's binary_logloss: 0.598436\n",
      "[65]\ttraining's binary_logloss: 0.481354\tvalid_1's binary_logloss: 0.5983\n",
      "[66]\ttraining's binary_logloss: 0.480728\tvalid_1's binary_logloss: 0.598608\n",
      "[67]\ttraining's binary_logloss: 0.480086\tvalid_1's binary_logloss: 0.599198\n",
      "[68]\ttraining's binary_logloss: 0.479599\tvalid_1's binary_logloss: 0.598801\n",
      "[69]\ttraining's binary_logloss: 0.479088\tvalid_1's binary_logloss: 0.598177\n",
      "[70]\ttraining's binary_logloss: 0.478596\tvalid_1's binary_logloss: 0.598244\n",
      "[71]\ttraining's binary_logloss: 0.478016\tvalid_1's binary_logloss: 0.598676\n",
      "[72]\ttraining's binary_logloss: 0.477571\tvalid_1's binary_logloss: 0.598708\n",
      "[73]\ttraining's binary_logloss: 0.477155\tvalid_1's binary_logloss: 0.598341\n",
      "[74]\ttraining's binary_logloss: 0.476765\tvalid_1's binary_logloss: 0.598385\n",
      "[75]\ttraining's binary_logloss: 0.476241\tvalid_1's binary_logloss: 0.598996\n",
      "[76]\ttraining's binary_logloss: 0.475726\tvalid_1's binary_logloss: 0.598453\n",
      "[77]\ttraining's binary_logloss: 0.475319\tvalid_1's binary_logloss: 0.598602\n",
      "[78]\ttraining's binary_logloss: 0.474966\tvalid_1's binary_logloss: 0.598325\n",
      "[79]\ttraining's binary_logloss: 0.474409\tvalid_1's binary_logloss: 0.598331\n",
      "[80]\ttraining's binary_logloss: 0.474076\tvalid_1's binary_logloss: 0.59837\n",
      "[81]\ttraining's binary_logloss: 0.473675\tvalid_1's binary_logloss: 0.597824\n",
      "[82]\ttraining's binary_logloss: 0.473225\tvalid_1's binary_logloss: 0.598155\n",
      "[83]\ttraining's binary_logloss: 0.472813\tvalid_1's binary_logloss: 0.598777\n",
      "[84]\ttraining's binary_logloss: 0.472437\tvalid_1's binary_logloss: 0.598154\n",
      "[85]\ttraining's binary_logloss: 0.47207\tvalid_1's binary_logloss: 0.598587\n",
      "[86]\ttraining's binary_logloss: 0.471724\tvalid_1's binary_logloss: 0.598007\n",
      "[87]\ttraining's binary_logloss: 0.471338\tvalid_1's binary_logloss: 0.598013\n",
      "[88]\ttraining's binary_logloss: 0.471026\tvalid_1's binary_logloss: 0.597724\n",
      "[89]\ttraining's binary_logloss: 0.470712\tvalid_1's binary_logloss: 0.598234\n",
      "[90]\ttraining's binary_logloss: 0.470366\tvalid_1's binary_logloss: 0.598777\n",
      "[91]\ttraining's binary_logloss: 0.469931\tvalid_1's binary_logloss: 0.599196\n",
      "[92]\ttraining's binary_logloss: 0.469556\tvalid_1's binary_logloss: 0.598836\n",
      "[93]\ttraining's binary_logloss: 0.469254\tvalid_1's binary_logloss: 0.599149\n",
      "[94]\ttraining's binary_logloss: 0.468824\tvalid_1's binary_logloss: 0.599453\n",
      "[95]\ttraining's binary_logloss: 0.468485\tvalid_1's binary_logloss: 0.599085\n",
      "[96]\ttraining's binary_logloss: 0.468183\tvalid_1's binary_logloss: 0.599056\n",
      "[97]\ttraining's binary_logloss: 0.467841\tvalid_1's binary_logloss: 0.598976\n",
      "[98]\ttraining's binary_logloss: 0.467488\tvalid_1's binary_logloss: 0.59891\n",
      "[99]\ttraining's binary_logloss: 0.467246\tvalid_1's binary_logloss: 0.59844\n",
      "[100]\ttraining's binary_logloss: 0.466915\tvalid_1's binary_logloss: 0.599245\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.466915\tvalid_1's binary_logloss: 0.599245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[検証用データ]acc:0.6923\n",
      "[ベースライン検証用データ]acc:0.6872\n",
      "-------------------- 1 --------------------\n",
      "(569, 2) (569, 1)\n",
      "(143, 2) (143, 1)\n",
      "y_tr:0.383, y_tr1:0.383, y_va1:0.385\n",
      "[1]\ttraining's binary_logloss: 0.647608\tvalid_1's binary_logloss: 0.648855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.633028\tvalid_1's binary_logloss: 0.634824\n",
      "[3]\ttraining's binary_logloss: 0.620704\tvalid_1's binary_logloss: 0.623418\n",
      "[4]\ttraining's binary_logloss: 0.610587\tvalid_1's binary_logloss: 0.613914\n",
      "[5]\ttraining's binary_logloss: 0.601796\tvalid_1's binary_logloss: 0.605919\n",
      "[6]\ttraining's binary_logloss: 0.594681\tvalid_1's binary_logloss: 0.599199\n",
      "[7]\ttraining's binary_logloss: 0.588585\tvalid_1's binary_logloss: 0.593092\n",
      "[8]\ttraining's binary_logloss: 0.583514\tvalid_1's binary_logloss: 0.588526\n",
      "[9]\ttraining's binary_logloss: 0.578301\tvalid_1's binary_logloss: 0.584517\n",
      "[10]\ttraining's binary_logloss: 0.574138\tvalid_1's binary_logloss: 0.581237\n",
      "[11]\ttraining's binary_logloss: 0.569166\tvalid_1's binary_logloss: 0.579392\n",
      "[12]\ttraining's binary_logloss: 0.565345\tvalid_1's binary_logloss: 0.577153\n",
      "[13]\ttraining's binary_logloss: 0.562068\tvalid_1's binary_logloss: 0.57583\n",
      "[14]\ttraining's binary_logloss: 0.559234\tvalid_1's binary_logloss: 0.574339\n",
      "[15]\ttraining's binary_logloss: 0.555537\tvalid_1's binary_logloss: 0.572645\n",
      "[16]\ttraining's binary_logloss: 0.55311\tvalid_1's binary_logloss: 0.571267\n",
      "[17]\ttraining's binary_logloss: 0.551337\tvalid_1's binary_logloss: 0.569663\n",
      "[18]\ttraining's binary_logloss: 0.548458\tvalid_1's binary_logloss: 0.568891\n",
      "[19]\ttraining's binary_logloss: 0.546752\tvalid_1's binary_logloss: 0.569509\n",
      "[20]\ttraining's binary_logloss: 0.545468\tvalid_1's binary_logloss: 0.569139\n",
      "[21]\ttraining's binary_logloss: 0.544221\tvalid_1's binary_logloss: 0.56799\n",
      "[22]\ttraining's binary_logloss: 0.542567\tvalid_1's binary_logloss: 0.568476\n",
      "[23]\ttraining's binary_logloss: 0.540564\tvalid_1's binary_logloss: 0.569463\n",
      "[24]\ttraining's binary_logloss: 0.53872\tvalid_1's binary_logloss: 0.569391\n",
      "[25]\ttraining's binary_logloss: 0.537504\tvalid_1's binary_logloss: 0.568935\n",
      "[26]\ttraining's binary_logloss: 0.53634\tvalid_1's binary_logloss: 0.569704\n",
      "[27]\ttraining's binary_logloss: 0.53481\tvalid_1's binary_logloss: 0.567903\n",
      "[28]\ttraining's binary_logloss: 0.533287\tvalid_1's binary_logloss: 0.568536\n",
      "[29]\ttraining's binary_logloss: 0.532496\tvalid_1's binary_logloss: 0.566753\n",
      "[30]\ttraining's binary_logloss: 0.531489\tvalid_1's binary_logloss: 0.56694\n",
      "[31]\ttraining's binary_logloss: 0.530579\tvalid_1's binary_logloss: 0.56609\n",
      "[32]\ttraining's binary_logloss: 0.529498\tvalid_1's binary_logloss: 0.566605\n",
      "[33]\ttraining's binary_logloss: 0.528301\tvalid_1's binary_logloss: 0.565102\n",
      "[34]\ttraining's binary_logloss: 0.527183\tvalid_1's binary_logloss: 0.566235\n",
      "[35]\ttraining's binary_logloss: 0.526156\tvalid_1's binary_logloss: 0.567575\n",
      "[36]\ttraining's binary_logloss: 0.52541\tvalid_1's binary_logloss: 0.568686\n",
      "[37]\ttraining's binary_logloss: 0.524654\tvalid_1's binary_logloss: 0.568812\n",
      "[38]\ttraining's binary_logloss: 0.523374\tvalid_1's binary_logloss: 0.569173\n",
      "[39]\ttraining's binary_logloss: 0.522552\tvalid_1's binary_logloss: 0.570072\n",
      "[40]\ttraining's binary_logloss: 0.521652\tvalid_1's binary_logloss: 0.570278\n",
      "[41]\ttraining's binary_logloss: 0.520933\tvalid_1's binary_logloss: 0.570514\n",
      "[42]\ttraining's binary_logloss: 0.51985\tvalid_1's binary_logloss: 0.571657\n",
      "[43]\ttraining's binary_logloss: 0.518738\tvalid_1's binary_logloss: 0.572044\n",
      "[44]\ttraining's binary_logloss: 0.517933\tvalid_1's binary_logloss: 0.572889\n",
      "[45]\ttraining's binary_logloss: 0.516999\tvalid_1's binary_logloss: 0.573756\n",
      "[46]\ttraining's binary_logloss: 0.516277\tvalid_1's binary_logloss: 0.574324\n",
      "[47]\ttraining's binary_logloss: 0.515512\tvalid_1's binary_logloss: 0.574374\n",
      "[48]\ttraining's binary_logloss: 0.51496\tvalid_1's binary_logloss: 0.574851\n",
      "[49]\ttraining's binary_logloss: 0.514277\tvalid_1's binary_logloss: 0.575318\n",
      "[50]\ttraining's binary_logloss: 0.513774\tvalid_1's binary_logloss: 0.574836\n",
      "[51]\ttraining's binary_logloss: 0.513208\tvalid_1's binary_logloss: 0.574212\n",
      "[52]\ttraining's binary_logloss: 0.512654\tvalid_1's binary_logloss: 0.57427\n",
      "[53]\ttraining's binary_logloss: 0.512074\tvalid_1's binary_logloss: 0.575267\n",
      "[54]\ttraining's binary_logloss: 0.511462\tvalid_1's binary_logloss: 0.576815\n",
      "[55]\ttraining's binary_logloss: 0.510922\tvalid_1's binary_logloss: 0.576767\n",
      "[56]\ttraining's binary_logloss: 0.510434\tvalid_1's binary_logloss: 0.577305\n",
      "[57]\ttraining's binary_logloss: 0.509835\tvalid_1's binary_logloss: 0.578381\n",
      "[58]\ttraining's binary_logloss: 0.509377\tvalid_1's binary_logloss: 0.577772\n",
      "[59]\ttraining's binary_logloss: 0.508894\tvalid_1's binary_logloss: 0.577591\n",
      "[60]\ttraining's binary_logloss: 0.508419\tvalid_1's binary_logloss: 0.578362\n",
      "[61]\ttraining's binary_logloss: 0.507458\tvalid_1's binary_logloss: 0.579263\n",
      "[62]\ttraining's binary_logloss: 0.506976\tvalid_1's binary_logloss: 0.579785\n",
      "[63]\ttraining's binary_logloss: 0.50645\tvalid_1's binary_logloss: 0.580244\n",
      "[64]\ttraining's binary_logloss: 0.506013\tvalid_1's binary_logloss: 0.580701\n",
      "[65]\ttraining's binary_logloss: 0.505625\tvalid_1's binary_logloss: 0.580355\n",
      "[66]\ttraining's binary_logloss: 0.505212\tvalid_1's binary_logloss: 0.580846\n",
      "[67]\ttraining's binary_logloss: 0.504322\tvalid_1's binary_logloss: 0.581001\n",
      "[68]\ttraining's binary_logloss: 0.503877\tvalid_1's binary_logloss: 0.581183\n",
      "[69]\ttraining's binary_logloss: 0.502931\tvalid_1's binary_logloss: 0.582118\n",
      "[70]\ttraining's binary_logloss: 0.502517\tvalid_1's binary_logloss: 0.582608\n",
      "[71]\ttraining's binary_logloss: 0.502163\tvalid_1's binary_logloss: 0.583037\n",
      "[72]\ttraining's binary_logloss: 0.501729\tvalid_1's binary_logloss: 0.582613\n",
      "[73]\ttraining's binary_logloss: 0.501296\tvalid_1's binary_logloss: 0.583371\n",
      "[74]\ttraining's binary_logloss: 0.500491\tvalid_1's binary_logloss: 0.584725\n",
      "[75]\ttraining's binary_logloss: 0.500141\tvalid_1's binary_logloss: 0.585198\n",
      "[76]\ttraining's binary_logloss: 0.499689\tvalid_1's binary_logloss: 0.585683\n",
      "[77]\ttraining's binary_logloss: 0.498902\tvalid_1's binary_logloss: 0.586517\n",
      "[78]\ttraining's binary_logloss: 0.498633\tvalid_1's binary_logloss: 0.587079\n",
      "[79]\ttraining's binary_logloss: 0.498101\tvalid_1's binary_logloss: 0.586769\n",
      "[80]\ttraining's binary_logloss: 0.497658\tvalid_1's binary_logloss: 0.586276\n",
      "[81]\ttraining's binary_logloss: 0.497322\tvalid_1's binary_logloss: 0.587123\n",
      "[82]\ttraining's binary_logloss: 0.496992\tvalid_1's binary_logloss: 0.587184\n",
      "[83]\ttraining's binary_logloss: 0.496673\tvalid_1's binary_logloss: 0.587706\n",
      "[84]\ttraining's binary_logloss: 0.496288\tvalid_1's binary_logloss: 0.588439\n",
      "[85]\ttraining's binary_logloss: 0.495564\tvalid_1's binary_logloss: 0.589494\n",
      "[86]\ttraining's binary_logloss: 0.495172\tvalid_1's binary_logloss: 0.590009\n",
      "[87]\ttraining's binary_logloss: 0.494565\tvalid_1's binary_logloss: 0.590882\n",
      "[88]\ttraining's binary_logloss: 0.4941\tvalid_1's binary_logloss: 0.590731\n",
      "[89]\ttraining's binary_logloss: 0.493692\tvalid_1's binary_logloss: 0.590854\n",
      "[90]\ttraining's binary_logloss: 0.493184\tvalid_1's binary_logloss: 0.591082\n",
      "[91]\ttraining's binary_logloss: 0.492705\tvalid_1's binary_logloss: 0.590817\n",
      "[92]\ttraining's binary_logloss: 0.492047\tvalid_1's binary_logloss: 0.590946\n",
      "[93]\ttraining's binary_logloss: 0.491589\tvalid_1's binary_logloss: 0.59089\n",
      "[94]\ttraining's binary_logloss: 0.491168\tvalid_1's binary_logloss: 0.591241\n",
      "[95]\ttraining's binary_logloss: 0.490703\tvalid_1's binary_logloss: 0.591094\n",
      "[96]\ttraining's binary_logloss: 0.490374\tvalid_1's binary_logloss: 0.590851\n",
      "[97]\ttraining's binary_logloss: 0.490015\tvalid_1's binary_logloss: 0.591178\n",
      "[98]\ttraining's binary_logloss: 0.489683\tvalid_1's binary_logloss: 0.591661\n",
      "[99]\ttraining's binary_logloss: 0.489422\tvalid_1's binary_logloss: 0.59167\n",
      "[100]\ttraining's binary_logloss: 0.489169\tvalid_1's binary_logloss: 0.591988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.489169\tvalid_1's binary_logloss: 0.591988\n",
      "[検証用データ]acc:0.6923\n",
      "[ベースライン検証用データ]acc:0.7095\n",
      "-------------------- 2 --------------------\n",
      "(570, 2) (570, 1)\n",
      "(142, 2) (142, 1)\n",
      "y_tr:0.383, y_tr1:0.384, y_va1:0.380\n",
      "[1]\ttraining's binary_logloss: 0.646843\tvalid_1's binary_logloss: 0.650747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.631397\tvalid_1's binary_logloss: 0.639788\n",
      "[3]\ttraining's binary_logloss: 0.618748\tvalid_1's binary_logloss: 0.631297\n",
      "[4]\ttraining's binary_logloss: 0.607969\tvalid_1's binary_logloss: 0.625014\n",
      "[5]\ttraining's binary_logloss: 0.598535\tvalid_1's binary_logloss: 0.61983\n",
      "[6]\ttraining's binary_logloss: 0.591103\tvalid_1's binary_logloss: 0.615996\n",
      "[7]\ttraining's binary_logloss: 0.58458\tvalid_1's binary_logloss: 0.612143\n",
      "[8]\ttraining's binary_logloss: 0.576418\tvalid_1's binary_logloss: 0.606718\n",
      "[9]\ttraining's binary_logloss: 0.569281\tvalid_1's binary_logloss: 0.602509\n",
      "[10]\ttraining's binary_logloss: 0.563291\tvalid_1's binary_logloss: 0.59988\n",
      "[11]\ttraining's binary_logloss: 0.558011\tvalid_1's binary_logloss: 0.596446\n",
      "[12]\ttraining's binary_logloss: 0.553632\tvalid_1's binary_logloss: 0.593854\n",
      "[13]\ttraining's binary_logloss: 0.549027\tvalid_1's binary_logloss: 0.593247\n",
      "[14]\ttraining's binary_logloss: 0.545155\tvalid_1's binary_logloss: 0.593294\n",
      "[15]\ttraining's binary_logloss: 0.54179\tvalid_1's binary_logloss: 0.591847\n",
      "[16]\ttraining's binary_logloss: 0.538721\tvalid_1's binary_logloss: 0.593144\n",
      "[17]\ttraining's binary_logloss: 0.536581\tvalid_1's binary_logloss: 0.593579\n",
      "[18]\ttraining's binary_logloss: 0.534625\tvalid_1's binary_logloss: 0.595817\n",
      "[19]\ttraining's binary_logloss: 0.531989\tvalid_1's binary_logloss: 0.596376\n",
      "[20]\ttraining's binary_logloss: 0.529708\tvalid_1's binary_logloss: 0.593837\n",
      "[21]\ttraining's binary_logloss: 0.528182\tvalid_1's binary_logloss: 0.59323\n",
      "[22]\ttraining's binary_logloss: 0.525977\tvalid_1's binary_logloss: 0.594405\n",
      "[23]\ttraining's binary_logloss: 0.524398\tvalid_1's binary_logloss: 0.59364\n",
      "[24]\ttraining's binary_logloss: 0.522907\tvalid_1's binary_logloss: 0.594367\n",
      "[25]\ttraining's binary_logloss: 0.521051\tvalid_1's binary_logloss: 0.595158\n",
      "[26]\ttraining's binary_logloss: 0.519656\tvalid_1's binary_logloss: 0.595798\n",
      "[27]\ttraining's binary_logloss: 0.518483\tvalid_1's binary_logloss: 0.594169\n",
      "[28]\ttraining's binary_logloss: 0.517067\tvalid_1's binary_logloss: 0.595176\n",
      "[29]\ttraining's binary_logloss: 0.51607\tvalid_1's binary_logloss: 0.593033\n",
      "[30]\ttraining's binary_logloss: 0.514775\tvalid_1's binary_logloss: 0.593292\n",
      "[31]\ttraining's binary_logloss: 0.513972\tvalid_1's binary_logloss: 0.59146\n",
      "[32]\ttraining's binary_logloss: 0.51267\tvalid_1's binary_logloss: 0.592909\n",
      "[33]\ttraining's binary_logloss: 0.511298\tvalid_1's binary_logloss: 0.593453\n",
      "[34]\ttraining's binary_logloss: 0.510239\tvalid_1's binary_logloss: 0.592624\n",
      "[35]\ttraining's binary_logloss: 0.509279\tvalid_1's binary_logloss: 0.593252\n",
      "[36]\ttraining's binary_logloss: 0.508212\tvalid_1's binary_logloss: 0.592123\n",
      "[37]\ttraining's binary_logloss: 0.507135\tvalid_1's binary_logloss: 0.592641\n",
      "[38]\ttraining's binary_logloss: 0.506099\tvalid_1's binary_logloss: 0.591444\n",
      "[39]\ttraining's binary_logloss: 0.505233\tvalid_1's binary_logloss: 0.591585\n",
      "[40]\ttraining's binary_logloss: 0.504134\tvalid_1's binary_logloss: 0.591432\n",
      "[41]\ttraining's binary_logloss: 0.503315\tvalid_1's binary_logloss: 0.59153\n",
      "[42]\ttraining's binary_logloss: 0.502284\tvalid_1's binary_logloss: 0.589929\n",
      "[43]\ttraining's binary_logloss: 0.501484\tvalid_1's binary_logloss: 0.591554\n",
      "[44]\ttraining's binary_logloss: 0.500892\tvalid_1's binary_logloss: 0.590889\n",
      "[45]\ttraining's binary_logloss: 0.500011\tvalid_1's binary_logloss: 0.590678\n",
      "[46]\ttraining's binary_logloss: 0.499352\tvalid_1's binary_logloss: 0.590339\n",
      "[47]\ttraining's binary_logloss: 0.498478\tvalid_1's binary_logloss: 0.589663\n",
      "[48]\ttraining's binary_logloss: 0.497775\tvalid_1's binary_logloss: 0.588811\n",
      "[49]\ttraining's binary_logloss: 0.497167\tvalid_1's binary_logloss: 0.588963\n",
      "[50]\ttraining's binary_logloss: 0.496441\tvalid_1's binary_logloss: 0.588396\n",
      "[51]\ttraining's binary_logloss: 0.495872\tvalid_1's binary_logloss: 0.588827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[52]\ttraining's binary_logloss: 0.495285\tvalid_1's binary_logloss: 0.588423\n",
      "[53]\ttraining's binary_logloss: 0.4946\tvalid_1's binary_logloss: 0.58802\n",
      "[54]\ttraining's binary_logloss: 0.493947\tvalid_1's binary_logloss: 0.588625\n",
      "[55]\ttraining's binary_logloss: 0.493347\tvalid_1's binary_logloss: 0.588102\n",
      "[56]\ttraining's binary_logloss: 0.492778\tvalid_1's binary_logloss: 0.587837\n",
      "[57]\ttraining's binary_logloss: 0.492248\tvalid_1's binary_logloss: 0.587451\n",
      "[58]\ttraining's binary_logloss: 0.491688\tvalid_1's binary_logloss: 0.587049\n",
      "[59]\ttraining's binary_logloss: 0.491135\tvalid_1's binary_logloss: 0.587581\n",
      "[60]\ttraining's binary_logloss: 0.490715\tvalid_1's binary_logloss: 0.588052\n",
      "[61]\ttraining's binary_logloss: 0.490065\tvalid_1's binary_logloss: 0.587272\n",
      "[62]\ttraining's binary_logloss: 0.489563\tvalid_1's binary_logloss: 0.58743\n",
      "[63]\ttraining's binary_logloss: 0.489142\tvalid_1's binary_logloss: 0.588337\n",
      "[64]\ttraining's binary_logloss: 0.488592\tvalid_1's binary_logloss: 0.587724\n",
      "[65]\ttraining's binary_logloss: 0.488155\tvalid_1's binary_logloss: 0.587532\n",
      "[66]\ttraining's binary_logloss: 0.487626\tvalid_1's binary_logloss: 0.58707\n",
      "[67]\ttraining's binary_logloss: 0.487239\tvalid_1's binary_logloss: 0.587465\n",
      "[68]\ttraining's binary_logloss: 0.486818\tvalid_1's binary_logloss: 0.587342\n",
      "[69]\ttraining's binary_logloss: 0.486482\tvalid_1's binary_logloss: 0.588221\n",
      "[70]\ttraining's binary_logloss: 0.486093\tvalid_1's binary_logloss: 0.588959\n",
      "[71]\ttraining's binary_logloss: 0.485675\tvalid_1's binary_logloss: 0.588516\n",
      "[72]\ttraining's binary_logloss: 0.485274\tvalid_1's binary_logloss: 0.58869\n",
      "[73]\ttraining's binary_logloss: 0.484907\tvalid_1's binary_logloss: 0.588851\n",
      "[74]\ttraining's binary_logloss: 0.483992\tvalid_1's binary_logloss: 0.588025\n",
      "[75]\ttraining's binary_logloss: 0.483529\tvalid_1's binary_logloss: 0.588657\n",
      "[76]\ttraining's binary_logloss: 0.483135\tvalid_1's binary_logloss: 0.588486\n",
      "[77]\ttraining's binary_logloss: 0.482853\tvalid_1's binary_logloss: 0.588875\n",
      "[78]\ttraining's binary_logloss: 0.482422\tvalid_1's binary_logloss: 0.589189\n",
      "[79]\ttraining's binary_logloss: 0.481668\tvalid_1's binary_logloss: 0.589093\n",
      "[80]\ttraining's binary_logloss: 0.481335\tvalid_1's binary_logloss: 0.589012\n",
      "[81]\ttraining's binary_logloss: 0.481044\tvalid_1's binary_logloss: 0.589485\n",
      "[82]\ttraining's binary_logloss: 0.480743\tvalid_1's binary_logloss: 0.5895\n",
      "[83]\ttraining's binary_logloss: 0.480471\tvalid_1's binary_logloss: 0.589738\n",
      "[84]\ttraining's binary_logloss: 0.479868\tvalid_1's binary_logloss: 0.588803\n",
      "[85]\ttraining's binary_logloss: 0.479512\tvalid_1's binary_logloss: 0.588572\n",
      "[86]\ttraining's binary_logloss: 0.479239\tvalid_1's binary_logloss: 0.588994\n",
      "[87]\ttraining's binary_logloss: 0.478558\tvalid_1's binary_logloss: 0.588586\n",
      "[88]\ttraining's binary_logloss: 0.478206\tvalid_1's binary_logloss: 0.588262\n",
      "[89]\ttraining's binary_logloss: 0.477857\tvalid_1's binary_logloss: 0.588679\n",
      "[90]\ttraining's binary_logloss: 0.477501\tvalid_1's binary_logloss: 0.589429\n",
      "[91]\ttraining's binary_logloss: 0.477237\tvalid_1's binary_logloss: 0.589392\n",
      "[92]\ttraining's binary_logloss: 0.476658\tvalid_1's binary_logloss: 0.58994\n",
      "[93]\ttraining's binary_logloss: 0.476339\tvalid_1's binary_logloss: 0.589052\n",
      "[94]\ttraining's binary_logloss: 0.475963\tvalid_1's binary_logloss: 0.588641\n",
      "[95]\ttraining's binary_logloss: 0.475724\tvalid_1's binary_logloss: 0.58884\n",
      "[96]\ttraining's binary_logloss: 0.475037\tvalid_1's binary_logloss: 0.587681\n",
      "[97]\ttraining's binary_logloss: 0.474763\tvalid_1's binary_logloss: 0.587509\n",
      "[98]\ttraining's binary_logloss: 0.474453\tvalid_1's binary_logloss: 0.58724\n",
      "[99]\ttraining's binary_logloss: 0.474188\tvalid_1's binary_logloss: 0.58682\n",
      "[100]\ttraining's binary_logloss: 0.473659\tvalid_1's binary_logloss: 0.586348\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.473659\tvalid_1's binary_logloss: 0.586348\n",
      "[検証用データ]acc:0.7465\n",
      "[ベースライン検証用データ]acc:0.7486\n",
      "-------------------- 3 --------------------\n",
      "(570, 2) (570, 1)\n",
      "(142, 2) (142, 1)\n",
      "y_tr:0.383, y_tr1:0.384, y_va1:0.380\n",
      "[1]\ttraining's binary_logloss: 0.644946\tvalid_1's binary_logloss: 0.653816\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.627798\tvalid_1's binary_logloss: 0.646251\n",
      "[3]\ttraining's binary_logloss: 0.61374\tvalid_1's binary_logloss: 0.641141\n",
      "[4]\ttraining's binary_logloss: 0.602168\tvalid_1's binary_logloss: 0.637565\n",
      "[5]\ttraining's binary_logloss: 0.591953\tvalid_1's binary_logloss: 0.636198\n",
      "[6]\ttraining's binary_logloss: 0.583158\tvalid_1's binary_logloss: 0.632628\n",
      "[7]\ttraining's binary_logloss: 0.575767\tvalid_1's binary_logloss: 0.63125\n",
      "[8]\ttraining's binary_logloss: 0.569401\tvalid_1's binary_logloss: 0.630408\n",
      "[9]\ttraining's binary_logloss: 0.564015\tvalid_1's binary_logloss: 0.629335\n",
      "[10]\ttraining's binary_logloss: 0.559662\tvalid_1's binary_logloss: 0.62966\n",
      "[11]\ttraining's binary_logloss: 0.555081\tvalid_1's binary_logloss: 0.628401\n",
      "[12]\ttraining's binary_logloss: 0.550184\tvalid_1's binary_logloss: 0.627761\n",
      "[13]\ttraining's binary_logloss: 0.545783\tvalid_1's binary_logloss: 0.624538\n",
      "[14]\ttraining's binary_logloss: 0.541113\tvalid_1's binary_logloss: 0.623218\n",
      "[15]\ttraining's binary_logloss: 0.537598\tvalid_1's binary_logloss: 0.621864\n",
      "[16]\ttraining's binary_logloss: 0.534705\tvalid_1's binary_logloss: 0.620787\n",
      "[17]\ttraining's binary_logloss: 0.531187\tvalid_1's binary_logloss: 0.62025\n",
      "[18]\ttraining's binary_logloss: 0.528631\tvalid_1's binary_logloss: 0.619979\n",
      "[19]\ttraining's binary_logloss: 0.525886\tvalid_1's binary_logloss: 0.620199\n",
      "[20]\ttraining's binary_logloss: 0.5239\tvalid_1's binary_logloss: 0.619331\n",
      "[21]\ttraining's binary_logloss: 0.52219\tvalid_1's binary_logloss: 0.619506\n",
      "[22]\ttraining's binary_logloss: 0.520532\tvalid_1's binary_logloss: 0.618147\n",
      "[23]\ttraining's binary_logloss: 0.518592\tvalid_1's binary_logloss: 0.61783\n",
      "[24]\ttraining's binary_logloss: 0.517407\tvalid_1's binary_logloss: 0.618601\n",
      "[25]\ttraining's binary_logloss: 0.516084\tvalid_1's binary_logloss: 0.618918\n",
      "[26]\ttraining's binary_logloss: 0.514804\tvalid_1's binary_logloss: 0.617216\n",
      "[27]\ttraining's binary_logloss: 0.513854\tvalid_1's binary_logloss: 0.61786\n",
      "[28]\ttraining's binary_logloss: 0.51285\tvalid_1's binary_logloss: 0.617992\n",
      "[29]\ttraining's binary_logloss: 0.511431\tvalid_1's binary_logloss: 0.618639\n",
      "[30]\ttraining's binary_logloss: 0.509541\tvalid_1's binary_logloss: 0.617735\n",
      "[31]\ttraining's binary_logloss: 0.508797\tvalid_1's binary_logloss: 0.61878\n",
      "[32]\ttraining's binary_logloss: 0.507123\tvalid_1's binary_logloss: 0.618187\n",
      "[33]\ttraining's binary_logloss: 0.506148\tvalid_1's binary_logloss: 0.617026\n",
      "[34]\ttraining's binary_logloss: 0.504966\tvalid_1's binary_logloss: 0.615648\n",
      "[35]\ttraining's binary_logloss: 0.504055\tvalid_1's binary_logloss: 0.61571\n",
      "[36]\ttraining's binary_logloss: 0.503141\tvalid_1's binary_logloss: 0.615493\n",
      "[37]\ttraining's binary_logloss: 0.502349\tvalid_1's binary_logloss: 0.615712\n",
      "[38]\ttraining's binary_logloss: 0.500938\tvalid_1's binary_logloss: 0.614718\n",
      "[39]\ttraining's binary_logloss: 0.499688\tvalid_1's binary_logloss: 0.616086\n",
      "[40]\ttraining's binary_logloss: 0.498597\tvalid_1's binary_logloss: 0.616508\n",
      "[41]\ttraining's binary_logloss: 0.497539\tvalid_1's binary_logloss: 0.616366\n",
      "[42]\ttraining's binary_logloss: 0.496679\tvalid_1's binary_logloss: 0.616361\n",
      "[43]\ttraining's binary_logloss: 0.495861\tvalid_1's binary_logloss: 0.616844\n",
      "[44]\ttraining's binary_logloss: 0.495027\tvalid_1's binary_logloss: 0.616959\n",
      "[45]\ttraining's binary_logloss: 0.494315\tvalid_1's binary_logloss: 0.617915\n",
      "[46]\ttraining's binary_logloss: 0.49344\tvalid_1's binary_logloss: 0.617414\n",
      "[47]\ttraining's binary_logloss: 0.492799\tvalid_1's binary_logloss: 0.618197\n",
      "[48]\ttraining's binary_logloss: 0.491891\tvalid_1's binary_logloss: 0.616767\n",
      "[49]\ttraining's binary_logloss: 0.491039\tvalid_1's binary_logloss: 0.61728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[50]\ttraining's binary_logloss: 0.490393\tvalid_1's binary_logloss: 0.617723\n",
      "[51]\ttraining's binary_logloss: 0.489763\tvalid_1's binary_logloss: 0.617806\n",
      "[52]\ttraining's binary_logloss: 0.488993\tvalid_1's binary_logloss: 0.616269\n",
      "[53]\ttraining's binary_logloss: 0.488363\tvalid_1's binary_logloss: 0.616712\n",
      "[54]\ttraining's binary_logloss: 0.487624\tvalid_1's binary_logloss: 0.615949\n",
      "[55]\ttraining's binary_logloss: 0.487047\tvalid_1's binary_logloss: 0.61701\n",
      "[56]\ttraining's binary_logloss: 0.48646\tvalid_1's binary_logloss: 0.616898\n",
      "[57]\ttraining's binary_logloss: 0.48592\tvalid_1's binary_logloss: 0.617698\n",
      "[58]\ttraining's binary_logloss: 0.485446\tvalid_1's binary_logloss: 0.617363\n",
      "[59]\ttraining's binary_logloss: 0.484921\tvalid_1's binary_logloss: 0.618091\n",
      "[60]\ttraining's binary_logloss: 0.484252\tvalid_1's binary_logloss: 0.617257\n",
      "[61]\ttraining's binary_logloss: 0.483763\tvalid_1's binary_logloss: 0.616447\n",
      "[62]\ttraining's binary_logloss: 0.4832\tvalid_1's binary_logloss: 0.615854\n",
      "[63]\ttraining's binary_logloss: 0.482648\tvalid_1's binary_logloss: 0.616813\n",
      "[64]\ttraining's binary_logloss: 0.482186\tvalid_1's binary_logloss: 0.617383\n",
      "[65]\ttraining's binary_logloss: 0.481685\tvalid_1's binary_logloss: 0.616529\n",
      "[66]\ttraining's binary_logloss: 0.481187\tvalid_1's binary_logloss: 0.616703\n",
      "[67]\ttraining's binary_logloss: 0.480719\tvalid_1's binary_logloss: 0.617431\n",
      "[68]\ttraining's binary_logloss: 0.480261\tvalid_1's binary_logloss: 0.618888\n",
      "[69]\ttraining's binary_logloss: 0.479808\tvalid_1's binary_logloss: 0.618406\n",
      "[70]\ttraining's binary_logloss: 0.479407\tvalid_1's binary_logloss: 0.618317\n",
      "[71]\ttraining's binary_logloss: 0.478959\tvalid_1's binary_logloss: 0.618001\n",
      "[72]\ttraining's binary_logloss: 0.478505\tvalid_1's binary_logloss: 0.618416\n",
      "[73]\ttraining's binary_logloss: 0.477972\tvalid_1's binary_logloss: 0.61791\n",
      "[74]\ttraining's binary_logloss: 0.477563\tvalid_1's binary_logloss: 0.618952\n",
      "[75]\ttraining's binary_logloss: 0.477177\tvalid_1's binary_logloss: 0.618718\n",
      "[76]\ttraining's binary_logloss: 0.47656\tvalid_1's binary_logloss: 0.618216\n",
      "[77]\ttraining's binary_logloss: 0.476164\tvalid_1's binary_logloss: 0.618172\n",
      "[78]\ttraining's binary_logloss: 0.475801\tvalid_1's binary_logloss: 0.618119\n",
      "[79]\ttraining's binary_logloss: 0.475393\tvalid_1's binary_logloss: 0.617471\n",
      "[80]\ttraining's binary_logloss: 0.474912\tvalid_1's binary_logloss: 0.617594\n",
      "[81]\ttraining's binary_logloss: 0.474501\tvalid_1's binary_logloss: 0.616806\n",
      "[82]\ttraining's binary_logloss: 0.474174\tvalid_1's binary_logloss: 0.617064\n",
      "[83]\ttraining's binary_logloss: 0.473711\tvalid_1's binary_logloss: 0.618268\n",
      "[84]\ttraining's binary_logloss: 0.473369\tvalid_1's binary_logloss: 0.619124\n",
      "[85]\ttraining's binary_logloss: 0.472976\tvalid_1's binary_logloss: 0.618585\n",
      "[86]\ttraining's binary_logloss: 0.472602\tvalid_1's binary_logloss: 0.619081\n",
      "[87]\ttraining's binary_logloss: 0.472136\tvalid_1's binary_logloss: 0.618099\n",
      "[88]\ttraining's binary_logloss: 0.471766\tvalid_1's binary_logloss: 0.619216\n",
      "[89]\ttraining's binary_logloss: 0.471447\tvalid_1's binary_logloss: 0.619755\n",
      "[90]\ttraining's binary_logloss: 0.470954\tvalid_1's binary_logloss: 0.618346\n",
      "[91]\ttraining's binary_logloss: 0.470644\tvalid_1's binary_logloss: 0.617869\n",
      "[92]\ttraining's binary_logloss: 0.470294\tvalid_1's binary_logloss: 0.619167\n",
      "[93]\ttraining's binary_logloss: 0.469966\tvalid_1's binary_logloss: 0.619384\n",
      "[94]\ttraining's binary_logloss: 0.469478\tvalid_1's binary_logloss: 0.618514\n",
      "[95]\ttraining's binary_logloss: 0.469167\tvalid_1's binary_logloss: 0.61935\n",
      "[96]\ttraining's binary_logloss: 0.468791\tvalid_1's binary_logloss: 0.619111\n",
      "[97]\ttraining's binary_logloss: 0.468343\tvalid_1's binary_logloss: 0.620433\n",
      "[98]\ttraining's binary_logloss: 0.468047\tvalid_1's binary_logloss: 0.620432\n",
      "[99]\ttraining's binary_logloss: 0.467762\tvalid_1's binary_logloss: 0.621001\n",
      "[100]\ttraining's binary_logloss: 0.467472\tvalid_1's binary_logloss: 0.621258\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.467472\tvalid_1's binary_logloss: 0.621258\n",
      "[検証用データ]acc:0.6761\n",
      "[ベースライン検証用データ]acc:0.7151\n",
      "-------------------- 4 --------------------\n",
      "(570, 2) (570, 1)\n",
      "(142, 2) (142, 1)\n",
      "y_tr:0.383, y_tr1:0.382, y_va1:0.387\n",
      "[1]\ttraining's binary_logloss: 0.646728\tvalid_1's binary_logloss: 0.649966\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.631547\tvalid_1's binary_logloss: 0.636118\n",
      "[3]\ttraining's binary_logloss: 0.619575\tvalid_1's binary_logloss: 0.625336\n",
      "[4]\ttraining's binary_logloss: 0.609541\tvalid_1's binary_logloss: 0.616434\n",
      "[5]\ttraining's binary_logloss: 0.600925\tvalid_1's binary_logloss: 0.608679\n",
      "[6]\ttraining's binary_logloss: 0.593848\tvalid_1's binary_logloss: 0.602973\n",
      "[7]\ttraining's binary_logloss: 0.588072\tvalid_1's binary_logloss: 0.598202\n",
      "[8]\ttraining's binary_logloss: 0.58282\tvalid_1's binary_logloss: 0.593566\n",
      "[9]\ttraining's binary_logloss: 0.575855\tvalid_1's binary_logloss: 0.590707\n",
      "[10]\ttraining's binary_logloss: 0.569232\tvalid_1's binary_logloss: 0.586112\n",
      "[11]\ttraining's binary_logloss: 0.563413\tvalid_1's binary_logloss: 0.582732\n",
      "[12]\ttraining's binary_logloss: 0.558632\tvalid_1's binary_logloss: 0.579731\n",
      "[13]\ttraining's binary_logloss: 0.554871\tvalid_1's binary_logloss: 0.576912\n",
      "[14]\ttraining's binary_logloss: 0.550968\tvalid_1's binary_logloss: 0.57449\n",
      "[15]\ttraining's binary_logloss: 0.547862\tvalid_1's binary_logloss: 0.571837\n",
      "[16]\ttraining's binary_logloss: 0.544596\tvalid_1's binary_logloss: 0.570412\n",
      "[17]\ttraining's binary_logloss: 0.542088\tvalid_1's binary_logloss: 0.568494\n",
      "[18]\ttraining's binary_logloss: 0.539862\tvalid_1's binary_logloss: 0.568846\n",
      "[19]\ttraining's binary_logloss: 0.537839\tvalid_1's binary_logloss: 0.567643\n",
      "[20]\ttraining's binary_logloss: 0.535334\tvalid_1's binary_logloss: 0.566358\n",
      "[21]\ttraining's binary_logloss: 0.533476\tvalid_1's binary_logloss: 0.565345\n",
      "[22]\ttraining's binary_logloss: 0.531453\tvalid_1's binary_logloss: 0.565304\n",
      "[23]\ttraining's binary_logloss: 0.529837\tvalid_1's binary_logloss: 0.564672\n",
      "[24]\ttraining's binary_logloss: 0.528119\tvalid_1's binary_logloss: 0.564724\n",
      "[25]\ttraining's binary_logloss: 0.52721\tvalid_1's binary_logloss: 0.564454\n",
      "[26]\ttraining's binary_logloss: 0.526191\tvalid_1's binary_logloss: 0.563422\n",
      "[27]\ttraining's binary_logloss: 0.524885\tvalid_1's binary_logloss: 0.563684\n",
      "[28]\ttraining's binary_logloss: 0.523515\tvalid_1's binary_logloss: 0.563987\n",
      "[29]\ttraining's binary_logloss: 0.522631\tvalid_1's binary_logloss: 0.563676\n",
      "[30]\ttraining's binary_logloss: 0.521648\tvalid_1's binary_logloss: 0.564078\n",
      "[31]\ttraining's binary_logloss: 0.5201\tvalid_1's binary_logloss: 0.56387\n",
      "[32]\ttraining's binary_logloss: 0.519008\tvalid_1's binary_logloss: 0.564732\n",
      "[33]\ttraining's binary_logloss: 0.51816\tvalid_1's binary_logloss: 0.56564\n",
      "[34]\ttraining's binary_logloss: 0.516887\tvalid_1's binary_logloss: 0.565103\n",
      "[35]\ttraining's binary_logloss: 0.516055\tvalid_1's binary_logloss: 0.564625\n",
      "[36]\ttraining's binary_logloss: 0.515305\tvalid_1's binary_logloss: 0.565044\n",
      "[37]\ttraining's binary_logloss: 0.514362\tvalid_1's binary_logloss: 0.563621\n",
      "[38]\ttraining's binary_logloss: 0.513754\tvalid_1's binary_logloss: 0.563793\n",
      "[39]\ttraining's binary_logloss: 0.513213\tvalid_1's binary_logloss: 0.563815\n",
      "[40]\ttraining's binary_logloss: 0.51256\tvalid_1's binary_logloss: 0.563378\n",
      "[41]\ttraining's binary_logloss: 0.511722\tvalid_1's binary_logloss: 0.56219\n",
      "[42]\ttraining's binary_logloss: 0.511254\tvalid_1's binary_logloss: 0.562373\n",
      "[43]\ttraining's binary_logloss: 0.51067\tvalid_1's binary_logloss: 0.561721\n",
      "[44]\ttraining's binary_logloss: 0.5101\tvalid_1's binary_logloss: 0.561299\n",
      "[45]\ttraining's binary_logloss: 0.509582\tvalid_1's binary_logloss: 0.561342\n",
      "[46]\ttraining's binary_logloss: 0.509\tvalid_1's binary_logloss: 0.56165\n",
      "[47]\ttraining's binary_logloss: 0.508325\tvalid_1's binary_logloss: 0.560949\n",
      "[48]\ttraining's binary_logloss: 0.507897\tvalid_1's binary_logloss: 0.561242\n",
      "[49]\ttraining's binary_logloss: 0.507274\tvalid_1's binary_logloss: 0.560581\n",
      "[50]\ttraining's binary_logloss: 0.506871\tvalid_1's binary_logloss: 0.560887\n",
      "[51]\ttraining's binary_logloss: 0.505959\tvalid_1's binary_logloss: 0.560854\n",
      "[52]\ttraining's binary_logloss: 0.505425\tvalid_1's binary_logloss: 0.560814\n",
      "[53]\ttraining's binary_logloss: 0.504986\tvalid_1's binary_logloss: 0.560168\n",
      "[54]\ttraining's binary_logloss: 0.504561\tvalid_1's binary_logloss: 0.559951\n",
      "[55]\ttraining's binary_logloss: 0.503861\tvalid_1's binary_logloss: 0.559969\n",
      "[56]\ttraining's binary_logloss: 0.503385\tvalid_1's binary_logloss: 0.559382\n",
      "[57]\ttraining's binary_logloss: 0.502893\tvalid_1's binary_logloss: 0.559422\n",
      "[58]\ttraining's binary_logloss: 0.502213\tvalid_1's binary_logloss: 0.559547\n",
      "[59]\ttraining's binary_logloss: 0.501765\tvalid_1's binary_logloss: 0.558911\n",
      "[60]\ttraining's binary_logloss: 0.501183\tvalid_1's binary_logloss: 0.559819\n",
      "[61]\ttraining's binary_logloss: 0.500651\tvalid_1's binary_logloss: 0.55897\n",
      "[62]\ttraining's binary_logloss: 0.500136\tvalid_1's binary_logloss: 0.558656\n",
      "[63]\ttraining's binary_logloss: 0.499657\tvalid_1's binary_logloss: 0.558278\n",
      "[64]\ttraining's binary_logloss: 0.499238\tvalid_1's binary_logloss: 0.558043\n",
      "[65]\ttraining's binary_logloss: 0.49887\tvalid_1's binary_logloss: 0.558013\n",
      "[66]\ttraining's binary_logloss: 0.498499\tvalid_1's binary_logloss: 0.557576\n",
      "[67]\ttraining's binary_logloss: 0.498131\tvalid_1's binary_logloss: 0.557795\n",
      "[68]\ttraining's binary_logloss: 0.49772\tvalid_1's binary_logloss: 0.557319\n",
      "[69]\ttraining's binary_logloss: 0.497005\tvalid_1's binary_logloss: 0.557446\n",
      "[70]\ttraining's binary_logloss: 0.496647\tvalid_1's binary_logloss: 0.557619\n",
      "[71]\ttraining's binary_logloss: 0.496304\tvalid_1's binary_logloss: 0.557203\n",
      "[72]\ttraining's binary_logloss: 0.495974\tvalid_1's binary_logloss: 0.557408\n",
      "[73]\ttraining's binary_logloss: 0.495697\tvalid_1's binary_logloss: 0.557009\n",
      "[74]\ttraining's binary_logloss: 0.495054\tvalid_1's binary_logloss: 0.557329\n",
      "[75]\ttraining's binary_logloss: 0.494636\tvalid_1's binary_logloss: 0.558071\n",
      "[76]\ttraining's binary_logloss: 0.494266\tvalid_1's binary_logloss: 0.557875\n",
      "[77]\ttraining's binary_logloss: 0.493949\tvalid_1's binary_logloss: 0.557934\n",
      "[78]\ttraining's binary_logloss: 0.493645\tvalid_1's binary_logloss: 0.558093\n",
      "[79]\ttraining's binary_logloss: 0.49338\tvalid_1's binary_logloss: 0.557822\n",
      "[80]\ttraining's binary_logloss: 0.493076\tvalid_1's binary_logloss: 0.558228\n",
      "[81]\ttraining's binary_logloss: 0.492514\tvalid_1's binary_logloss: 0.55874\n",
      "[82]\ttraining's binary_logloss: 0.492201\tvalid_1's binary_logloss: 0.558258\n",
      "[83]\ttraining's binary_logloss: 0.491759\tvalid_1's binary_logloss: 0.55819\n",
      "[84]\ttraining's binary_logloss: 0.49147\tvalid_1's binary_logloss: 0.558512\n",
      "[85]\ttraining's binary_logloss: 0.490968\tvalid_1's binary_logloss: 0.558991\n",
      "[86]\ttraining's binary_logloss: 0.490655\tvalid_1's binary_logloss: 0.558996\n",
      "[87]\ttraining's binary_logloss: 0.49038\tvalid_1's binary_logloss: 0.559093\n",
      "[88]\ttraining's binary_logloss: 0.489681\tvalid_1's binary_logloss: 0.559242\n",
      "[89]\ttraining's binary_logloss: 0.489328\tvalid_1's binary_logloss: 0.559097\n",
      "[90]\ttraining's binary_logloss: 0.489051\tvalid_1's binary_logloss: 0.558724\n",
      "[91]\ttraining's binary_logloss: 0.48877\tvalid_1's binary_logloss: 0.558464\n",
      "[92]\ttraining's binary_logloss: 0.488251\tvalid_1's binary_logloss: 0.558764\n",
      "[93]\ttraining's binary_logloss: 0.487976\tvalid_1's binary_logloss: 0.559096\n",
      "[94]\ttraining's binary_logloss: 0.487597\tvalid_1's binary_logloss: 0.558869\n",
      "[95]\ttraining's binary_logloss: 0.487253\tvalid_1's binary_logloss: 0.559127\n",
      "[96]\ttraining's binary_logloss: 0.487022\tvalid_1's binary_logloss: 0.559202\n",
      "[97]\ttraining's binary_logloss: 0.486661\tvalid_1's binary_logloss: 0.559446\n",
      "[98]\ttraining's binary_logloss: 0.486306\tvalid_1's binary_logloss: 0.559714\n",
      "[99]\ttraining's binary_logloss: 0.486065\tvalid_1's binary_logloss: 0.560106\n",
      "[100]\ttraining's binary_logloss: 0.48588\tvalid_1's binary_logloss: 0.559898\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.48588\tvalid_1's binary_logloss: 0.559898\n",
      "[検証用データ]acc:0.7042\n",
      "[ベースライン検証用データ]acc:0.7095\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'n_estimators': 100000,\n",
    "    'random_state': 123,\n",
    "    'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "imp = pd.DataFrame()\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "# x_tr, y_trのデータセットの分割の組み合わせをn_splits種類作成、それぞれのindexをリストで所持\n",
    "cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123).split(x_tr, y_tr))\n",
    "\n",
    "# クロスバリデーション\n",
    "for nfold in np.arange(n_splits):\n",
    "    print('-'*20, nfold, '-'*20)\n",
    "    # 学習データ(x_tr1,y_tr1)と検証データ(x_va1,y_va1)の分割\n",
    "    idx_tr, idx_va = cv[nfold][0], cv[nfold][1] # 各組合わせcv[tr],cv[va]のidxを格納\n",
    "    x_tr1, y_tr1 = x_tr.loc[idx_tr], y_tr.loc[idx_tr] # trindex -> 学習用データフレイム作成\n",
    "    x_va1, y_va1 = x_tr.loc[idx_va], y_tr.loc[idx_va] # vaindex -> 検証用データフレイム作成\n",
    "    print(x_tr1.shape, y_tr1.shape) # 学習データ\n",
    "    print(x_va1.shape, y_va1.shape) # 検証データ\n",
    "    print('y_tr:{:.3f}, y_tr1:{:.3f}, y_va1:{:.3f}'.format(y_tr['Survived'].mean(),\n",
    "                                               y_tr1['Survived'].mean(),\n",
    "                                               y_va1['Survived'].mean(),\n",
    "                                               ))\n",
    "    \n",
    "    # モデル学習\n",
    "    model = lgb.LGBMClassifier()\n",
    "    model.fit(x_tr1, y_tr1,\n",
    "              eval_set = [(x_tr1, y_tr1), (x_va1, y_va1)],\n",
    "              callbacks=[lgb.early_stopping(stopping_rounds=100,\n",
    "                                            verbose=10)\n",
    "                         ])\n",
    "    \n",
    "    # 精度評価\n",
    "    y_va1_pred = model.predict(x_va1) \n",
    "    y_va_pred = model.predict(x_va)    \n",
    "    metric_va1 = accuracy_score(y_va1, y_va1_pred) # 検証用データ\n",
    "    metric_va = accuracy_score(y_va, y_va_pred) # ベースライン検証用データ\n",
    "    print(f'[検証用データ]acc:{metric_va1:.4f}')\n",
    "    print(f'[ベースライン検証用データ]acc:{metric_va:.4f}')\n",
    "    \n",
    "    metrics.append([nfold, metric_va1, metric_va])\n",
    "    _imp = pd.DataFrame({'col': x_tr.columns,\n",
    "                         'imp':model.feature_importances_,\n",
    "                         'nfold': nfold})\n",
    "    imp = pd.concat([imp, _imp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*20, 'result', '-'*20)\n",
    "metrics = np.array(metrics)\n",
    "print(metrics)\n",
    "\n",
    "print('[cv]検証用データ: {:.3f}+-{:.3f}, ベースライン検証用データ: {:.3f}+-{:.3f}'.format(\n",
    "    metrics[:, 1].mean(), metrics[:, 1].std(),\n",
    "    metrics[:, 2].mean(), metrics[:, 2].std(),\n",
    "))\n",
    "\n",
    "imp = imp.groupby('col')['imp'].agg(['mean', 'std'])\n",
    "imp.columns = ['imp', 'imp_std']\n",
    "imp = imp.reset_index(drop=False)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>19.697716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>115.8</td>\n",
       "      <td>12.872451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col     imp    imp_std\n",
       "0    Fare  1776.0  19.697716\n",
       "1  Pclass   115.8  12.872451"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 説明変数の重要度算出\n",
    "imp.sort_values('imp', ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証用データ\n",
      "[[75 12]\n",
      " [30 25]]\n",
      "[[0.52816901 0.08450704]\n",
      " [0.21126761 0.17605634]]\n",
      "ベースライン検証用データ\n",
      "[[87 23]\n",
      " [29 40]]\n",
      "[[0.48603352 0.12849162]\n",
      " [0.16201117 0.22346369]]\n"
     ]
    }
   ],
   "source": [
    "# 誤差分布\n",
    "print('検証用データ')\n",
    "print(confusion_matrix(y_va1, y_va1_pred))\n",
    "print(confusion_matrix(y_va1, y_va1_pred,  normalize='all')) # 全データを分母とした割合\n",
    "print('ベースライン検証用データ')\n",
    "print(confusion_matrix(y_va, y_va_pred))\n",
    "print(confusion_matrix(y_va, y_va_pred,  normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f37959a3a10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測値の分布比較\n",
    "y_va1_pred_prod = model.predict_proba(x_va1)[:, 1]\n",
    "y_va_pred_prod = model.predict_proba(x_va)[:, 1]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "fig.add_subplot(2, 1, 1)\n",
    "plt.title('検証データ')\n",
    "plt.hist(y_va1_pred_prod[np.array(y_va1).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va1_pred_prod[np.array(y_va1).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(2, 1, 2)\n",
    "plt.title('ベースライン検証データ')\n",
    "plt.hist(y_va_pred_prod[np.array(y_va).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va_pred_prod[np.array(y_va).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "x_test = df_test[['Pclass', 'Fare']]\n",
    "id_test = df_test[['PassengerId']]\n",
    "y_test_pred = model.predict(x_test)\n",
    "df_submit = pd.DataFrame({\n",
    "    'PassengerId': id_test['PassengerId'],\n",
    "    'Survived': y_test_pred\n",
    "})\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('c_submission_baseline.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
